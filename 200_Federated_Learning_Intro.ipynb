{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d39628",
   "metadata": {},
   "source": [
    "__Purpose:__ Introduce Federated Learning, specifically by implementing FedAveraging on our dataset and moving on to more advanced methods.\n",
    "<br>\n",
    "1. Need to figure out what the weights are\n",
    "2. Need to look into asynchronous FL\n",
    "3. Create a global decoder from the last update... can I test it? I don't think so...\n",
    "4. I still think it could be beneficial to create a random external model that we could easily do FL on...\n",
    "5. Does scipy.optimize.minimize() run 1 iter or all necessary? Can it be replaced with SGD?  How are BFGS and SGD related?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d2f09a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import h5py as h5\n",
    "#import aopy \n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "#from numpy.matlib import repmat\n",
    "#from matplotlib import pyplot as plt\n",
    "#from scipy.signal import detrend, firwin, freqz, lfilter\n",
    "#from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from scipy.optimize import minimize, least_squares\n",
    "import copy\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9f58c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_params import *\n",
    "from simulations import *\n",
    "import time\n",
    "import pickle5 as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fda900",
   "metadata": {},
   "source": [
    "## Load Our Data In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e71bffbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7168, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>METACPHS_S106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METACPHS_S106</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METACPHS_S106</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METACPHS_S106</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>METACPHS_S106</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Subject  Condition  Channel\n",
       "0  METACPHS_S106          0        0\n",
       "1  METACPHS_S106          0        1\n",
       "2  METACPHS_S106          0        2\n",
       "3  METACPHS_S106          0        3\n",
       "4  METACPHS_S106          0        4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject\n",
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emg_labels_df1 = pd.read_csv(\"Data\\emg_full_labels1.csv\")\n",
    "#emg_labels_df2 = pd.read_csv(\"Data\\emg_full_labels2.csv\")\n",
    "emg_labels_df = emg_labels_df1\n",
    "#emg_labels_df = pd.concat((emg_labels_df1, emg_labels_df2))\n",
    "\n",
    "try:\n",
    "    emg_labels_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "except:\n",
    "    # Masterful code here\n",
    "    print(\"NO UNNAMED COLUMN DETECTED!\")\n",
    "\n",
    "print(emg_labels_df.shape)\n",
    "display(emg_labels_df.head())\n",
    "\n",
    "labels_df = pd.DataFrame(emg_labels_df['Subject'].map(key_to_num))\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0676454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(emg_labels_df[\"Subject\"].unique())\n",
    "print()\n",
    "\n",
    "print(emg_labels_df.shape[0]/14/64/8)\n",
    "# 14 participants / 64 channels / 8 conditions\n",
    "# Why do I only have 2 updates..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "165598f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "t0 = time.time()\n",
    "emg_data_df1 = pd.read_csv(\"Data\\emg_full_data1.csv\")\n",
    "emg_data_df2 = pd.read_csv(\"Data\\emg_full_data2.csv\")\n",
    "emg_data_df = pd.concat((emg_data_df1, emg_data_df2))\n",
    "try:\n",
    "    emg_data_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "except:\n",
    "    print(\"NO UNNAMED COLUMN DETECTED!\")\n",
    "t1 = time.time()\n",
    "total = t1-t0  \n",
    "print(total)\n",
    "print(emg_data_df.shape)\n",
    "emg_data_df.head()\n",
    "'''\n",
    "# Just use the emg data directly from the pickle file for now\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "845b1837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "t0 = time.time()\n",
    "#envelope_df50 = pd.read_csv(\"Data\\envelope_df50.csv\")\n",
    "envelope_df100 = pd.read_csv(\"Data\\envelope_df100.csv\")\n",
    "#envelope_df150 = pd.read_csv(\"Data\\envelope_df150.csv\")\n",
    "#envelope_df200 = pd.read_csv(\"Data\\envelope_df200.csv\")\n",
    "#envelope_df250 = pd.read_csv(\"Data\\envelope_df250.csv\")\n",
    "#envelope_df300 = pd.read_csv(\"Data\\envelope_df300.csv\")\n",
    "#raw_envs = [envelope_df50, envelope_df100, envelope_df150, envelope_df200, envelope_df250, envelope_df300]\n",
    "#all_envs = [env.drop('Unnamed: 0', axis=1) for env in raw_envs]\n",
    "try:\n",
    "    envelope_df100.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "except:\n",
    "    print(\"NO UNNAMED COLUMN DETECTED!\")\n",
    "t1 = time.time()\n",
    "total = t1-t0  \n",
    "print(total)\n",
    "print(envelope_df100.shape)\n",
    "envelope_df100.head()\n",
    "'''\n",
    "# Just use the emg data directly from the pickle file for now\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bbe511db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.45900559425354\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "with open('Data\\continuous_full_data_block1.pickle', 'rb') as handle:\n",
    "    #refs_block1, poss_block1, dec_vels_block1, int_vel_block1, emgs_block1, Ws_block1, Hs_block1, alphas_block1, pDs_block1, times_block1, conditions_block1 = pickle.load(handle)\n",
    "    refs_block1, _, _, _, emgs_block1, Ws_block1, _, _, _, _, _ = pickle.load(handle)\n",
    "\n",
    "#with open('Data\\continuous_full_data_block2.pickle', 'rb') as handle:\n",
    "    #refs_block2, poss_block2, dec_vels_block2, int_vel_block2, emgs_block2, Ws_block2, Hs_block2, alphas_block2, pDs_block2, times_block2, conditions_block2 = pickle.load(handle)\n",
    "    #refs_block2, _, _, _, emgs_block2, Ws_block2, _, _, _, _, _ = pickle.load(handle)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0  \n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25c5ad93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 20770, 2, 64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8 conditions, 20770 data points (only 19 unique sets!), xy, channels\n",
    "Ws_block1[keys[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e9af127a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,  1200,  2402,  3604,  4806,  6008,  7210,  8412,  9614,\n",
       "       10816, 12018, 13220, 14422, 15624, 16826, 18028, 19230, 20432,\n",
       "       20769])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a7812773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of decoder: (2, 64)\n",
      "\n",
      "Total difference between dec0 and dec1: 0.0\n",
      "E.g., as previously shown, the first two decs are the same\n",
      "\n",
      "Total difference between dec0 and dec2: 3.1981579823181594\n"
     ]
    }
   ],
   "source": [
    "dec_cond0_user1_update0 = Ws_block1[keys[0]][0,0,:,:]\n",
    "dec_cond0_user1_update1 = Ws_block1[keys[0]][0,update_ix[1],:,:]\n",
    "dec_cond0_user1_update2 = Ws_block1[keys[0]][0,update_ix[2],:,:]\n",
    "\n",
    "print(f\"Shape of decoder: {dec_cond0_user1_update0.shape}\")\n",
    "print()\n",
    "print(f\"Total difference between dec0 and dec1: {(dec_cond0_user1_update0 - dec_cond0_user1_update1).sum()}\")\n",
    "print(\"E.g., as previously shown, the first two decs are the same\")\n",
    "print()\n",
    "print(f\"Total difference between dec0 and dec2: {(dec_cond0_user1_update0 - dec_cond0_user1_update2).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fd624fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#emg_cond0_user1_update0 = emg_data_df.iloc[:64,:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4e9ae3",
   "metadata": {},
   "source": [
    "## Run One Iteration On Above Data and Check Decoders Are the Same\n",
    "1. Modifying Simulations Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d034aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just 1 person\n",
    "filtered_signals = emg_data_df.iloc[:64,:]\n",
    "# Read in the reference positions from the pickle file\n",
    "cued_target_position = refs_block1[keys[0]][0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2cc88fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previously created random decoder, but we are trying to rerun\n",
    "#D_0 = np.random.rand(2,64)\n",
    "D_0 = dec_cond0_user1_update0\n",
    "\n",
    "#learning_batch = 8\n",
    "learning_batch = update_ix[1]  # I think this is supposed to be the number of datapoints per update?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "203958de",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .95 # higher alpha means more old decoder (slower update)\n",
    "alphaF=1e-1\n",
    "alphaD = 1e-1\n",
    "\n",
    "D = []\n",
    "D_constant = []\n",
    "D_bounded = []\n",
    "D_constant_bounded = []\n",
    "D.append(D_0)\n",
    "D_constant.append(D_0)\n",
    "D_bounded.append(D_0)\n",
    "D_constant_bounded.append(D_0)\n",
    "accuracy = []\n",
    "accuracy_constant = []\n",
    "accuracy_bounded = []\n",
    "accuracy_constant_bounded = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "de312ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original code for running simulations...\n",
    "# for ix in range(10000):\n",
    "    #accuracy_constant_,D_constant,p_constrained_constant = simulation_constant_intent(D_constant,learning_batch,alpha,alphaF=alphaF,alphaD=alphaD)\n",
    "    #accuracy_constant.extend(accuracy_constant_)\n",
    "    #accuracy_,D,p_constrained = simulation(D,learning_batch,alpha,alphaF=alphaF,alphaD=alphaD)    \n",
    "    #accuracy.extend(accuracy_)\n",
    "    #accuracy_bounded_,D_bounded,p_bounded = simulation_bounded_pos(D_bounded,learning_batch,alpha,alphaF=alphaF,alphaD=alphaD)  \n",
    "    #accuracy_bounded.extend(accuracy_bounded_)\n",
    "    #accuracy_constant_bounded_,D_constant_bounded,p_constant_bounded = simulation_constant_intent_bounded(D_constant_bounded,learning_batch,alpha,alphaF=alphaF,alphaD=alphaD)\n",
    "    #accuracy_constant_bounded.extend(accuracy_constant_bounded_)\n",
    "    \n",
    "# Modified code for running simulations...\n",
    "# Why loop at all right now...\n",
    "#for ix in range(10):\n",
    "    #accuracy_,D,p_constrained = simulation(D,learning_batch,alpha,alphaF=alphaF,alphaD=alphaD)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8494cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added 2 new parameters\n",
    "#def simulation(D,learning_batch,alpha,alphaF=1e-2,alphaD=1e-2,display_info=False,num_iters=False):\n",
    "#D  # Already defined\n",
    "#learning_batch  # Already defined\n",
    "#alpha  # Already defined\n",
    "#alphaF=1e-2  #defined as something else earlier...\n",
    "#alphaD=1e-2  #defined as something else earlier...\n",
    "display_info=True\n",
    "num_iters=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "455c7b95",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_888\\873535753.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiltered_signals_randomized\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlearning_batch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlearning_batch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mp_intended\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcued_target_position_randomized\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlearning_batch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlearning_batch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# stack p_intended (2 x 60 timepoints x learning batch size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mv_intended\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp_constrained\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_new_decoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp_intended\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# CLASSIFY CURRENT DECODER ACCURACY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\simulations.py\u001b[0m in \u001b[0;36moutput_new_decoder\u001b[1;34m(s, D, p_intended)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0ms\u001b[0m \u001b[1;31m# actual decoded velocity (2,60)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m     \u001b[1;31m# integrate decoded velocities into positions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mix\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "p_classify = []\n",
    "accuracy_temp = []\n",
    "\n",
    "#num_updates = int(np.floor((filtered_signals.shape[0]-1)/learning_batch)) # how many times can we update decoder based on learning batch    \n",
    "num_updates = 19  # Let this equal the number of actual updates\n",
    "\n",
    "#############################################################################################\n",
    "# RANDOMIZE DATASET\n",
    "# Idk what's going on here\n",
    "# I KNOW USE THIS SPACE TO CONVERT THE DFS TO NUMPY ARRAYS\n",
    "randomized_integers = np.random.permutation(range(0,cued_target_position.shape[0]))\n",
    "filtered_signals_randomized = filtered_signals.to_numpy()   # filtered_signals[randomized_integers]\n",
    "cued_target_position_randomized = cued_target_position#.to_numpy()   # cued_target_position[randomized_integers]\n",
    "#############################################################################################\n",
    "\n",
    "# batches the trials into each of the update batch\n",
    "for ix in range(num_updates):\n",
    "    #s = np.hstack([x for x in filtered_signals_randomized[int(ix*learning_batch+1):int((ix+1)*learning_batch+1),:,:]])# stack s (64 x (60 timepoints x learning batch size))\n",
    "    # stack s (64 x (60 timepoints x learning batch size))\n",
    "    s = filtered_signals_randomized[:, int(ix*learning_batch+1):int((ix+1)*learning_batch+1)]\n",
    "    p_intended = np.hstack([np.tile(x[:,np.newaxis],60) for x in cued_target_position_randomized[int(ix*learning_batch+1):int((ix+1)*learning_batch+1),:]]) # stack p_intended (2 x 60 timepoints x learning batch size)\n",
    "    v_intended,p_constrained = output_new_decoder(s,D[-1],p_intended)\n",
    "\n",
    "    # CLASSIFY CURRENT DECODER ACCURACY\n",
    "    v_actual = D[-1]@s\n",
    "    for trial in range(learning_batch):\n",
    "        v_trial = v_actual[:,int(trial*60):int((trial+1)*60)] # velocities for each trials (2,60)\n",
    "        p_final = np.sum(v_trial,axis=1)[:,np.newaxis] # final position after integration (2,)\n",
    "        p_classify.append(classify(p_final))\n",
    "\n",
    "    # UPDATE DECODER\n",
    "    u = copy.deepcopy(s) # u is the person's signal s (64 CHANNELS X TIMEPOINTS)\n",
    "    q = copy.deepcopy(v_intended) # use cued positions as velocity vectors for updating decoder should be 2 x num_trials\n",
    "\n",
    "    # emg_windows against intended_targets (trial specific cued target)\n",
    "    F = copy.deepcopy(u[:,:-1]) # note: truncate F for estimate_decoder\n",
    "    V = copy.deepcopy(q)\n",
    "\n",
    "    # initial decoder estimate for gradient descent\n",
    "    D0 = np.random.rand(2,64)\n",
    "\n",
    "    # set alphas\n",
    "    H = np.zeros((2,2))\n",
    "    # use scipy minimize for gradient descent and provide pre-computed analytical gradient for speed\n",
    "    if num_iters is False:\n",
    "        out = minimize(lambda D: cost_l2(F,D,H,V), D0, method='BFGS', jac = lambda D: gradient_cost_l2(F,D,H,V), options={'disp': display_info})\n",
    "    else:\n",
    "        out = minimize(lambda D: cost_l2(F,D,H,V), D0, method='BFGS', jac = lambda D: gradient_cost_l2(F,D,H,V), options={'disp': display_info, 'maxiter':num_iters})\n",
    "\n",
    "    # reshape to decoder parameters\n",
    "    W_hat = np.reshape(out.x,(2, 64))\n",
    "\n",
    "    # DO SMOOTHBATCH\n",
    "    W_new = alpha*D[-1] + ((1 - alpha) * W_hat)\n",
    "    D.append(W_new)\n",
    "\n",
    "    # COMPUTE CLASSIFICATION ACURACY \n",
    "    p_target = (cued_target_position[randomized_integers])[int(ix*learning_batch+1):int((ix+1)*learning_batch+1),:] # obtain target\n",
    "    accuracy_temp.append(classification_accuracy(p_target,p_classify[-learning_batch:]))\n",
    "\n",
    "p_classify = np.asarray(p_classify)\n",
    "#return accuracy_temp,D,p_constrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c1cf430f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 20770)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_signals_randomized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d64b2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_signals_randomized[:, int(ix*learning_batch+1):int((ix+1)*learning_batch+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fabba7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(ix*learning_batch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "66745cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1201"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int((ix+1)*learning_batch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "572300f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20760</th>\n",
       "      <th>20761</th>\n",
       "      <th>20762</th>\n",
       "      <th>20763</th>\n",
       "      <th>20764</th>\n",
       "      <th>20765</th>\n",
       "      <th>20766</th>\n",
       "      <th>20767</th>\n",
       "      <th>20768</th>\n",
       "      <th>20769</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.778148</td>\n",
       "      <td>10.778148</td>\n",
       "      <td>10.778148</td>\n",
       "      <td>26.874088</td>\n",
       "      <td>43.189501</td>\n",
       "      <td>43.189501</td>\n",
       "      <td>38.594581</td>\n",
       "      <td>...</td>\n",
       "      <td>54.343173</td>\n",
       "      <td>54.343173</td>\n",
       "      <td>53.363208</td>\n",
       "      <td>53.363208</td>\n",
       "      <td>53.363208</td>\n",
       "      <td>53.363208</td>\n",
       "      <td>59.557374</td>\n",
       "      <td>59.557374</td>\n",
       "      <td>59.557374</td>\n",
       "      <td>55.634152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.891218</td>\n",
       "      <td>9.891218</td>\n",
       "      <td>9.891218</td>\n",
       "      <td>23.589349</td>\n",
       "      <td>36.477933</td>\n",
       "      <td>36.477933</td>\n",
       "      <td>31.296507</td>\n",
       "      <td>...</td>\n",
       "      <td>79.894291</td>\n",
       "      <td>79.894291</td>\n",
       "      <td>86.860329</td>\n",
       "      <td>86.860329</td>\n",
       "      <td>86.860329</td>\n",
       "      <td>86.860329</td>\n",
       "      <td>71.319955</td>\n",
       "      <td>71.319955</td>\n",
       "      <td>71.319955</td>\n",
       "      <td>56.606641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.606057</td>\n",
       "      <td>1.606057</td>\n",
       "      <td>1.606057</td>\n",
       "      <td>8.623857</td>\n",
       "      <td>15.845217</td>\n",
       "      <td>15.845217</td>\n",
       "      <td>17.957593</td>\n",
       "      <td>...</td>\n",
       "      <td>89.500295</td>\n",
       "      <td>89.500295</td>\n",
       "      <td>84.266738</td>\n",
       "      <td>84.266738</td>\n",
       "      <td>84.266738</td>\n",
       "      <td>84.266738</td>\n",
       "      <td>71.979639</td>\n",
       "      <td>71.979639</td>\n",
       "      <td>71.979639</td>\n",
       "      <td>65.918534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.668527</td>\n",
       "      <td>3.668527</td>\n",
       "      <td>3.668527</td>\n",
       "      <td>7.165376</td>\n",
       "      <td>11.628290</td>\n",
       "      <td>11.628290</td>\n",
       "      <td>15.308951</td>\n",
       "      <td>...</td>\n",
       "      <td>68.943668</td>\n",
       "      <td>68.943668</td>\n",
       "      <td>66.983974</td>\n",
       "      <td>66.983974</td>\n",
       "      <td>66.983974</td>\n",
       "      <td>66.983974</td>\n",
       "      <td>64.104558</td>\n",
       "      <td>64.104558</td>\n",
       "      <td>64.104558</td>\n",
       "      <td>61.848159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.411810</td>\n",
       "      <td>1.411810</td>\n",
       "      <td>1.411810</td>\n",
       "      <td>9.707134</td>\n",
       "      <td>15.677262</td>\n",
       "      <td>15.677262</td>\n",
       "      <td>18.922410</td>\n",
       "      <td>...</td>\n",
       "      <td>43.565918</td>\n",
       "      <td>43.565918</td>\n",
       "      <td>42.343590</td>\n",
       "      <td>42.343590</td>\n",
       "      <td>42.343590</td>\n",
       "      <td>42.343590</td>\n",
       "      <td>42.235306</td>\n",
       "      <td>42.235306</td>\n",
       "      <td>42.235306</td>\n",
       "      <td>41.818073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.733732</td>\n",
       "      <td>0.733732</td>\n",
       "      <td>0.733732</td>\n",
       "      <td>1.852057</td>\n",
       "      <td>2.709863</td>\n",
       "      <td>2.709863</td>\n",
       "      <td>2.888886</td>\n",
       "      <td>...</td>\n",
       "      <td>10.512180</td>\n",
       "      <td>10.512180</td>\n",
       "      <td>8.433349</td>\n",
       "      <td>8.433349</td>\n",
       "      <td>8.433349</td>\n",
       "      <td>8.433349</td>\n",
       "      <td>8.819507</td>\n",
       "      <td>8.819507</td>\n",
       "      <td>8.819507</td>\n",
       "      <td>8.783999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.786207</td>\n",
       "      <td>0.786207</td>\n",
       "      <td>0.786207</td>\n",
       "      <td>2.342935</td>\n",
       "      <td>3.775112</td>\n",
       "      <td>3.775112</td>\n",
       "      <td>3.591124</td>\n",
       "      <td>...</td>\n",
       "      <td>10.358660</td>\n",
       "      <td>10.358660</td>\n",
       "      <td>10.076067</td>\n",
       "      <td>10.076067</td>\n",
       "      <td>10.076067</td>\n",
       "      <td>10.076067</td>\n",
       "      <td>9.053318</td>\n",
       "      <td>9.053318</td>\n",
       "      <td>9.053318</td>\n",
       "      <td>8.717604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.964077</td>\n",
       "      <td>1.964077</td>\n",
       "      <td>1.964077</td>\n",
       "      <td>3.469345</td>\n",
       "      <td>5.954418</td>\n",
       "      <td>5.954418</td>\n",
       "      <td>4.932899</td>\n",
       "      <td>...</td>\n",
       "      <td>11.642759</td>\n",
       "      <td>11.642759</td>\n",
       "      <td>10.478702</td>\n",
       "      <td>10.478702</td>\n",
       "      <td>10.478702</td>\n",
       "      <td>10.478702</td>\n",
       "      <td>9.317424</td>\n",
       "      <td>9.317424</td>\n",
       "      <td>9.317424</td>\n",
       "      <td>10.649868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.254783</td>\n",
       "      <td>2.254783</td>\n",
       "      <td>2.254783</td>\n",
       "      <td>6.474291</td>\n",
       "      <td>9.297987</td>\n",
       "      <td>9.297987</td>\n",
       "      <td>11.163922</td>\n",
       "      <td>...</td>\n",
       "      <td>16.111081</td>\n",
       "      <td>16.111081</td>\n",
       "      <td>14.372208</td>\n",
       "      <td>14.372208</td>\n",
       "      <td>14.372208</td>\n",
       "      <td>14.372208</td>\n",
       "      <td>11.566742</td>\n",
       "      <td>11.566742</td>\n",
       "      <td>11.566742</td>\n",
       "      <td>11.841818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.102943</td>\n",
       "      <td>2.102943</td>\n",
       "      <td>2.102943</td>\n",
       "      <td>5.434527</td>\n",
       "      <td>8.741306</td>\n",
       "      <td>8.741306</td>\n",
       "      <td>9.329476</td>\n",
       "      <td>...</td>\n",
       "      <td>9.309057</td>\n",
       "      <td>9.309057</td>\n",
       "      <td>9.324670</td>\n",
       "      <td>9.324670</td>\n",
       "      <td>9.324670</td>\n",
       "      <td>9.324670</td>\n",
       "      <td>9.323918</td>\n",
       "      <td>9.323918</td>\n",
       "      <td>9.323918</td>\n",
       "      <td>9.326920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 20770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2          3          4          5          6          7  \\\n",
       "0   0.0  0.0  0.0  10.778148  10.778148  10.778148  26.874088  43.189501   \n",
       "1   0.0  0.0  0.0   9.891218   9.891218   9.891218  23.589349  36.477933   \n",
       "2   0.0  0.0  0.0   1.606057   1.606057   1.606057   8.623857  15.845217   \n",
       "3   0.0  0.0  0.0   3.668527   3.668527   3.668527   7.165376  11.628290   \n",
       "4   0.0  0.0  0.0   1.411810   1.411810   1.411810   9.707134  15.677262   \n",
       "..  ...  ...  ...        ...        ...        ...        ...        ...   \n",
       "59  0.0  0.0  0.0   0.733732   0.733732   0.733732   1.852057   2.709863   \n",
       "60  0.0  0.0  0.0   0.786207   0.786207   0.786207   2.342935   3.775112   \n",
       "61  0.0  0.0  0.0   1.964077   1.964077   1.964077   3.469345   5.954418   \n",
       "62  0.0  0.0  0.0   2.254783   2.254783   2.254783   6.474291   9.297987   \n",
       "63  0.0  0.0  0.0   2.102943   2.102943   2.102943   5.434527   8.741306   \n",
       "\n",
       "            8          9  ...      20760      20761      20762      20763  \\\n",
       "0   43.189501  38.594581  ...  54.343173  54.343173  53.363208  53.363208   \n",
       "1   36.477933  31.296507  ...  79.894291  79.894291  86.860329  86.860329   \n",
       "2   15.845217  17.957593  ...  89.500295  89.500295  84.266738  84.266738   \n",
       "3   11.628290  15.308951  ...  68.943668  68.943668  66.983974  66.983974   \n",
       "4   15.677262  18.922410  ...  43.565918  43.565918  42.343590  42.343590   \n",
       "..        ...        ...  ...        ...        ...        ...        ...   \n",
       "59   2.709863   2.888886  ...  10.512180  10.512180   8.433349   8.433349   \n",
       "60   3.775112   3.591124  ...  10.358660  10.358660  10.076067  10.076067   \n",
       "61   5.954418   4.932899  ...  11.642759  11.642759  10.478702  10.478702   \n",
       "62   9.297987  11.163922  ...  16.111081  16.111081  14.372208  14.372208   \n",
       "63   8.741306   9.329476  ...   9.309057   9.309057   9.324670   9.324670   \n",
       "\n",
       "        20764      20765      20766      20767      20768      20769  \n",
       "0   53.363208  53.363208  59.557374  59.557374  59.557374  55.634152  \n",
       "1   86.860329  86.860329  71.319955  71.319955  71.319955  56.606641  \n",
       "2   84.266738  84.266738  71.979639  71.979639  71.979639  65.918534  \n",
       "3   66.983974  66.983974  64.104558  64.104558  64.104558  61.848159  \n",
       "4   42.343590  42.343590  42.235306  42.235306  42.235306  41.818073  \n",
       "..        ...        ...        ...        ...        ...        ...  \n",
       "59   8.433349   8.433349   8.819507   8.819507   8.819507   8.783999  \n",
       "60  10.076067  10.076067   9.053318   9.053318   9.053318   8.717604  \n",
       "61  10.478702  10.478702   9.317424   9.317424   9.317424  10.649868  \n",
       "62  14.372208  14.372208  11.566742  11.566742  11.566742  11.841818  \n",
       "63   9.324670   9.324670   9.323918   9.323918   9.323918   9.326920  \n",
       "\n",
       "[64 rows x 20770 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_signals_randomized.iloc[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98a738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(D)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
