{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d39628",
   "metadata": {},
   "source": [
    "__Purpose:__ Before implementing Federated Learning, re-implement the original simulatinos on the continuous data task we've been working off of to ensure that we implement the correct loss functions in the federated learning task. Simulated decoders should match the decoders found in Ws_block1 from the CPHS data pickle file.\n",
    "<br>\n",
    "1. The dec matrix is the weights to pass back and forth, although it comes out of SmoothBatch first\n",
    "1. We are assuming we can test on the second half (updates 10-19ish) since learning should be complete by then!\n",
    "1. Scipy.optimize.minimize() runs many iters to fully minimize its cost function.  You can change it to run as many iters as you'd like, although AFAIK you won't know how many it takes to converge.  But this is still a good set up for FL.\n",
    "1. Hmm minimize() is doing BFGS rn and not SGD... not sure if that matters really.  Could probably implement SGD on my own or find it.  BFGS is 2nd order but we don't have a lot of parameters, I don't think.  Plus we can (already have?) solved analytically for the Hessian.  I think."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2f09a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "#from numpy.matlib import repmat\n",
    "from matplotlib import pyplot as plt\n",
    "#from scipy.signal import detrend, firwin, freqz, lfilter\n",
    "#from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from scipy.optimize import minimize, least_squares\n",
    "import copy\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f58c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_params import *\n",
    "from simulations import *\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9634c84f",
   "metadata": {},
   "source": [
    "# Reminder of Conditions Order\n",
    "\n",
    "NOTE: \n",
    "\n",
    "* **CONDITIONS** = array(['D_1', 'D_2', 'D_5', 'D_6', 'D_3', 'D_4', 'D_7','D_8']\n",
    "* **LEARNING RATES:** alpha = 0.25 and 0.75; alpha = 0.25 for D1, D2, D5, D6; alpha = 0.75 for D3, D4, D7, D8\n",
    "* **SMOOTHBATCH:** W_next = alpha*W_old + ((1 - alpha) * W_calc)\n",
    "\n",
    "* **DECODER INIT:** pos for D1 - D4, neg for D5 - D8\n",
    "\n",
    "* **PENALTY TERM:** $\\lambda_E$ = 1e-6 for all, $\\lambda_F$ = 1e-7 for all, $\\lambda_D$ = 1e-3 for 1, 3, 5, 7 and 1e-4 for 2, 4, 6, 8 \n",
    "\n",
    "\n",
    "| DECODER | ALPHA | PENALTY | DEC INIT |\n",
    "| --- | --- | --- | --- |\n",
    "| 1 | 0.25 | 1e-3 | + |\n",
    "| 2 | 0.25 | 1e-4 | + |\n",
    "| 3 | 0.75 | 1e-3 | + |\n",
    "| 4 | 0.75 | 1e-4 | + |\n",
    "| 5 | 0.25 | 1e-3 | - |\n",
    "| 6 | 0.25 | 1e-4 | - |\n",
    "| 7 | 0.75 | 1e-3 | - |\n",
    "| 8 | 0.75 | 1e-4 | - |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fda900",
   "metadata": {},
   "source": [
    "## Load Our Data In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe511db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0862083435058594\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "with open('Data\\continuous_full_data_block1.pickle', 'rb') as handle:\n",
    "    #refs_block1, poss_block1, dec_vels_block1, int_vel_block1, emgs_block1, Ws_block1, Hs_block1, alphas_block1, pDs_block1, times_block1, conditions_block1 = pickle.load(handle)\n",
    "    refs_block1, _, _, _, emgs_block1, Ws_block1, _, _, _, _, _ = pickle.load(handle)\n",
    "\n",
    "#with open('Data\\continuous_full_data_block2.pickle', 'rb') as handle:\n",
    "    #refs_block2, poss_block2, dec_vels_block2, int_vel_block2, emgs_block2, Ws_block2, Hs_block2, alphas_block2, pDs_block2, times_block2, conditions_block2 = pickle.load(handle)\n",
    "    #refs_block2, _, _, _, emgs_block2, Ws_block2, _, _, _, _, _ = pickle.load(handle)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0  \n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25c5ad93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 20770, 2, 64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8 conditions, 20770 data points (only 19 unique sets!), xy, channels\n",
    "Ws_block1[keys[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9af127a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,  1200,  2402,  3604,  4806,  6008,  7210,  8412,  9614,\n",
       "       10816, 12018, 13220, 14422, 15624, 16826, 18028, 19230, 20432,\n",
       "       20769])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7812773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of decoder: (2, 64)\n",
      "\n",
      "Total difference between dec0 and dec1: 0.0\n",
      "E.g., as previously shown, the first two decs are the same\n",
      "\n",
      "Total difference between dec0 and dec2: 3.1981579823181594\n"
     ]
    }
   ],
   "source": [
    "dec_cond0_user1_update0 = Ws_block1[keys[0]][0,0,:,:]\n",
    "dec_cond0_user1_update1 = Ws_block1[keys[0]][0,update_ix[1],:,:]\n",
    "dec_cond0_user1_update2 = Ws_block1[keys[0]][0,update_ix[2],:,:]\n",
    "\n",
    "print(f\"Shape of decoder: {dec_cond0_user1_update0.shape}\")\n",
    "print()\n",
    "print(f\"Total difference between dec0 and dec1: {(dec_cond0_user1_update0 - dec_cond0_user1_update1).sum()}\")\n",
    "print(\"E.g., as previously shown, the first two decs are the same\")\n",
    "print()\n",
    "print(f\"Total difference between dec0 and dec2: {(dec_cond0_user1_update0 - dec_cond0_user1_update2).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd624fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 20770, 64)\n",
      "(20770, 64)\n"
     ]
    }
   ],
   "source": [
    "#emg_cond0_user1_update0 = emg_data_df.iloc[:64,:].shape\n",
    "\n",
    "# (Condition, datapoints, channels)\n",
    "print(emgs_block1[keys[0]][:,:,:].shape)\n",
    "\n",
    "# Condition 0 of subject 1 (\"0\")\n",
    "print(emgs_block1[keys[0]][0,:,:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4e9ae3",
   "metadata": {},
   "source": [
    "## Run One Iteration On Above Data and Check Decoders Are the Same\n",
    "1. Modifying Simulations Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "203958de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For condition 1:\n",
    "alpha = .25 # higher alpha means more old decoder (slower update)\n",
    "# Assuming these are the same as lambda's, the decoder cost penalties\n",
    "alphaF = 1e-7\n",
    "alphaD = 1e-3\n",
    "lambdaE = 1e-6\n",
    "#where is lambda E?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6587c7",
   "metadata": {},
   "source": [
    "Condition 0 only for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "176d573c-470b-4d6c-9a8f-c3d38ae16d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 20770, 2, 64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ws_block1[keys[0]].shape # 8 conditions, timepoint, D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "130563dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_half = 7\n",
    "\n",
    "# Added 2 new parameters\n",
    "#def simulation(D,learning_batch,alpha,alphaF=1e-2,alphaD=1e-2,display_info=False,num_iters=False):\n",
    "display_info=False\n",
    "num_updates = 19  # This is 19 for us\n",
    "dt = 1/60\n",
    "\n",
    "D = [[0 for _ in range(num_updates)] for i in range(first_half)]\n",
    "cost_log = [[0 for _ in range(num_updates)] for i in range(first_half)]\n",
    "grad_cost_log = [[0 for _ in range(num_updates)] for i in range(first_half)]\n",
    "\n",
    "for idx, user in enumerate(keys[:first_half]):\n",
    "    filtered_signals = emgs_block1[user][0,:,:] # (20770 time , 64 channels)\n",
    "    p_reference_full = refs_block1[user][0,:,:] #(20770 time, 2 (x,y))\n",
    "    D[idx][0] = Ws_block1[user][0,1,:,:] # (2 (x,y), 64 channels)\n",
    "    total_datapoints = emgs_block1[user][0,:,:].shape[0]\n",
    "    # batches the trials into each of the update batch\n",
    "    # Do num_updates-1 because the very last update is only 1 datapoint, the 2nd to last is only 337\n",
    "    for ix in range(num_updates-1):\n",
    "        ix+=1  # I think this might make it skip the 1st update (eg update 0) --> I changed it to ix-1, ix\n",
    "        # Reason is because it lets us do D[idx][ix-1] to get the init dec\n",
    "        #print(ix)\n",
    "\n",
    "        # Instead of using learning_batch, we should get the same results just using update_ix values\n",
    "        lower_bound = update_ix[ix-1]\n",
    "        if ix==(num_updates-1):\n",
    "            upper_bound = total_datapoints\n",
    "        else:\n",
    "            upper_bound = update_ix[ix]\n",
    "        learning_batch = upper_bound - lower_bound\n",
    "\n",
    "        s = np.transpose(filtered_signals[lower_bound:upper_bound,:]) # 64 ch x 1200 timepoints\n",
    "        v_actual = D[idx][ix-1]@s\n",
    "        # Numerical integration of v_actual to get p_actual\n",
    "        #p_actual = np.sum(v_actual, axis=1)*dt  # dt=1/60\n",
    "        # Cumulative sum instead\n",
    "        p_actual = np.cumsum(v_actual, axis=1)*dt # 2 (x,y) x 1200 timepoints\n",
    "        #p_actual = np.reshape(p_actual, (p_actual.shape[0], 1))\n",
    "        # Update decoder\n",
    "        p_reference = np.transpose(p_reference_full[lower_bound:upper_bound,:])\n",
    "        #(r-y)/60=D_new@s  # This is the optimization problem\n",
    "        V = (p_reference[:,1:] - p_actual[:,:-1])*dt\n",
    "        F = copy.deepcopy(s[:,:-2]) # note: truncate F for estimate_decoder # why?\n",
    "\n",
    "        # set alphas\n",
    "        H = np.zeros((2,2))\n",
    "        D0 = estimate_decoder(F, H, V)\n",
    "        # use scipy minimize for gradient descent and provide pre-computed analytical gradient for speed\n",
    "        # Is using D[-1] the same as solving the lambda min D function?\n",
    "        cost_log[idx][ix] = cost_l2(F,D0,H,V,learning_batch,alphaF,alphaD,lambdaE)\n",
    "        grad_cost_log[idx][ix] = gradient_cost_l2(F,D0,H,V,learning_batch,alphaF,alphaD,lambdaE)\n",
    "        out = minimize(lambda D: cost_l2(F,D,H,V,learning_batch,alphaF,alphaD,lambdaE), D0, method='BFGS', jac=lambda D: gradient_cost_l2(F,D,H,V,learning_batch,alphaF,alphaD,lambdaE), options={'disp': display_info})\n",
    "\n",
    "        # reshape to decoder parameters\n",
    "        W_hat = np.reshape(out.x,(2, 64))\n",
    "\n",
    "        # DO SMOOTHBATCH\n",
    "        W_new = alpha*D[idx][ix-1] + ((1 - alpha) * W_hat)\n",
    "        D[idx][ix] = W_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5717c6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6280197299989076\n"
     ]
    }
   ],
   "source": [
    "# The first instance where they could concievable have the same dec value is the 3rd dec in Ws_block (AKA index 2)\n",
    "#print((D[1] - Ws_block1[keys[0]][0,update_ix[2],:,:]).sum())\n",
    "print((D[0][1] - Ws_block1[keys[0]][0,update_ix[1]+1,:,:]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fb1061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how different the final decs are, this is all we really care about\n",
    "# Although if the earlier decs are different how could the last ones be the same lol\n",
    "print((D[0][-1] - Ws_block1[keys[0]][0,update_ix[-1],:,:]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52169558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differences between consecutive decoders\n",
    "\n",
    "# From this file\n",
    "print(f\"Length of D (sims code): {len(D)}\")\n",
    "print(f\"Length of Ws_block1 (cphs code): {len(update_ix)}\")\n",
    "print()\n",
    "print(\"Labels;       D (Sims);     Ws (CPHS);     Sim - CPHS\")\n",
    "for i in range(len(D)-2):\n",
    "    print(f\"Dec{i+1} - Dec{i}: {(D[0][i+1] - D[0][i]).sum():9.5f};    {(Ws_block1[keys[0]][0,update_ix[i+1],:,:] - Ws_block1[keys[0]][0,update_ix[i],:,:]).sum():9.5f};      {(D[i] - Ws_block1[keys[0]][0,update_ix[i],:,:]).sum():9.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9947e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding one to account for the fact that Ws_block 0 and 1 are the same.\n",
    "for i in range(len(D)-2):\n",
    "    print(f\"{(D[0][i] - Ws_block1[keys[0]][0,update_ix[i+1],:,:]).sum():9.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62020ee6",
   "metadata": {},
   "source": [
    "## Now try plotting the costs to see if it matches NB201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1708c96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2color = {0:'lightcoral', 1:'maroon', 2:'chocolate', 3:'darkorange', 4:'gold', 5:'olive', 6:'olivedrab', \n",
    "            7:'lawngreen', 8:'aquamarine', 9:'deepskyblue', 10:'steelblue', 11:'violet', 12:'darkorchid', 13:'deeppink'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99299cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(first_half):\n",
    "    for idx, update_cost in enumerate(cost_log[i]):\n",
    "        plt.scatter(idx, update_cost, color=id2color[i])\n",
    "        \n",
    "plt.ylabel('Cost L2')\n",
    "plt.xlabel('Iteration Number')\n",
    "plt.title('Simulation Cost Eval')\n",
    "#plt.ylim(0, 70)\n",
    "plt.xticks(np.arange(0, 19, 3.0))\n",
    "#plt.yticks(np.arange(0, 120, 20.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e465f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_indices = list(range(19))\n",
    "for i in range(first_half):\n",
    "    plt.plot(step_indices, cost_log[i], color=id2color[i])\n",
    "    \n",
    "plt.ylabel('Cost L2')\n",
    "plt.xlabel('Iteration Number')\n",
    "plt.title('Simulation Cost Eval')\n",
    "#plt.ylim(0, 70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f60721",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(first_half):\n",
    "    if i in (1, 3, 13):\n",
    "        pass\n",
    "    else:\n",
    "        plt.plot(step_indices, cost_log[i], color=id2color[i])\n",
    "    \n",
    "plt.ylabel('Cost L2')\n",
    "plt.xlabel('Iteration Number')\n",
    "plt.title('Simulation Cost Eval')\n",
    "plt.ylim(0, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86920c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(first_half):\n",
    "    if i in (1, 3, 13):\n",
    "        pass\n",
    "    else:\n",
    "        plt.plot(step_indices, cost_log[i], color=id2color[i])\n",
    "    \n",
    "plt.ylabel('Cost L2')\n",
    "plt.xlabel('Iteration Number')\n",
    "plt.title('Simulation Cost Eval')\n",
    "plt.ylim(0, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aa0928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
