{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d39628",
   "metadata": {},
   "source": [
    "__Purpose:__ Introduce Federated Learning, specifically by implementing FedAveraging on our dataset and moving on to more advanced methods.  Start by modifying the Simulations code, worry about (a)synchronicity later.\n",
    "<br>\n",
    "1. We are assuming we can test on the second half (updates 10-19ish) since (human/co-adaptive) learning should be complete by then!  For reasons shown in earlier NBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2f09a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f58c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_params import *\n",
    "from cost_funcs import *\n",
    "from fl_sim_classes import *\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9450bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\kdmen\\Desktop\\Research\\personalization-privacy-risk\\Data'\n",
    "cond0_filename = r'\\cond0_dict_list.p'\n",
    "all_decs_init_filename = r'\\all_decs_init.p'\n",
    "nofl_decs_filename = r'\\nofl_decs.p'\n",
    "id2color = {0:'lightcoral', 1:'maroon', 2:'chocolate', 3:'darkorange', 4:'gold', 5:'olive', 6:'olivedrab', \n",
    "            7:'lawngreen', 8:'aquamarine', 9:'deepskyblue', 10:'steelblue', 11:'violet', 12:'darkorchid', 13:'deeppink'}\n",
    "implemented_client_training_methods = ['EtaGradStep', 'EtaScipyMinStep', 'FullScipyMinStep']\n",
    "implement_these_methods_next = ['APFL', 'AFL', 'PersA_FL_MAML', 'PersA_FL_ME', 'PFA']\n",
    "num_participants = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9634c84f",
   "metadata": {},
   "source": [
    "# Reminder of Conditions Order\n",
    "\n",
    "NOTE: \n",
    "\n",
    "* **CONDITIONS** = array(['D_1', 'D_2', 'D_5', 'D_6', 'D_3', 'D_4', 'D_7','D_8']\n",
    "* **LEARNING RATES:** alpha = 0.25 and 0.75; alpha = 0.25 for D1, D2, D5, D6; alpha = 0.75 for D3, D4, D7, D8\n",
    "* **SMOOTHBATCH:** W_next = alpha*W_old + ((1 - alpha) * W_calc)\n",
    "\n",
    "* **DECODER INIT:** pos for D1 - D4, neg for D5 - D8\n",
    "\n",
    "* **PENALTY TERM:** $\\lambda_E$ = 1e-6 for all, $\\lambda_F$ = 1e-7 for all, $\\lambda_D$ = 1e-3 for 1, 3, 5, 7 and 1e-4 for 2, 4, 6, 8 \n",
    "\n",
    "\n",
    "| DECODER | ALPHA | PENALTY | DEC INIT |\n",
    "| --- | --- | --- | --- |\n",
    "| 1 | 0.25 | 1e-3 | + |\n",
    "| 2 | 0.25 | 1e-4 | + |\n",
    "| 3 | 0.75 | 1e-3 | + |\n",
    "| 4 | 0.75 | 1e-4 | + |\n",
    "| 5 | 0.25 | 1e-3 | - |\n",
    "| 6 | 0.25 | 1e-4 | - |\n",
    "| 7 | 0.75 | 1e-3 | - |\n",
    "| 8 | 0.75 | 1e-4 | - |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e846069e",
   "metadata": {},
   "source": [
    "# Personalized FL Algorithms\n",
    "ALL PERSONALIZATION ALGORITHMS\n",
    "1. APFL\n",
    "1. Cesar/Taha: AFL\n",
    "1. Cesar/Taha: PersA-FL MAML\n",
    "1. Cesar/Taha: PersA-FL ME\n",
    "1. PFA: PP F Adaptation for Effective Model Personalization\n",
    "1. Pers RT FL for Epileptic Seizure Detection\n",
    "1. An Efficient Framework for Clustered FL\n",
    "1. Pers FL with DP\n",
    "## Adaptive Personalized FL Testing Ground"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd91d63",
   "metadata": {},
   "source": [
    "Adapting their code to actually be able to be run in something other than top-down server-only approach\n",
    "> Their Github: https://github.com/MLOPTPSU/FedTorch <br>\n",
    "> APFL link: https://github.com/MLOPTPSU/FedTorch/blob/ab8068dbc96804a5c1a8b898fd115175cfebfe75/fedtorch/comms/trainings/federated/apfl.py#L33\n",
    "\n",
    "loss.backward() computes dloss/dx for every parameter x which has requires_grad=True. These are accumulated into x.grad for every parameter x. Loss.backward() does not update the weights, only computes the gradients.  The graph is used by loss.backward() to compute gradients.  In pseudo-code: x.grad += dloss/dx\n",
    "\n",
    "optimizer.step updates the value of x using the gradient x.grad. For example, the SGD optimizer performs:\n",
    "\n",
    "x += -lr * x.grad\n",
    "optimizer.zero_grad() clears x.grad for every parameter x in the optimizer. It’s important to call this before loss.backward(), otherwise you’ll accumulate the gradients from multiple passes.\n",
    "\n",
    "optimizer.zero_grad() and optimizer.step() do not affect the graph of autograd objects. They only touch the model’s parameters and the parameter’s grad attributes.\n",
    "\n",
    "If you have multiple losses (loss1, loss2) you can sum them and then call backwards once:\n",
    "\n",
    "loss3 = loss1 + loss2\n",
    "loss3.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "491a1b53",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27860\\3481756770.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert(1==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f1c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python run_mpi.py -f -ft apfl -n 10 -d mnist -lg 0.1 -b 50 -c 20 -k 1.0 -fs local_step -l 10 -r 2 -pa 0.5 -fp\n",
    "#'--num_epochs': args.num_epochs_per_comm * args.num_comms,\n",
    "\n",
    "# num_epochs_per_comm=1\n",
    "# num_clients=20\n",
    "# batch_size=50\n",
    "# num_comms=100\n",
    "# lr_gamma=1.0\n",
    "# lr_mu = 1\n",
    "\n",
    "cmd = 'python main.py '\n",
    "for k, v in training_params.items():\n",
    "    if v is not None:\n",
    "        cmd += ' {} {} '.format(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7d1fc9",
   "metadata": {},
   "source": [
    "Reworking their code for us <br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ff92ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/MLOPTPSU/FedTorch/blob/ab8068dbc96804a5c1a8b898fd115175cfebfe75/fedtorch/comms/trainings/federated/apfl.py#L33\n",
    "\n",
    "def apfl_skeleton(client):\n",
    "    # Number of communication rounds in federated setting should be defined\n",
    "    for n_c in range(client.args.num_comms):\n",
    "        client.args.rounds_comm += 1\n",
    "        # Configuring the devices for this round of communication\n",
    "        if client.args.graph.rank in online_clients_server: \n",
    "            if client.args.graph.rank in online_clients:\n",
    "                is_sync = False\n",
    "                ep = -1 # counting number of epochs\n",
    "                while not is_sync:\n",
    "                    ep += 1\n",
    "                    for i, (_input, _target) in enumerate(client.train_loader):\n",
    "                        # update local step.\n",
    "                        # update local index and get local step\n",
    "                        # adjust learning rate (based on the # of accessed samples)\n",
    "                        # load data\n",
    "                        # Skip batches with one sample because of BatchNorm issue in some models!\n",
    "                        # inference and get current performance.\n",
    "                        # compute gradient and do local SGD step.\n",
    "                        # compute gradient and do local SGD step.\n",
    "                        # update alpha\n",
    "                        # reset load time for the tracker.\n",
    "            # Sync the model server based on model_clients\n",
    "            # evaluate the sync time\n",
    "            # Do the validation on the server model\n",
    "            # logging.\n",
    "            # reset start round time.\n",
    "            # validate the models at the test data\n",
    "            \n",
    "################################################################################################\n",
    "\n",
    "def train_and_validate_federated_apfl():\n",
    "    #if client.args.evaluate and client.args.graph.rank==0:\n",
    "    #    # Do the testing on the server and return\n",
    "    #    do_validate(client.args, client.model, client.optimizer,  client.criterion, client.metrics, client.test_loader, client.all_clients_group, data_mode='test')\n",
    "    #    return\n",
    "    \n",
    "    tracker = define_local_training_tracker()\n",
    "    start_global_time = time.time()\n",
    "    tracker['start_load_time'] = time.time()\n",
    "\n",
    "    # Number of communication rounds in federated setting should be defined\n",
    "    # IN THIS CASE, WE NUM_COMMS IS NUM ROUNDS BUT WE COUNT UNAVAILABILITY FOR A ROUND AS A COMM\n",
    "    # How to change this to the case where the global model controls but the local nodes have their own number of comm rounds?\n",
    "    # For now I think it's easiest to just use a single shared global num_comms\n",
    "    for n_c in range(self.num_comms):\n",
    "        self.current_round += 1\n",
    "        self.comm_time.append(0.0)  # NEED TO ADD THIS\n",
    "        # Configuring the devices for this round of communication\n",
    "        self.set_available_clients_list()\n",
    "        self.choose_clients()\n",
    "        # Idk what this is doing, I'm assuming just choosing clients\n",
    "        #if (n_c == 0) and (0 not in online_clients):\n",
    "        #    online_clients += [0]\n",
    "        #online_clients_server = online_clients if 0 in online_clients else online_clients + [0]\n",
    "        #online_clients_group = dist.new_group(online_clients_server)\n",
    "        \n",
    "        # Idk what all this graph rank stuff is\n",
    "        #if client.args.graph.rank in online_clients_server: \n",
    "        for my_client in self.chosen_clients_lst:\n",
    "            #client.model_server = distribute_model_server(client.model_server, online_clients_group, src=0)\n",
    "            # This is what the above line does, broadcasts params to the client model... what params?\n",
    "            #    for server_param in model_server.parameters():\n",
    "            #          dist.broadcast(server_param.data, src=src, group=group)\n",
    "            #my_client. ?? recieve new global model? Other params?\n",
    "            # Maybe I could combine these into a dictionary to pass down instead of doing this manually\n",
    "            my_client.global_method = self.method\n",
    "            my_client.global_w = self.w\n",
    "            \n",
    "            # Now load condition num for us I think, or general client init stuff\n",
    "            #client.model.load_state_dict(client.model_server.state_dict())\n",
    "            #\n",
    "            \n",
    "            #if client.args.graph.rank in online_clients:\n",
    "            if True:  # Not sure how the above condition is different from my existing for loop above \n",
    "                is_sync = False\n",
    "                # Client's epoch? Does it matter?\n",
    "                ep = -1 # counting number of epochs\n",
    "                while not is_sync:\n",
    "                    ep += 1\n",
    "                    #self.training_data\n",
    "                    #self.labels\n",
    "                    # Slice up training-data and labels using my already written code:\n",
    "                    #my_client.data_stream='streaming'  # This should be set in the client inits already\n",
    "                    my_client.simulate_data_stream()\n",
    "                    _input = self.F\n",
    "                    _target = self.V\n",
    "                    \n",
    "                    # What data are we looping through? Could this be our updates? I don't think we want to do all updates on 1 comm tho...\n",
    "                    # Assuming this is some SGD stochastic data batch stuff\n",
    "                    #for i, (_input, _target) in enumerate(client.train_loader):\n",
    "                    for i in range(1):\n",
    "                        my_client.train_model\n",
    "                        # update local step.\n",
    "                        logging_load_time(tracker)  # NEED TO ADD THIS\n",
    "                        # update local index and get local step\n",
    "                        # ^ How is local index different from local round?\n",
    "                        \n",
    "                        #client.args.local_index += 1\n",
    "                        my_client.local_round += 1\n",
    "                        # Yah this is some stochastic batching stuff... ask Momona if we should be doing this\n",
    "                        #client.args.local_data_seen += len(_target)\n",
    "                        #get_current_epoch(client.args)\n",
    "                        # This code is the above function... I don't think we are doing epochs?\n",
    "                        #if args.growing_batch_size:\n",
    "                        #    args.epoch_ = args.local_data_seen / args.num_samples_per_epoch\n",
    "                        #else:\n",
    "                        #    args.epoch_ = args.local_index / args.num_batches_train_per_device_per_epoch\n",
    "                        #args.epoch = int(args.epoch_)\n",
    "                        \n",
    "                        # I don't have a decaying learning rate yet\n",
    "                        #local_step = get_current_local_step(client.args)\n",
    "                        #\"\"\"Design a specific local step adjustment scheme based on lr_decay_by_epoch\"\"\"\n",
    "                        #try:\n",
    "                        #    return args.local_steps[args.epoch]\n",
    "                        #except:\n",
    "                        #    return args.local_steps[-1]\n",
    "                        \n",
    "                        # adjust learning rate (based on the # of accessed samples)\n",
    "                        #lr = adjust_learning_rate(client.args, client.optimizer, client.scheduler)\n",
    "                        # What is lr_external? The global one or a default val?\n",
    "                        # Whose lr is this? The client's or the server's?\n",
    "                        if lr_external is None:\n",
    "                            # Don't have a scheduler since no epochs\n",
    "                            lr = lr_scheduler(epoch_)\n",
    "                            if lr is None:\n",
    "                                lr = lr_prev\n",
    "                        else:\n",
    "                            lr = lr_external\n",
    "                        if lr_prev != lr:\n",
    "                            lr_prev = lr\n",
    "\n",
    "                        # load data\n",
    "                        # \"\"\"Loads a mini-batch and records the loading time.\"\"\"\n",
    "                        #_input, _target = load_data_batch(client.args, _input, _target, tracker)\n",
    "                        \n",
    "                        # Doesn't apply to us I don't think\n",
    "                        # Skip batches with one sample because of BatchNorm issue in some models!\n",
    "                        #if _input.size(0)==1:\n",
    "                        #    is_sync = is_sync_fed(client.args)\n",
    "                        #    break\n",
    "                        \n",
    "                        # inference and get current performance.\n",
    "                        # zero_grad just returns a deepcopy of self.model... not sure if this is different from our self.w? It sets self.grad to deepcopy(self.model)\n",
    "                        # ^ Should this be self.w or the cost func?\n",
    "                        # So does this even do anything then? If I did self.w = self.w... so it must be something else...\n",
    "                        client.optimizer.zero_grad()\n",
    "                        loss, performance = inference(client.model, client.criterion, client.metrics, _input, _target)\n",
    "                        # compute gradient and do local SGD step.\n",
    "                        loss.backward()\n",
    "                        client.optimizer.step(apply_lr=True,apply_in_momentum=client.args.in_momentum, apply_out_momentum=False)\n",
    "                        client.optimizer.zero_grad()\n",
    "                        client.optimizer_personal.zero_grad()\n",
    "                        loss_personal, performance_personal = inference_personal(client.model_personal, client.model, \n",
    "                                                                                 client.args.fed_personal_alpha, client.criterion, \n",
    "                                                                                 client.metrics, _input, _target)\n",
    "                        # compute gradient and do local SGD step.\n",
    "                        loss_personal.backward()\n",
    "                        client.optimizer_personal.step(apply_lr=True,apply_in_momentum=client.args.in_momentum, apply_out_momentum=False)\n",
    "                        # update alpha\n",
    "                        if client.args.fed_adaptive_alpha and i==0 and ep==0:\n",
    "                            client.args.fed_personal_alpha = alpha_update(client.model, client.model_personal, client.args.fed_personal_alpha, lr) #0.1/np.sqrt(1+args.local_index))\n",
    "                            average_alpha = client.args.fed_personal_alpha\n",
    "                            average_alpha = global_average(average_alpha, client.args.graph.n_nodes, group=online_clients_group)\n",
    "                            log(\"New alpha is:{}\".format(average_alpha.item()), client.args.debug)\n",
    "                        # reset load time for the tracker.\n",
    "                        tracker['start_load_time'] = time.time()\n",
    "                        is_sync = is_sync_fed(client.args)\n",
    "                        if is_sync:\n",
    "                            break\n",
    "            else:\n",
    "                log(\"Offline in this round. Waiting on others to finish!\", client.args.debug)\n",
    "\n",
    "            do_validate(client.args, client.model, client.optimizer_personal, client.criterion, client.metrics, \n",
    "                        client.train_loader, online_clients_group, data_mode='train', personal=True, \n",
    "                        model_personal=client.model_personal, alpha=client.args.fed_personal_alpha)\n",
    "            if client.args.fed_personal:\n",
    "                do_validate(client.args, client.model, client.optimizer_personal, client.criterion, client.metrics, \n",
    "                            client.val_loader, online_clients_group, data_mode='validation', personal=True, \n",
    "                            model_personal=client.model_personal, alpha=client.args.fed_personal_alpha)\n",
    "\n",
    "            # Sync the model server based on model_clients\n",
    "            tracker['start_sync_time'] = time.time()\n",
    "            client.args.global_index += 1\n",
    "            client.model_server = fedavg_aggregation(client.args, client.model_server, client.model, \n",
    "                                                     online_clients_group, online_clients, client.optimizer)\n",
    "            # evaluate the sync time\n",
    "            logging_sync_time(tracker)\n",
    "            # Do the validation on the server model\n",
    "            do_validate(client.args, client.model_server, client.optimizer, client.criterion, client.metrics, \n",
    "                        client.train_loader, online_clients_group, data_mode='train')\n",
    "            if client.args.fed_personal:\n",
    "                do_validate(client.args, client.model_server, client.optimizer, client.criterion, client.metrics, \n",
    "                            client.val_loader, online_clients_group, data_mode='validation')\n",
    "            # logging.\n",
    "            logging_globally(tracker, start_global_time)\n",
    "            # reset start round time.\n",
    "            start_global_time = time.time()\n",
    "            # validate the models at the test data\n",
    "            if client.args.fed_personal_test:\n",
    "                do_validate(client.args, client.model_client, client.optimizer_personal, client.criterion, \n",
    "                            client.metrics, client.test_loader, online_clients_group, data_mode='test', personal=True,\n",
    "                            model_personal=client.model_personal, alpha=client.args.fed_personal_alpha)\n",
    "            elif client.args.graph.rank == 0:\n",
    "                do_validate(client.args, client.model_server, client.optimizer, client.criterion, \n",
    "                            client.metrics, client.test_loader, online_clients_group, data_mode='test')\n",
    "        else:\n",
    "            log(\"Offline in this round. Waiting on others to finish!\", client.args.debug)\n",
    "        dist.barrier(group=client.all_clients_group)            log(\"Offline in this round. Waiting on others to finish!\", client.args.debug)\n",
    "        dist.barrier(group=client.all_clients_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a55727",
   "metadata": {},
   "source": [
    "My original attempts at writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc24e16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to set smoothbatch='off'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a3dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.choose_clients()\n",
    "K = len(self.chosen_clients_lst)\n",
    "for t in range(T):\n",
    "    running_dec_aggr = 0\n",
    "    # They wrote: \"if t not devices Tau then\" but that seem like it would only run 1 update per t, \n",
    "    # AKA 50 t's to select new clients.  I'll write it like they did ig...\n",
    "    #for i in range(tau):  # DEFINE tau\n",
    "    if t%tau!=0:\n",
    "        for my_client in self.chosen_clients_lst:\n",
    "            # This checks updates, handles streaming, and sets FVD\n",
    "            #my_client.simulate_data_stream(streaming_method='streaming')\n",
    "            \n",
    "            mu = my_client.alpha_D\n",
    "            L = np.linalg.norm(( my_client.F*np.tranpose(my_client.F) + my_client.alpha_D))\n",
    "            kappa = L/mu\n",
    "            a = np.max(128*kappa, tau)\n",
    "            eta_t = 16 / (mu*(t+a))\n",
    "            my_client.p.append((t+a)**2)\n",
    "\n",
    "            #my_client.global_w -= my_client.eta * grad(f_i(my_client.global_w; my_client.smallChi))\n",
    "            my_client.global_w -= eta_t * my_client.gradient_cost_l2(my_client.F, self.global_w, my_client.H, my_client.V, my_client.learning_batch, my_client.alphaF, my_client.alphaD)\n",
    "            #my_client.local_w -= my_client.eta * grad_v(f_i(my_client.v_bar; my_client.smallChi))\n",
    "            my_client.local_w -= eta_t * my_client.gradient_cost_l2(my_client.F, my_client.mixed_w, my_client.H, my_client.V, my_client.learning_batch, my_client.alphaF, my_client.alphaD)\n",
    "            my_client.mixed_w = my_client.adap_alpha*my_client.local_w - (1 - my_client.adap_alpha) * my_client.global_w\n",
    "    else:\n",
    "        running_global_dec = 0\n",
    "        for my_client in self.chosen_clients_lst:\n",
    "            running_global_dec += my_client.global_w\n",
    "        self.w = copy.copy(running_global_dec)\n",
    "        self.choose_clients()\n",
    "        # Presumably len(self.chosen_clients_lst) will always be the same (same C)... otherwise would need to re-set K\n",
    "        for my_client in self.chosen_clients_lst:\n",
    "            my_client.global_w = copy.copy(self.w)  # Does this need to be a copy?\n",
    "    self.w = (1/K)*running_dec_aggr\n",
    "    #^ Should this be self.global_w? Just have to make it consistent everywhere\n",
    "    # This is the global model's dec, so I'll leave it as is.  No reason for the global model to have a local dec too...\n",
    "\n",
    "    # The purpose of this is to update the current weight to just be the same as last iter\n",
    "    # My code doesn't track history so I don't need to do it, for now at least\n",
    "    #for my_client in (set(self.available_clients_lst) ^ set(self.chosen_clients_lst)):  # Symmetric Difference for sets\n",
    "    #    my_client.local_w = my_client.local_w\n",
    "\n",
    "    # Defining params used in the next section\n",
    "    #for my_client in self.available_clients_lst:\n",
    "    #    my_client.running_pers_term = 0\n",
    "    #    my_client.running_global_term = 0\n",
    "    #    for t in range(T):\n",
    "    #        # Summed chosen globals is j exists in Ut... so just the (newly?) chosen clients?\n",
    "    #        # Likewise it should be the same for all clients since it varies wrt j I think\n",
    "    #        summed_chosen_globals = np.sum([chosen_client.global_w for chosen_client in self.chosen_clients_lst])\n",
    "    #        my_client.running_pers_term += my_client.p[t]*(my_client.adap_alpha*my_client.local_w + (1-my_client.adap_alpha)*(1/K)*summed_chosen_globals\n",
    "    #        my_client.running_global_term += my_client.p[t]*summed_chosen_globals\n",
    "    # Defining params used in the next section\n",
    "    for t in range(T):\n",
    "        summed_chosen_globals = np.sum([chosen_client.global_w for chosen_client in self.chosen_clients_lst])\n",
    "        for my_client in self.available_clients_lst:\n",
    "            # These should be made into attrs\n",
    "            #my_client.running_pers_term = 0\n",
    "            #my_client.running_global_term = 0\n",
    "            \n",
    "            my_client.running_pers_term += my_client.p[t]*(my_client.adap_alpha*my_client.local_w + (1-my_client.adap_alpha)*(1/K)*summed_chosen_globals\n",
    "            my_client.running_global_term += my_client.p[t]*summed_chosen_globals\n",
    "\n",
    "# The actual models                                                    \n",
    "# \"tin for i=1,...,n\"\n",
    "for my_client in self.available_clients_lst:\n",
    "    S_T = np.sum(my_client.p)\n",
    "    # All these random params are defined in theorem 2 on Page 10\n",
    "    # \"Output\" --> lol and do what with\n",
    "    # v^hat AKA personalized_w = (1/S_T)*\\sum_1^T(p_t(alpha_i*v_i^t + (1-alpha_i)*(1/K)*(\\sum_{j in chosen clients} w_j^t)))\n",
    "    my_client.personalized_w = (1/S_T)*my_client.running_pers_term\n",
    "    # Global model\n",
    "    # w^hat = 1/(K*S_T)*(\\sum_1^T p_t*(\\sum_j w_j^t))\n",
    "    my_client.global_w = (1/K*S_T)*my_client.running_global_term\n",
    "    #self.dec_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6584d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the optimal alpha\n",
    "# a_i* = argmin_{a_i exists in [0,1]} f_i(a_i*v + (1-a_i)w)\n",
    "a_i(t) = a_i(t-1) - eta_t grad_a(v_bar_i^(t-1); zeta_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a6699f",
   "metadata": {},
   "source": [
    "## Personalized Asynchronous Federated Learning (Taha+Cesar)\n",
    "> https://arxiv.org/pdf/2210.01176.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605dde82",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(1==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fee4ed7",
   "metadata": {},
   "source": [
    "Basic AFL\n",
    "> My code is not configured to run this way, although this way is the most realistic (server waits for client responses).  Ideally would have some way to weight different clients if there are some that are spamming, or generally just faster than others and contributing more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203fd581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat until converged...\n",
    "# how do you know in a decentralized way lol\n",
    "#if self.update_recieved:\n",
    "#    self.w -= self.beta*self.latest_update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd427f0",
   "metadata": {},
   "source": [
    "Personalized AFL\n",
    "> 3 Methods (1 is just vanilla AFL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d93aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: number of local steps Q, local stepsize η, MAML stepsize α, Moreau Envelope (ME) regularization parameter λ, minimum batch size b, estimation error ν.\n",
    "\n",
    "# Do client selection\n",
    "\n",
    "for my_client in self.chosen_clients_lst:\n",
    "    my_client.global_w = self.w\n",
    "    for q in range(Q):\n",
    "        #\"Sample a data batch D_{i, q} from distribution p_i\"\n",
    "        \n",
    "        # OPTION A (AFL) --> Just what is shown in the cell above\n",
    "        if self.global_method=='AFL':\n",
    "            # Server doesn't have client's grad input info... eg FDHV\n",
    "            # In their model/code, does the client send the params or the new weight?\n",
    "            \n",
    "            # Eqn 5 is the original\n",
    "            # Eqn 9 is the biased estimation of 5, shown below\n",
    "            self.w -= self.eta*gradient_cost_l2(self.F,self.D,self.H,self.V,self.learning_batch,self.alphaF,self.alphaD)\n",
    "        # OPTION B (PersA-FL: MAML)\n",
    "        elif self.global_method=='PersA_FL_MAML':\n",
    "            #\"Sample 2 databatches from distribution p_i\"\n",
    "            # I have no idea what these terms are lol\n",
    "            # I don't think I can use the analytical cost funcs here either now\n",
    "            self.w -= self.eta*(I-alpha*Hessian(self.w, D_dd))*grad(self.w-alpha*grad(D_d), D)\n",
    "        # OPTION C (PersA-FL: ME)\n",
    "        elif self.global_method=='PersA_FL_ME':\n",
    "            self.h = f(theta_i, D) + lambda*0.5*(np.linalg.norm(theta_i - self.w)^2)\n",
    "            #\"Minimize h wrt theta_i up to accuracy level v to find theta_tilde_i\"\n",
    "            #np.linalg.norm(grad_h(theta_tilde_i(self.w), self.w, D)) <= v\n",
    "            #scipy.minimize(...)\n",
    "            self.w -= self.eta*lambda*(self.w - theta_tilde_i(self.w))\n",
    "        \n",
    "        # ELSE\n",
    "        else:\n",
    "            print(f'Global method {self.method} not defined, please select one from the following: {self.implemented_global_training_methods}')\n",
    "delta_i = self.w_i_0 - self.w_i_Q\n",
    "# client i broadcasts delta_i to the server\n",
    "#\"Repeat until not interrupted by the server\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ad4c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87bd474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16784d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f29a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GLOBAL VERSION\n",
    "\n",
    "# Turn this to a class attr\n",
    "different_local_round_thresh_per_client = False\n",
    "\n",
    "def plot_error(global_error=True, local_error=True, dim_reduc_factor=10, print_update_dividers_at_end=False):\n",
    "    \n",
    "        if global_error and local_error:\n",
    "            my_title = 'Global and Local Costs Per Iteration'\n",
    "        elif global_error:\n",
    "            my_title = 'Global Cost Per Iteration'\n",
    "        elif local_error:\n",
    "            my_title = 'Local Costs Per Iteration'\n",
    "        else:\n",
    "            raise(\"You set both global and local to False.  At least one must be true in order to plot something.\")\n",
    "\n",
    "        if self.type=='Server':\n",
    "            for i, my_client in enumerate(self.all_clients):\n",
    "                current_threshold, local_round_threshold, print_update_dividers_at_end, different_local_round_thresh_per_client = _plot_error(my_client)\n",
    "        elif self.type=='Client':\n",
    "            current_threshold, local_round_threshold, print_update_dividers_at_end, different_local_round_thresh_per_client = _plot_error(self)\n",
    "        else:\n",
    "            raise(\"Unsupported class in plot_error func\")\n",
    "            \n",
    "        if print_update_dividers_at_end and different_local_round_thresh_per_client:\n",
    "            # Just using the last client\n",
    "            for thresh_idx in range(current_threshold // local_round_threshold):\n",
    "                plt.axvline(x=(thresh_idx+1)*local_round_threshold, color=\"k\", linewidth=1, linestyle=':')\n",
    "    \n",
    "    plt.ylabel('Cost L2')\n",
    "    plt.xlabel('Iteration Number')\n",
    "    plt.title(my_title)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def _plot_error(my_client, global_error=True, local_error=True, dim_reduc_factor=10, print_update_dividers_at_end=False):\n",
    "    # Idk if this needs to be here if it's defined in the base class?  I don't think so?\n",
    "    id2color = {0:'lightcoral', 1:'maroon', 2:'chocolate', 3:'darkorange', 4:'gold', 5:'olive', 6:'olivedrab', \n",
    "            7:'lawngreen', 8:'aquamarine', 9:'deepskyblue', 10:'steelblue', 11:'violet', 12:'darkorchid', 13:'deeppink'}\n",
    "    \n",
    "    if global_error:\n",
    "        df = pd.DataFrame(my_client.global_error_log)\n",
    "        df10 = df.groupby(df.index//dim_reduc_factor, axis=0).mean()\n",
    "        plt.plot(df10.values[:, 0], df10.values[:, 1], color=id2color[i], linewidth=2.5, linestyle='--')\n",
    "    if local_error:  # NO ELIF\n",
    "        df = pd.DataFrame(my_client.local_error_log)\n",
    "        df10 = df.groupby(df.index//dim_reduc_factor, axis=0).mean()\n",
    "        plt.plot(df10.values[:, 0], df10.values[:, 1], color=id2color[i], linewidth=1)\n",
    "        if self.different_local_round_thresh_per_client:\n",
    "            if user_c0_1ScipyStep[i].data_stream == 'streaming':\n",
    "                for my_update_transition in my_client.update_transition_log:\n",
    "                    plt.scatter(my_update_transition+1, my_client.local_error_log[my_update_transition][1], color=id2color[i], marker='d')\n",
    "        else:\n",
    "            print_update_dividers_at_end = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
