{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d39628",
   "metadata": {},
   "source": [
    "__Purpose:__ Introduce Personalized Federated Learning, specifically by implementing APFL on our dataset and then trying other methods.\n",
    "<br>\n",
    "1. We are still assuming we can test on the second half (updates 10-19ish) since (human/co-adaptive) learning should be complete by then!  For reasons shown in earlier NBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2f09a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "import copy\n",
    "\n",
    "from experiment_params import *\n",
    "from cost_funcs import *\n",
    "from fl_sim_classes import *\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9450bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\kdmen\\Desktop\\Research\\personalization-privacy-risk\\Data'\n",
    "cond0_filename = r'\\cond0_dict_list.p'\n",
    "all_decs_init_filename = r'\\all_decs_init.p'\n",
    "nofl_decs_filename = r'\\nofl_decs.p'\n",
    "id2color = {0:'lightcoral', 1:'maroon', 2:'chocolate', 3:'darkorange', 4:'gold', 5:'olive', 6:'olivedrab', \n",
    "            7:'lawngreen', 8:'aquamarine', 9:'deepskyblue', 10:'steelblue', 11:'violet', 12:'darkorchid', 13:'deeppink'}\n",
    "implemented_client_training_methods = ['EtaGradStep', 'EtaScipyMinStep', 'FullScipyMinStep']\n",
    "implement_these_methods_next = ['APFL', 'AFL', 'PersA_FL_MAML', 'PersA_FL_ME', 'PFA']\n",
    "num_participants = 14\n",
    "\n",
    "# For exclusion when plotting later on\n",
    "bad_nodes = [1,3,13]\n",
    "\n",
    "with open(path+cond0_filename, 'rb') as fp:\n",
    "    cond0_training_and_labels_lst = pickle.load(fp)\n",
    "\n",
    "D_0_7 = np.random.rand(2,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eefe71",
   "metadata": {},
   "source": [
    "# Testing APFL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed36785",
   "metadata": {},
   "source": [
    "Testing the APFL Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "154190a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (2, 600) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25036\\377338165.py\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mglobal_model_APFL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mServer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD_0_7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'APFL'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_c0_APFL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mglobal_model_APFL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_FL_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\fl_sim_classes.py\u001b[0m in \u001b[0;36mexecute_FL_loop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[1;31m# AKA 50 t's to select new clients.  I'll write it like they did ig...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_client_and_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclient_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchosen_clients_lst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mmy_client\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavailable_clients_lst\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m^\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchosen_clients_lst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                     \u001b[1;31m# Otherwise indices will break when calculating finalized running terms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\fl_sim_classes.py\u001b[0m in \u001b[0;36mtrain_client_and_log\u001b[1;34m(self, client_set)\u001b[0m\n\u001b[0;32m    226\u001b[0m                     \u001b[0mpers_init_carry_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersonalized_error_log\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmy_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;31m#[0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmy_client\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclient_set\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m                 \u001b[0mmy_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_training_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m                 current_local_lst.append((my_client.ID, self.current_round, \n\u001b[0;32m    230\u001b[0m                                           my_client.eval_model(which='local')))\n",
      "\u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\fl_sim_classes.py\u001b[0m in \u001b[0;36mexecute_training_loop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexecute_training_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulate_data_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[1;31m# Append (ROUND, COST) to the CLIENT error log\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\fl_sim_classes.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[1;31m# Note that eig does not necessarily return ordered args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[0meigvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m             \u001b[0mmu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meigvals\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Mu is the minimum eigvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m                 \u001b[1;31m# I don't think the below is valid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36mamin\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mamin\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2944\u001b[0m     \u001b[1;36m6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m     \"\"\"\n\u001b[1;32m-> 2946\u001b[1;33m     return _wrapreduction(a, np.minimum, 'min', axis, None, out,\n\u001b[0m\u001b[0;32m   2947\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0;32m   2948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (2, 600) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "user_c0_APFL = [Client(i, D_0_7, 'NAN', cond0_training_and_labels_lst[i], 'streaming', num_steps=10, delay_scaling=0, track_gradient=True, global_method='APFL') for i in range(14)]\n",
    "global_model_APFL = Server(1, D_0_7, 'APFL', user_c0_APFL, num_steps=10)\n",
    "\n",
    "global_model_APFL.execute_FL_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30022e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    global_model_APFL.execute_FL_loop()\n",
    "    #print(f\"ROUND {i}\")\n",
    "    #for my_client in global_model_APFL.chosen_clients_lst:\n",
    "    #    # So since APFL sets the chosen_clients_lst AFTER it runs instead of before each iter, the following line can actually fail...\n",
    "    #    #print(round(np.linalg.norm(( my_client.F@np.transpose(my_client.F) + my_client.alphaD*np.identity(my_client.F.shape[0]))), 3))\n",
    "    #print(global_model_APFL.current_round)\n",
    "    #print(len(global_model_APFL.global_error_log))\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504759d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a83891",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = global_model_APFL.chosen_clients_lst[0].ID\n",
    "user_c0_APFL[i].personalized_error_log[-1]#[user_c0_APFL[i].ID]#[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da888bc0",
   "metadata": {},
   "source": [
    "^ Int is not subscriptable!\n",
    "> Personalized_error_log is not being updated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a700b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvals = np.linalg.eig(user_c0_APFL[i].F.T@user_c0_APFL[i].F)\n",
    "eigenvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2809a499",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amin(eigenvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1643f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.amin(eigenvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0111c0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_participants):\n",
    "    try:\n",
    "        user_c0_APFL[i].F.shape\n",
    "        # If it works then break the loop\n",
    "        break\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe345a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i = 0\n",
    "# This should be the same i as the above loop\n",
    "\n",
    "print(f\"F.shape: {user_c0_APFL[i].F.shape}\")\n",
    "print(f\"Norm: {np.linalg.norm(user_c0_APFL[i].F)}\")\n",
    "print(f\"Sum: {np.sum((user_c0_APFL[i].F))}\")\n",
    "print(f\"**2 Sum: {np.sum((user_c0_APFL[i].F)**2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf9a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Decs\")\n",
    "print(user_c0_APFL[i].local_w)\n",
    "print(user_c0_APFL[i].global_w)\n",
    "diff = user_c0_APFL[i].local_w - user_c0_APFL[i].global_w\n",
    "print(diff)\n",
    "print()\n",
    "print(\"Gradient\")\n",
    "out = gradient_cost_l2(user_c0_APFL[i].F, user_c0_APFL[i].mixed_w, user_c0_APFL[i].H, user_c0_APFL[i].V, user_c0_APFL[i].learning_batch, user_c0_APFL[i].alphaF, user_c0_APFL[i].alphaD, Ne=7)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c6ccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.inner(diff.flatten(), out.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaaa051",
   "metadata": {},
   "source": [
    "Run loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5cc0ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "big_loop_iters = 1000\n",
    "for i in range(big_loop_iters):\n",
    "    global_model_APFL.execute_FL_loop()\n",
    "    \n",
    "print(\"(Current Local Round, Current Local Update)\")\n",
    "for my_client in global_model_APFL.all_clients:\n",
    "    print((my_client.current_round, my_client.current_update))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3753fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_c0_APFL[0].adap_alpha[:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eae331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F.shape: {user_c0_APFL[0].F.shape}\")\n",
    "print(f\"Norm: {np.linalg.norm(user_c0_APFL[0].F)}\")\n",
    "print(f\"Sum: {np.sum((user_c0_APFL[0].F))}\")\n",
    "print(f\"**2 Sum: {np.sum((user_c0_APFL[0].F)**2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a897f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_c0_APFL[0].local_w)\n",
    "print(user_c0_APFL[0].global_w)\n",
    "diff = user_c0_APFL[0].local_w - user_c0_APFL[0].global_w\n",
    "print(diff)\n",
    "out = gradient_cost_l2(user_c0_APFL[0].F, user_c0_APFL[0].mixed_w, user_c0_APFL[0].H, user_c0_APFL[0].V, user_c0_APFL[0].learning_batch, user_c0_APFL[0].alphaF, user_c0_APFL[0].alphaD, Ne=7)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178e24ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.inner(diff.flatten(), out.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b734b72",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24b97fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL, 'local', pers_error=True, show_update_change=False, custom_title=\"APFL: Global, Local, and Pers Costs Per Iter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4acd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(global_model_APFL, 'global', pers_error=True, show_update_change=False, custom_title=\"APFL: Global and Local Costs Per Iteration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe18b76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL, 'local', plot_gradient=True, local_error=False, global_error=False, show_update_change=False, custom_title='GRADIENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be670f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model_APFL.current_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c0bd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client_loss.append(input_data.global_error_log[j][i][2])\n",
    "len(global_model_APFL.global_error_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ed5a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(global_model_APFL.local_error_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04015e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(global_model_APFL.personalized_error_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff9eba0",
   "metadata": {},
   "source": [
    "Re-running but with input learning rate (eta) of 0.00001 (didn't work by itself)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4c876f",
   "metadata": {},
   "source": [
    "Now also fix alpha (not adaptive anymore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18de4b3c",
   "metadata": {},
   "source": [
    "Now set eta to 0.000000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c945b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_learning_rate = 0.0000000000000000000000000000001\n",
    "print(my_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8133abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_c0_APFL = [Client(i, D_0_7, 'NAN', cond0_training_and_labels_lst[i], 'streaming', input_eta=True, num_steps=10, adaptive=False, eta=my_learning_rate, delay_scaling=0, global_method='APFL') for i in range(14)]\n",
    "global_model_APFL = Server(1, D_0_7, 'APFL', user_c0_APFL, num_steps=10)\n",
    "\n",
    "global_model_APFL.execute_FL_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c51b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    global_model_APFL.execute_FL_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220f51f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(big_loop_iters):\n",
    "    global_model_APFL.execute_FL_loop()\n",
    "    \n",
    "print(\"(Current Local Round, Current Local Update)\")\n",
    "for my_client in global_model_APFL.all_clients:\n",
    "    print((my_client.current_round, my_client.current_update))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c84b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_c0_APFL[0].adap_alpha[:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d738d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL, 'local', pers_error=True, show_update_change=False, custom_title=\"APFL: Global, Local, and Pers Costs Per Iter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afb0a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(global_model_APFL, 'global', pers_error=True, show_update_change=False, custom_title=\"APFL: Global and Local Costs Per Iteration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4465670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(1==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfff773",
   "metadata": {},
   "source": [
    "# DEVELOPMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e846069e",
   "metadata": {},
   "source": [
    "# Personalized FL Algorithms\n",
    "ALL PERSONALIZATION ALGORITHMS\n",
    "1. APFL\n",
    "1. Cesar/Taha: AFL\n",
    "1. Cesar/Taha: PersA-FL MAML\n",
    "1. Cesar/Taha: PersA-FL ME\n",
    "1. PFA: PP F Adaptation for Effective Model Personalization\n",
    "1. Pers RT FL for Epileptic Seizure Detection\n",
    "1. An Efficient Framework for Clustered FL\n",
    "1. Pers FL with DP\n",
    "## Adaptive Personalized FL Testing Ground"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd91d63",
   "metadata": {},
   "source": [
    "Adapting their code to actually be able to be run in something other than top-down server-only approach\n",
    "> Their Github: https://github.com/MLOPTPSU/FedTorch <br>\n",
    "> APFL link: https://github.com/MLOPTPSU/FedTorch/blob/ab8068dbc96804a5c1a8b898fd115175cfebfe75/fedtorch/comms/trainings/federated/apfl.py#L33\n",
    "\n",
    "loss.backward() computes dloss/dx for every parameter x which has requires_grad=True. These are accumulated into x.grad for every parameter x. Loss.backward() does not update the weights, only computes the gradients.  The graph is used by loss.backward() to compute gradients.  In pseudo-code: x.grad += dloss/dx\n",
    "\n",
    "optimizer.step updates the value of x using the gradient x.grad. For example, the SGD optimizer performs:\n",
    "\n",
    "x += -lr * x.grad\n",
    "optimizer.zero_grad() clears x.grad for every parameter x in the optimizer. It’s important to call this before loss.backward(), otherwise you’ll accumulate the gradients from multiple passes.\n",
    "\n",
    "optimizer.zero_grad() and optimizer.step() do not affect the graph of autograd objects. They only touch the model’s parameters and the parameter’s grad attributes.\n",
    "\n",
    "If you have multiple losses (loss1, loss2) you can sum them and then call backwards once:\n",
    "\n",
    "loss3 = loss1 + loss2\n",
    "loss3.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f1c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python run_mpi.py -f -ft apfl -n 10 -d mnist -lg 0.1 -b 50 -c 20 -k 1.0 -fs local_step -l 10 -r 2 -pa 0.5 -fp\n",
    "#'--num_epochs': args.num_epochs_per_comm * args.num_comms,\n",
    "\n",
    "# num_epochs_per_comm=1\n",
    "# num_clients=20\n",
    "# batch_size=50\n",
    "# num_comms=100\n",
    "# lr_gamma=1.0\n",
    "# lr_mu = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a6699f",
   "metadata": {},
   "source": [
    "## Personalized Asynchronous Federated Learning (Taha+Cesar)\n",
    "> https://arxiv.org/pdf/2210.01176.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605dde82",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(1==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fee4ed7",
   "metadata": {},
   "source": [
    "Basic AFL\n",
    "> My code is not configured to run this way, although this way is the most realistic (server waits for client responses).  Ideally would have some way to weight different clients if there are some that are spamming, or generally just faster than others and contributing more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203fd581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat until converged...\n",
    "# how do you know in a decentralized way lol\n",
    "#if self.update_recieved:\n",
    "#    self.w -= self.beta*self.latest_update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd427f0",
   "metadata": {},
   "source": [
    "Personalized AFL\n",
    "> 3 Methods (1 is just vanilla AFL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d93aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: number of local steps Q, local stepsize η, MAML stepsize α, Moreau Envelope (ME) regularization parameter λ, minimum batch size b, estimation error ν.\n",
    "\n",
    "# Do client selection\n",
    "\n",
    "for my_client in self.chosen_clients_lst:\n",
    "    my_client.global_w = self.w\n",
    "    for q in range(Q):\n",
    "        #\"Sample a data batch D_{i, q} from distribution p_i\"\n",
    "        \n",
    "        # OPTION A (AFL) --> Just what is shown in the cell above\n",
    "        if self.global_method=='AFL':\n",
    "            # Server doesn't have client's grad input info... eg FDHV\n",
    "            # In their model/code, does the client send the params or the new weight?\n",
    "            \n",
    "            # Eqn 5 is the original\n",
    "            # Eqn 9 is the biased estimation of 5, shown below\n",
    "            self.w -= self.eta*gradient_cost_l2(self.F,self.D,self.H,self.V,self.learning_batch,self.alphaF,self.alphaD)\n",
    "        # OPTION B (PersA-FL: MAML)\n",
    "        elif self.global_method=='PersA_FL_MAML':\n",
    "            #\"Sample 2 databatches from distribution p_i\"\n",
    "            # I have no idea what these terms are lol\n",
    "            # I don't think I can use the analytical cost funcs here either now\n",
    "            self.w -= self.eta*(I-alpha*Hessian(self.w, D_dd))*grad(self.w-alpha*grad(D_d), D)\n",
    "        # OPTION C (PersA-FL: ME)\n",
    "        elif self.global_method=='PersA_FL_ME':\n",
    "            self.h = f(theta_i, D) + lambda*0.5*(np.linalg.norm(theta_i - self.w)^2)\n",
    "            #\"Minimize h wrt theta_i up to accuracy level v to find theta_tilde_i\"\n",
    "            #np.linalg.norm(grad_h(theta_tilde_i(self.w), self.w, D)) <= v\n",
    "            #scipy.minimize(...)\n",
    "            self.w -= self.eta*lambda*(self.w - theta_tilde_i(self.w))\n",
    "        \n",
    "        # ELSE\n",
    "        else:\n",
    "            print(f'Global method {self.method} not defined, please select one from the following: {self.implemented_global_training_methods}')\n",
    "delta_i = self.w_i_0 - self.w_i_Q\n",
    "# client i broadcasts delta_i to the server\n",
    "#\"Repeat until not interrupted by the server\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ad4c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87bd474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16784d97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
