{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d39628",
   "metadata": {},
   "source": [
    "__Purpose:__ Introduce Personalized Federated Learning, specifically by implementing APFL on our dataset and then trying other methods.\n",
    "<br>\n",
    "1. We are still assuming we can test on the second half (updates 10-19ish) since (human/co-adaptive) learning should be complete by then!  For reasons shown in earlier NBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2f09a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "import copy\n",
    "\n",
    "from experiment_params import *\n",
    "from cost_funcs import *\n",
    "from fl_sim_classes import *\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9450bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\kdmen\\Desktop\\Research\\personalization-privacy-risk\\Data'\n",
    "cond0_filename = r'\\cond0_dict_list.p'\n",
    "all_decs_init_filename = r'\\all_decs_init.p'\n",
    "nofl_decs_filename = r'\\nofl_decs.p'\n",
    "id2color = {0:'lightcoral', 1:'maroon', 2:'chocolate', 3:'darkorange', 4:'gold', 5:'olive', 6:'olivedrab', \n",
    "            7:'lawngreen', 8:'aquamarine', 9:'deepskyblue', 10:'steelblue', 11:'violet', 12:'darkorchid', 13:'deeppink'}\n",
    "implemented_client_training_methods = ['EtaGradStep', 'EtaScipyMinStep', 'FullScipyMinStep']\n",
    "implement_these_methods_next = ['APFL', 'AFL', 'PersA_FL_MAML', 'PersA_FL_ME', 'PFA']\n",
    "num_participants = 14\n",
    "\n",
    "# For exclusion when plotting later on\n",
    "bad_nodes = [1,3,13]\n",
    "\n",
    "with open(path+cond0_filename, 'rb') as fp:\n",
    "    cond0_training_and_labels_lst = pickle.load(fp)\n",
    "\n",
    "D_0_7 = np.random.rand(2,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eefe71",
   "metadata": {},
   "source": [
    "# Testing APFL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed36785",
   "metadata": {},
   "source": [
    "Testing the APFL Implementation\n",
    "> Why does the client and global server need num_steps... is it not just set by the server?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f75f84",
   "metadata": {},
   "source": [
    "Dynamic learning rate, adaptive off; USING REAL HESSIAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aefb6278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0 of 250\n",
      "Round 10 of 250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27592\\4232414121.py\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Round {i} of {big_loop_iters}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mglobal_model_APFL_realhess_noeta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_FL_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"(Current Local Round, Current Local Update)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\fl_sim_classes.py\u001b[0m in \u001b[0;36mexecute_FL_loop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;31m# AKA 50 t's to select new clients.  I'll write it like they did ig...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_client_and_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclient_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchosen_clients_lst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mmy_client\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavailable_clients_lst\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m^\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchosen_clients_lst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                     \u001b[1;31m# Otherwise indices will break when calculating finalized running terms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\fl_sim_classes.py\u001b[0m in \u001b[0;36mtrain_client_and_log\u001b[1;34m(self, client_set)\u001b[0m\n\u001b[0;32m    222\u001b[0m                     \u001b[0mpers_init_carry_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersonalized_error_log\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmy_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;31m#[0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmy_client\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclient_set\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m                 \u001b[0mmy_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_training_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m                 current_local_lst.append((my_client.ID, self.current_round, \n\u001b[0;32m    226\u001b[0m                                           my_client.eval_model(which='local')))\n",
      "\u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\fl_sim_classes.py\u001b[0m in \u001b[0;36mexecute_training_loop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    416\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexecute_training_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulate_data_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;31m# Append (ROUND, COST) to the CLIENT error log\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\fl_sim_classes.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    574\u001b[0m                     \u001b[0meigvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprev_eigvals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Client{self.ID}: Recalculating the Hessian for new update {self.current_update}!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m                     \u001b[0meigvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhessian_cost_l2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malphaD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprev_eigvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meigvals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36meig\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36meig\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m   1302\u001b[0m         _raise_linalgerror_eigenvalues_nonconvergence)\n\u001b[0;32m   1303\u001b[0m     \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D->DD'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'd->DD'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m     \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimag\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "user_c0_APFL_realhess_noeta = [Client(i, D_0_7, 'NAN', cond0_training_and_labels_lst[i], \n",
    "                       'streaming', use_real_hess=True, adaptive=False, \n",
    "                       num_steps=10, global_method='APFL') for i in range(14)]\n",
    "global_model_APFL_realhess_noeta = Server(1, D_0_7, 'APFL', user_c0_APFL_realhess_noeta, num_steps=10)\n",
    "\n",
    "big_loop_iters = 250\n",
    "for i in range(big_loop_iters):\n",
    "    if i%10==0:\n",
    "        print(f\"Round {i} of {big_loop_iters}\")\n",
    "    global_model_APFL_realhess_noeta.execute_FL_loop()\n",
    "    \n",
    "print(\"(Current Local Round, Current Local Update)\")\n",
    "for my_client in global_model_APFL_realhess_noeta.all_clients:\n",
    "    print((my_client.current_round, my_client.current_update))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0623f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_realhess, 'local', global_error=False, dim_reduc_factor=10, show_update_change=False, custom_title='Eta=1e-10 Cost Func')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7a0b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_realhess, 'local', plot_gradient=True, local_error=False, \n",
    "                            global_error=False, show_update_change=False, custom_title='Real Hess Gradient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee96819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e66f1d0f",
   "metadata": {},
   "source": [
    "Learning rate of 1e-10, adaptive off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89320e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_c0_APFL_eta_m10 = [Client(i, D_0_7, 'NAN', cond0_training_and_labels_lst[i], \n",
    "                       'streaming', eta=1e-10, input_eta=True, gradient_clipping=True, adaptive=False, \n",
    "                       num_steps=10, global_method='APFL') for i in range(14)]\n",
    "global_model_APFL_eta_m10 = Server(1, D_0_7, 'APFL', user_c0_APFL_eta_m10, num_steps=10)\n",
    "\n",
    "big_loop_iters = 500\n",
    "for i in range(big_loop_iters):\n",
    "    if i%10==0:\n",
    "        print(f\"Round {i} of {big_loop_iters}\")\n",
    "    global_model_APFL_eta_m10.execute_FL_loop()\n",
    "    \n",
    "print(\"(Current Local Round, Current Local Update)\")\n",
    "for my_client in global_model_APFL_eta_m10.all_clients:\n",
    "    print((my_client.current_round, my_client.current_update))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ca1e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_eta_m10, 'local', global_error=False, dim_reduc_factor=10, show_update_change=False, custom_title='Eta=1e-10 Cost Func')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1502ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_eta_m10, 'local', plot_gradient=True, local_error=False, \n",
    "                            global_error=False, show_update_change=False, custom_title='Eta=1e-10 Gradient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673fb68a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "065beaf4",
   "metadata": {},
   "source": [
    "Safe Learning Rate APFL (Adaptive Off)\n",
    "> Gradient clipping appaers to be failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30000848",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_c0_APFL_slr_15 = [Client(i, D_0_7, 'NAN', cond0_training_and_labels_lst[i], \n",
    "                       'streaming', safe_lr=15, adaptive=False, gradient_clipping=True, num_steps=10, \n",
    "                       global_method='APFL') for i in range(14)]\n",
    "global_model_APFL_slr_15 = Server(1, D_0_7, 'APFL', user_c0_APFL_slr_15, num_steps=10)\n",
    "global_model_APFL_slr_15.execute_FL_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d41f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_loop_iters = 1000\n",
    "for i in range(big_loop_iters):\n",
    "    global_model_APFL_slr_15.execute_FL_loop()\n",
    "    \n",
    "print(\"(Current Local Round, Current Local Update)\")\n",
    "for my_client in global_model_APFL_slr_15.all_clients:\n",
    "    print((my_client.current_round, my_client.current_update))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a9ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_slr_15, 'local', plot_gradient=True, local_error=False, \n",
    "                            global_error=False, show_update_change=False, custom_title='Safe Learning Rate 1/15L Gradient')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fad290",
   "metadata": {},
   "source": [
    "Vanilla APFL\n",
    "> Adaptive is on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154190a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_c0_APFL = [Client(i, D_0_7, 'NAN', cond0_training_and_labels_lst[i], 'streaming', num_steps=10, gradient_clipping=True, global_method='APFL') for i in range(14)]\n",
    "global_model_APFL = Server(1, D_0_7, 'APFL', user_c0_APFL, num_steps=10)\n",
    "global_model_APFL.execute_FL_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843635fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_loop_iters = 1000\n",
    "for i in range(big_loop_iters):\n",
    "    global_model_APFL.execute_FL_loop()\n",
    "    \n",
    "print(\"(Current Local Round, Current Local Update)\")\n",
    "for my_client in global_model_APFL.all_clients:\n",
    "    print((my_client.current_round, my_client.current_update))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6a5854",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL, 'local', plot_gradient=True, local_error=False, \n",
    "                            global_error=False, show_update_change=False, custom_title='Eta=10 Gradient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8195776",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL, 'local', plot_gradient=True, local_error=False,\n",
    "                            global_error=False, show_update_change=False, custom_title='Eta=10 Gradient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9de0e72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a83891",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = global_model_APFL.chosen_clients_lst[0].ID\n",
    "user_c0_APFL[i].personalized_error_log[-1]#[user_c0_APFL[i].ID]#[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da888bc0",
   "metadata": {},
   "source": [
    "^ Int is not subscriptable!\n",
    "> Personalized_error_log is not being updated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e870eb73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eigvals, eigvecs = np.linalg.eig(user_c0_APFL[i].F.T@user_c0_APFL[i].F)\n",
    "eigvals[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd216065",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.amin(eigvals)\n",
    "L = np.amax(eigvals)\n",
    "print(f\"mu: {mu}\")\n",
    "print(f\"L: {L.round(3)}\")\n",
    "if mu.real < 1e-10:\n",
    "    mu = 1e-3\n",
    "    print(f\"New mu: {mu}\")\n",
    "kappa = L/mu\n",
    "print(f\"kappa: {kappa.round(3)}\")\n",
    "\n",
    "# tau is 10 in the above run, for now\n",
    "a = np.max([128*kappa, 10])  # Max works on an array input, not multiple inputs\n",
    "eta_t = 16 / (mu*(1+a))\n",
    "print(f\"a: {a.round(3)}\")\n",
    "print(f\"eta_t: {eta_t.round(6)}\")\n",
    "print(f\"1/2L: {(1/(2*L)).round(6)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07719ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_limit = 1/(2*L)\n",
    "print(lr_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf92d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_lr_limit = 1/(10*L)\n",
    "print(safe_lr_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1bcbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvals_rounded = eigvals.round(7)\n",
    "\n",
    "print(\"10 Eigs\")\n",
    "print(eigvals_rounded[:10])\n",
    "print(\"Mu (min eigval)\")\n",
    "print(np.amin(eigvals_rounded))\n",
    "print(\"L (max eigval)\")\n",
    "print(np.amax(eigvals_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af27275",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvals_inplace = copy.copy(eigvals)\n",
    "eps = 1e-7\n",
    "\n",
    "eigvals_inplace[np.abs(eigvals_inplace) < eps] = 0\n",
    "\n",
    "print(\"10 Eigs\")\n",
    "print(eigvals_inplace[:10])\n",
    "print(\"Mu (min eigval)\")\n",
    "print(np.amin(eigvals_inplace))\n",
    "print(\"L (max eigval)\")\n",
    "print(np.amax(eigvals_inplace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2080968",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvals_ReIm = copy.copy(eigvals)\n",
    "tol = 1e-7\n",
    "\n",
    "eigvals_ReIm.real[abs(eigvals_ReIm.real) < tol] = 0.0\n",
    "eigvals_ReIm.imag[abs(eigvals_ReIm.imag) < tol] = 0.0\n",
    "\n",
    "print(\"10 Eigs\")\n",
    "print(eigvals_ReIm[:10])\n",
    "print(\"Mu (min eigval)\")\n",
    "print(np.amin(eigvals_ReIm))\n",
    "print(\"L (max eigval)\")\n",
    "print(np.amax(eigvals_ReIm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a37a420",
   "metadata": {},
   "source": [
    "Doing the reverse transposed order, this is supposed to be the same FOR REAL SQUARE MATRICES ONLY.  F is not square though..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a700b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eigvals2, eigvecs2 = np.linalg.eig(user_c0_APFL[i].F@user_c0_APFL[i].F.T)\n",
    "mu2 = np.amin(eigvals2)\n",
    "L2 = np.amax(eigvals2)\n",
    "\n",
    "print(f\"First 10 eigs: \\n {eigvals2[:10]}\\n\")\n",
    "print(f\"mu2: {mu2}\")\n",
    "print(f\"L2: {L2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135821d0",
   "metadata": {},
   "source": [
    "Misc stuff idk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe345a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i = 0\n",
    "# This should be the same i as the above loop\n",
    "\n",
    "print(f\"F.shape: {user_c0_APFL[i].F.shape}\")\n",
    "print(f\"Norm: {np.linalg.norm(user_c0_APFL[i].F)}\")\n",
    "print(f\"Sum: {np.sum((user_c0_APFL[i].F))}\")\n",
    "print(f\"**2 Sum: {np.sum((user_c0_APFL[i].F)**2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b2eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "hess = user_c0_APFL[i].F@user_c0_APFL[i].F.T\n",
    "np.linalg.eig(hess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf9a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Decs\")\n",
    "print(user_c0_APFL[i].local_w)\n",
    "print(user_c0_APFL[i].global_w)\n",
    "diff = user_c0_APFL[i].local_w - user_c0_APFL[i].global_w\n",
    "print(diff)\n",
    "print()\n",
    "print(\"Gradient\")\n",
    "out = gradient_cost_l2(user_c0_APFL[i].F, user_c0_APFL[i].mixed_w, user_c0_APFL[i].H, user_c0_APFL[i].V, user_c0_APFL[i].learning_batch, user_c0_APFL[i].alphaF, user_c0_APFL[i].alphaD, Ne=7)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c6ccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.inner(diff.flatten(), out.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaaa051",
   "metadata": {},
   "source": [
    "Look at Vanilla APFL Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3753fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_c0_APFL[0].adap_alpha[:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eae331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F.shape: {user_c0_APFL[0].F.shape}\")\n",
    "print(f\"Norm: {np.linalg.norm(user_c0_APFL[0].F)}\")\n",
    "print(f\"Sum: {np.sum((user_c0_APFL[0].F))}\")\n",
    "print(f\"**2 Sum: {np.sum((user_c0_APFL[0].F)**2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a897f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_c0_APFL[0].local_w)\n",
    "print(user_c0_APFL[0].global_w)\n",
    "diff = user_c0_APFL[0].local_w - user_c0_APFL[0].global_w\n",
    "print(diff)\n",
    "out = gradient_cost_l2(user_c0_APFL[0].F, user_c0_APFL[0].mixed_w, user_c0_APFL[0].H, user_c0_APFL[0].V, user_c0_APFL[0].learning_batch, user_c0_APFL[0].alphaF, user_c0_APFL[0].alphaD, Ne=7)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178e24ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.inner(diff.flatten(), out.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b734b72",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24b97fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL, 'local', pers_error=True, show_update_change=False, custom_title=\"APFL: Global, Local, and Pers Costs Per Iter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4acd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(global_model_APFL, 'global', pers_error=True, show_update_change=False, custom_title=\"APFL: Global and Local Costs Per Iteration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe18b76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL, 'local', plot_gradient=True, local_error=False, global_error=False, show_update_change=False, custom_title='GRADIENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be670f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model_APFL.current_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c0bd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client_loss.append(input_data.global_error_log[j][i][2])\n",
    "len(global_model_APFL.global_error_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ed5a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(global_model_APFL.local_error_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04015e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(global_model_APFL.personalized_error_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4465670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(1==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfff773",
   "metadata": {},
   "source": [
    "# DEVELOPMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e846069e",
   "metadata": {},
   "source": [
    "# Personalized FL Algorithms\n",
    "ALL PERSONALIZATION ALGORITHMS\n",
    "1. APFL\n",
    "1. Cesar/Taha: AFL + PARS-PUSH\n",
    "1. PFA: PP F Adaptation for Effective Model Personalization\n",
    "1. Pers RT FL for Epileptic Seizure Detection\n",
    "1. An Efficient Framework for Clustered FL\n",
    "1. Pers FL with DP\n",
    "## Adaptive Personalized FL Testing Ground"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd91d63",
   "metadata": {},
   "source": [
    "Adapting their code to actually be able to be run in something other than top-down server-only approach\n",
    "> Their Github: https://github.com/MLOPTPSU/FedTorch <br>\n",
    "> APFL link: https://github.com/MLOPTPSU/FedTorch/blob/ab8068dbc96804a5c1a8b898fd115175cfebfe75/fedtorch/comms/trainings/federated/apfl.py#L33\n",
    "\n",
    "loss.backward() computes dloss/dx for every parameter x which has requires_grad=True. These are accumulated into x.grad for every parameter x. Loss.backward() does not update the weights, only computes the gradients.  The graph is used by loss.backward() to compute gradients.  In pseudo-code: x.grad += dloss/dx\n",
    "\n",
    "optimizer.step updates the value of x using the gradient x.grad. For example, the SGD optimizer performs:\n",
    "\n",
    "x += -lr * x.grad\n",
    "optimizer.zero_grad() clears x.grad for every parameter x in the optimizer. It’s important to call this before loss.backward(), otherwise you’ll accumulate the gradients from multiple passes.\n",
    "\n",
    "optimizer.zero_grad() and optimizer.step() do not affect the graph of autograd objects. They only touch the model’s parameters and the parameter’s grad attributes.\n",
    "\n",
    "If you have multiple losses (loss1, loss2) you can sum them and then call backwards once:\n",
    "\n",
    "loss3 = loss1 + loss2\n",
    "loss3.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f1c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python run_mpi.py -f -ft apfl -n 10 -d mnist -lg 0.1 -b 50 -c 20 -k 1.0 -fs local_step -l 10 -r 2 -pa 0.5 -fp\n",
    "#'--num_epochs': args.num_epochs_per_comm * args.num_comms,\n",
    "\n",
    "# num_epochs_per_comm=1\n",
    "# num_clients=20\n",
    "# batch_size=50\n",
    "# num_comms=100\n",
    "# lr_gamma=1.0\n",
    "# lr_mu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16784d97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
