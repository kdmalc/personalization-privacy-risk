{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d17f193d",
   "metadata": {},
   "source": [
    "> __Purpose:__ Implement an initial privacy attack to quantify how much re-identiifcation and linkability risk exists from personalization parameters (the decoder used in the co-adaptation algorithm). Thus, implement a basic ML model to link the decoder matrices back to the corresponding subject.  \n",
    "\n",
    "- This NB is copied from NB107.  \n",
    "- May want to log, save, and write all the decs from NBs 201/202.  \n",
    "- Not sure whether it is worth testing on all conditions (e.g. to generate more training data for this adversarial model). I did so since there were so few instances of each class in the training data otherwise.  Well really each update doesn't matter only the user so maybe I didn't need to do that   \n",
    "- Also should save the models from earlier NBs (102, 104, 106, 107) and see how they perform on this data\n",
    "- Plot adversarial accuracy wrt each local iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a61b3128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "from kcs_ml_infr import *\n",
    "from experiment_params import *\n",
    "from fl_sim_classes import *\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, tree, preprocessing, metrics, linear_model\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Make annoying KNN warning go away since I'm not going to edit scikit learn's code lol\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "random.seed(a=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2b58b",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d53f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\kdmen\\Desktop\\Research\\personalization-privacy-risk\\Data'\n",
    "cond0_filename = r'\\cond0_dict_list.p'\n",
    "all_decs_init_filename = r'\\all_decs_init.p'\n",
    "nofl_decs_filename = r'\\nofl_decs.p'\n",
    "id2color = {0:'lightcoral', 1:'maroon', 2:'chocolate', 3:'darkorange', 4:'gold', 5:'olive', 6:'olivedrab', \n",
    "            7:'lawngreen', 8:'aquamarine', 9:'deepskyblue', 10:'steelblue', 11:'violet', 12:'darkorchid', 13:'deeppink'}\n",
    "implemented_client_training_methods = ['EtaGradStep', 'EtaScipyMinStep', 'FullScipyMinStep']\n",
    "implement_these_methods_next = ['APFL', 'AFL', 'PersA_FL_MAML', 'PersA_FL_ME', 'PFA']\n",
    "num_participants = 14\n",
    "\n",
    "D_0 = np.random.rand(2,64)\n",
    "D_0_7 = np.random.rand(2,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95fa2fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data\\continuous_full_data_block1.pickle', 'rb') as handle:\n",
    "    #refs_block1, poss_block1, dec_vels_block1, int_vel_block1, emgs_block1, Ws_block1, Hs_block1, alphas_block1, pDs_block1, times_block1, conditions_block1 = pickle.load(handle)\n",
    "    refs_block1, _, _, _, emgs_block1, Ws_block1, _, _, _, _, _ = pickle.load(handle)\n",
    "\n",
    "cond1b1_dict_list = [0]*num_participants\n",
    "cond2b1_dict_list = [0]*num_participants\n",
    "cond3b1_dict_list = [0]*num_participants\n",
    "cond4b1_dict_list = [0]*num_participants\n",
    "#cond5b1_dict_list = [0]*num_participants\n",
    "#cond6b1_dict_list = [0]*num_participants\n",
    "#cond7b1_dict_list = [0]*num_participants\n",
    "#cond8b1_dict_list = [0]*num_participants\n",
    "for idx in range(num_participants):\n",
    "    b1_emg = emgs_block1[keys[idx]]\n",
    "    b1_ref = refs_block1[keys[idx]]\n",
    "    cond1b1_dict_list[idx] = {'training':b1_emg[0,:,:], 'labels':b1_ref[0,:,:]}\n",
    "    cond2b1_dict_list[idx] = {'training':b1_emg[1,:,:], 'labels':b1_ref[1,:,:]}\n",
    "    cond3b1_dict_list[idx] = {'training':b1_emg[2,:,:], 'labels':b1_ref[2,:,:]}\n",
    "    cond4b1_dict_list[idx] = {'training':b1_emg[3,:,:], 'labels':b1_ref[3,:,:]}\n",
    "    #cond5b1_dict_list[idx] = {'training':b1_emg[4,:,:], 'labels':b1_ref[4,:,:]}\n",
    "    #cond6b1_dict_list[idx] = {'training':b1_emg[5,:,:], 'labels':b1_ref[5,:,:]}\n",
    "    #cond7b1_dict_list[idx] = {'training':b1_emg[6,:,:], 'labels':b1_ref[6,:,:]}\n",
    "    #cond8b1_dict_list[idx] = {'training':b1_emg[7,:,:], 'labels':b1_ref[7,:,:]}\n",
    "    \n",
    "    cond1b1_AllInitDecs_list = [Ws_block1[keys[i]][0, 0, :, :] for i in range(num_participants)]\n",
    "    cond2b1_AllInitDecs_list = [Ws_block1[keys[i]][1, 0, :, :] for i in range(num_participants)]\n",
    "    cond3b1_AllInitDecs_list = [Ws_block1[keys[i]][2, 0, :, :] for i in range(num_participants)]\n",
    "    cond4b1_AllInitDecs_list = [Ws_block1[keys[i]][3, 0 :, :] for i in range(num_participants)]\n",
    "    #cond5b1_AllInitDecs_list = [Ws_block1[keys[i]][4, 0, :, :] for i in range(num_participants)]\n",
    "    #cond6b1_AllInitDecs_list = [Ws_block1[keys[i]][5, 0, :, :] for i in range(num_participants)]\n",
    "    #cond7b1_AllInitDecs_list = [Ws_block1[keys[i]][6, 0, :, :] for i in range(num_participants)]\n",
    "    #cond8b1_AllInitDecs_list = [Ws_block1[keys[i]][7, 0, :, :] for i in range(num_participants)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3784926",
   "metadata": {},
   "outputs": [],
   "source": [
    "del refs_block1\n",
    "del emgs_block1\n",
    "del Ws_block1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfdb3db",
   "metadata": {},
   "source": [
    "## No-FL Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2e90f4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2436\\1289671525.py\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnum_updates_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m18\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_updates_left\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mglobal_c1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_FL_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mcondensed_external_plotting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musers_c1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'local'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_reduc_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_update_change\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_title\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Using CPHS Init Decs: Client Cost Eval with No FL'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\fl_sim_classes.py\u001b[0m in \u001b[0;36mexecute_FL_loop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m                 \u001b[1;31m# Eg don't do a global-global smoothbatch for the other cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'NoFL'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_client_and_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclient_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_clients\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'APFL'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_round\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\fl_sim_classes.py\u001b[0m in \u001b[0;36mtrain_client_and_log\u001b[1;34m(self, client_set)\u001b[0m\n\u001b[0;32m    213\u001b[0m                 \u001b[0mmy_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m                 \u001b[0mmy_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_training_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m                 current_local_lst.append((my_client.ID, self.current_round, \n\u001b[0;32m    217\u001b[0m                                           my_client.eval_model(which='local')))\n",
      "\u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\fl_sim_classes.py\u001b[0m in \u001b[0;36mexecute_training_loop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexecute_training_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulate_data_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m         \u001b[1;31m# LOG EVERYTHING\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\fl_sim_classes.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    615\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_eta_scipyminstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malphaF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malphaD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPCA_comps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPCA_comps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'FullScipyMinStep'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_eta_scipyminstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malphaF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malphaD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPCA_comps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPCA_comps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unrecognized method\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\fl_sim_classes.py\u001b[0m in \u001b[0;36mtrain_eta_scipyminstep\u001b[1;34m(self, w, eta, F, D, H, V, learning_batch, alphaF, alphaD, D0, display_info, PCA_comps, full)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# I turned off display_info because it's kind of annoying\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfull\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcost_l2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malphaF\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malphaD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPCA_comps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'BFGS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgradient_cost_l2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malphaF\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malphaD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPCA_comps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#, options={'disp': display_info})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcost_l2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malphaF\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malphaD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPCA_comps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'BFGS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgradient_cost_l2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malphaF\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malphaD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPCA_comps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'maxiter'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0meta\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#'disp': display_info,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    610\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'bfgs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         return _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_minimize_bfgs\u001b[1;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m   1173\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdisp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Divide-by-zero encountered: rhok assumed large\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m         \u001b[0mA1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mI\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0myk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrhok\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1176\u001b[0m         \u001b[0mA2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mI\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0myk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrhok\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         Hk = np.dot(A1, np.dot(Hk, A2)) + (rhok * sk[:, np.newaxis] *\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "users_c1 = [Client(i, cond1b1_AllInitDecs_list[i], 'FullScipyMinStep', cond1b1_dict_list[i], 'advance_each_iter', global_method='NoFL', track_cost_components=True, normalize_EMG=False, PCA_comps=64, delay_scaling=0) for i in range(14)]\n",
    "global_c1 = Server(-1, D_0, 'NoFL', users_c1, PCA_comps=64)\n",
    "\n",
    "num_updates_left = 18\n",
    "for i in range(num_updates_left):\n",
    "    global_c1.execute_FL_loop()\n",
    "    \n",
    "condensed_external_plotting(users_c1, 'local', global_error=False, dim_reduc_factor=1, show_update_change=False, custom_title='Using CPHS Init Decs: Client Cost Eval with No FL')\n",
    "condensed_external_plotting(users_c1, 'local', plot_gradient=True, dim_reduc_factor=1, local_error=False, global_error=False, show_update_change=False, custom_title='GRADIENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c529ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_c2 = [Client(i, cond2b1_AllInitDecs_list[i], 'FullScipyMinStep', cond2b1_dict_list[i], 'advance_each_iter', global_method='NoFL', track_cost_components=True, normalize_EMG=False, PCA_comps=64, condition_number=2, delay_scaling=0) for i in range(14)]\n",
    "global_c2 = Server(-1, D_0, 'NoFL', users_c2, PCA_comps=64)\n",
    "\n",
    "users_c3 = [Client(i, cond3b1_AllInitDecs_list[i], 'FullScipyMinStep', cond3b1_dict_list[i], 'advance_each_iter', global_method='NoFL', track_cost_components=True, normalize_EMG=False, PCA_comps=64, condition_number=3, delay_scaling=0) for i in range(14)]\n",
    "global_c3 = Server(-1, D_0, 'NoFL', users_c3, PCA_comps=64)\n",
    "\n",
    "users_c4 = [Client(i, cond4b1_AllInitDecs_list[i], 'FullScipyMinStep', cond4b1_dict_list[i], 'advance_each_iter', global_method='NoFL', track_cost_components=True, normalize_EMG=False, PCA_comps=64, condition_number=4, delay_scaling=0) for i in range(14)]\n",
    "global_c4 = Server(-1, D_0, 'NoFL', users_c4, PCA_comps=64)\n",
    "\n",
    "#users_c5 = [Client(i, cond5b1_AllInitDecs_list[i], 'FullScipyMinStep', cond5b1_dict_list[i], 'advance_each_iter', global_method='NoFL', track_cost_components=True, normalize_EMG=False, PCA_comps=64, condition_number=5, delay_scaling=0) for i in range(14)]\n",
    "#global_c5 = Server(-1, D_0, 'NoFL', users_c5, PCA_comps=64)\n",
    "#\n",
    "#users_c6 = [Client(i, cond6b1_AllInitDecs_list[i], 'FullScipyMinStep', cond6b1_dict_list[i], 'advance_each_iter', global_method='NoFL', track_cost_components=True, normalize_EMG=False, PCA_comps=64, condition_number=6, delay_scaling=0) for i in range(14)]\n",
    "#global_c6 = Server(-1, D_0, 'NoFL', users_c6, PCA_comps=64)\n",
    "#\n",
    "#users_c7 = [Client(i, cond7b1_AllInitDecs_list[i], 'FullScipyMinStep', cond7b1_dict_list[i], 'advance_each_iter', global_method='NoFL', track_cost_components=True, normalize_EMG=False, PCA_comps=64, condition_number=7, delay_scaling=0) for i in range(14)]\n",
    "#global_c7 = Server(-1, D_0, 'NoFL', users_c7, PCA_comps=64)\n",
    "#\n",
    "#users_c8 = [Client(i, cond8b1_AllInitDecs_list[i], 'FullScipyMinStep', cond8b1_dict_list[i], 'advance_each_iter', global_method='NoFL', track_cost_components=True, normalize_EMG=False, PCA_comps=64, condition_number=8, delay_scaling=0) for i in range(14)]\n",
    "#global_c8 = Server(-1, D_0, 'NoFL', users_c8, PCA_comps=64)\n",
    "\n",
    "num_updates_left = 19\n",
    "for i in range(num_updates_left):\n",
    "    global_c2.execute_FL_loop()\n",
    "    global_c3.execute_FL_loop()\n",
    "    global_c4.execute_FL_loop()\n",
    "    #global_c5.execute_FL_loop()\n",
    "    #global_c6.execute_FL_loop()\n",
    "    #global_c7.execute_FL_loop()\n",
    "    #global_c8.execute_FL_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fb330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "dec_flattened1 = pd.DataFrame(columns=['Subject', 'Update Number', 'Flattened Dec'])\n",
    "dec_flattened2 = pd.DataFrame(columns=['Subject', 'Update Number', 'Flattened Dec'])\n",
    "dec_flattened3 = pd.DataFrame(columns=['Subject', 'Update Number', 'Flattened Dec'])\n",
    "dec_flattened4 = pd.DataFrame(columns=['Subject', 'Update Number', 'Flattened Dec'])\n",
    "#dec_flattened5 = pd.DataFrame(columns=['Subject', 'Update Number', 'Flattened Dec'])\n",
    "#dec_flattened6 = pd.DataFrame(columns=['Subject', 'Update Number', 'Flattened Dec'])\n",
    "#dec_flattened7 = pd.DataFrame(columns=['Subject', 'Update Number', 'Flattened Dec'])\n",
    "#dec_flattened8 = pd.DataFrame(columns=['Subject', 'Update Number', 'Flattened Dec'])\n",
    "#my_cond = 1\n",
    "for key_idx, key in enumerate(keys):\n",
    "    for update_number, update_idx in enumerate(update_ix):\n",
    "        dec_flattened1.loc[len(dec_flattened1)] = [key, update_number, np.ravel(users_c1[key_idx].dec_log[update_number])]\n",
    "        dec_flattened2.loc[len(dec_flattened2)] = [key, update_number, np.ravel(users_c2[key_idx].dec_log[update_number])]\n",
    "        dec_flattened3.loc[len(dec_flattened3)] = [key, update_number, np.ravel(users_c3[key_idx].dec_log[update_number])]\n",
    "        dec_flattened4.loc[len(dec_flattened4)] = [key, update_number, np.ravel(users_c4[key_idx].dec_log[update_number])]\n",
    "        #dec_flattened5.loc[len(dec_flattened5)] = [key, update_number, np.ravel(users_c5[key_idx].dec_log[update_number])]\n",
    "        #dec_flattened6.loc[len(dec_flattened6)] = [key, update_number, np.ravel(users_c6[key_idx].dec_log[update_number])]\n",
    "        #dec_flattened7.loc[len(dec_flattened7)] = [key, update_number, np.ravel(users_c7[key_idx].dec_log[update_number])]\n",
    "        #dec_flattened8.loc[len(dec_flattened8)] = [key, update_number, np.ravel(users_c8[key_idx].dec_log[update_number])]        \n",
    "t1 = time.time()\n",
    "total = t1-t0  \n",
    "print(total)\n",
    "\n",
    "# Concat all the dfs into a single training input dataframe\n",
    "#dec_flattened = pd.concat([dec_flattened1, dec_flattened2, dec_flattened3, dec_flattened4, dec_flattened5, dec_flattened6, dec_flattened7, dec_flattened8], ignore_index=True, axis=0)\n",
    "dec_flattened = pd.concat([dec_flattened1, dec_flattened2, dec_flattened3, dec_flattened4], ignore_index=True, axis=0)\n",
    "#dec_flattened = pd.concat([dec_flattened1, dec_flattened2], ignore_index=True, axis=0)\n",
    "\n",
    "# Take the keys (key_to_num for label) as label df\n",
    "flat_dec_labels = pd.DataFrame(dec_flattened['Subject'].apply(lambda x: key_to_num[x]))\n",
    "\n",
    "print(dec_flattened.shape)\n",
    "display(dec_flattened.head())\n",
    "display(flat_dec_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a094d605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30a949a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84b31d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4898ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = [list(range(x, x+4)) for x in (3,4,5,6)]\n",
    "lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e486d9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': [3,4,5,6], 'B': lists})\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964bf519",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['B'].apply(pd.Series).add_prefix('col_')\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f42ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(columns=['B']).join(df['B'].apply(pd.Series).add_prefix('col_'))\n",
    "df2.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef2962e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f8f81d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dec_flattened.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdacc376",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dps = 4\n",
    "\n",
    "rounded_df = pd.DataFrame(dec_flattened['Flattened Dec']).apply(lambda x: [np.round(ele, num_dps) for ele in x])\n",
    "rounded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1932d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_flattened2 = rounded_df.drop(columns=['Subject', 'Update Number']).join(rounded_df['Flattened Dec'].apply(pd.Series))#.add_prefix('col_'))\n",
    "dec_flattened2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce797fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90d61d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bb885f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138d600e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66626f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d6d69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21e323c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fdc133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c772f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dps = 4\n",
    "\n",
    "rounded_df = pd.DataFrame(dec_flattened['Flattened Dec']).apply(lambda x: [np.round(ele, num_dps) for ele in x])\n",
    "rounded_df.head()\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "expanded_dec_df = pd.DataFrame()\n",
    "\n",
    "# Break up list so that every element is its own cell (col)\n",
    "for my_row in range(rounded_df.shape[0]):\n",
    "    test=pd.DataFrame(rounded_df.iloc[my_row,0]).T\n",
    "    expanded_dec_df = pd.concat((expanded_dec_df, test))\n",
    "expanded_dec_df.reset_index(inplace=True, drop=True)\n",
    "expanded_dec_df.insert(loc=0, column='Update Number', value=list(dec_flattened['Update Number']))\n",
    "#expanded_dec_df.insert(loc=0, column='Condition', value=list(dec_flattened['Condition']))\n",
    "expanded_dec_df.insert(loc=0, column='Subject', value=list(dec_flattened['Subject']))\n",
    "    \n",
    "print(expanded_dec_df.shape)\n",
    "expanded_dec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08c13b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226198b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd63d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5308583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_dec_df = pd.DataFrame()\n",
    "\n",
    "# Break up list so that every element is its own cell (col)\n",
    "for my_row in range(dec_flattened.shape[0]):\n",
    "    test=pd.DataFrame(dec_flattened.iloc[my_row,2]).T\n",
    "    expanded_dec_df = pd.concat((expanded_dec_df, test))\n",
    "expanded_dec_df.reset_index(inplace=True, drop=True)\n",
    "expanded_dec_df.insert(loc=0, column='Update Number', value=list(dec_flattened['Update Number']))\n",
    "#expanded_dec_df.insert(loc=0, column='Condition', value=list(dec_flattened['Condition']))\n",
    "expanded_dec_df.insert(loc=0, column='Subject', value=list(dec_flattened['Subject']))\n",
    "    \n",
    "print(expanded_dec_df.shape)\n",
    "expanded_dec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ffb7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.sum(expanded_dec_df.isnull().values)==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a850bb15",
   "metadata": {},
   "source": [
    "# Adversarial Model Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f141f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_models = [LogisticRegression(), KNeighborsClassifier(), GradientBoostingClassifier()]\n",
    "my_models = [LogisticRegression(), KNeighborsClassifier(), LinearSVC(), SGDClassifier(), DecisionTreeClassifier(), GradientBoostingClassifier()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e76ca5",
   "metadata": {},
   "source": [
    "# Concat All 19 Update Model Results\n",
    "> Should I be trying to use the same model but predicting on different datasets too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b04f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_update_models(flattened_input_df, my_metrics_columns=['Algorithm', 'One Off Acc', 'CV Acc', 'K Folds'], my_models_list=[LogisticRegression(), KNeighborsClassifier(), GaussianNB(), LinearSVC(), SGDClassifier(), DecisionTreeClassifier(), GradientBoostingClassifier()], make_df=True, full_test_df=pd.DataFrame()):\n",
    "\n",
    "    if make_df:\n",
    "        full_test_df = pd.DataFrame(columns=my_metrics_columns)\n",
    "\n",
    "    for i in range(19):\n",
    "        print(f\"{i} of {19}\")\n",
    "        ith_df, ith_test_df = nth_decoder_model(flattened_input_df, i, my_models_list, test=True)\n",
    "\n",
    "        full_test_df = pd.concat((full_test_df, ith_test_df))\n",
    "\n",
    "    full_test_df.drop('K Folds', axis=1, inplace=True)\n",
    "    full_test_df.drop('One Off Acc', axis=1, inplace=True)\n",
    "    full_test_df.drop('CV Acc', axis=1, inplace=True)\n",
    "\n",
    "    return full_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7e4f41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_test_df = make_all_update_models(expanded_dec_df)\n",
    "full_test_df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7023c06b",
   "metadata": {},
   "source": [
    "## Plot Accuracy As a Func of N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_lr_df = full_pos_test_df[full_pos_test_df['Algorithm']=='LogisticRegression()']\n",
    "pos_knn_df = full_pos_test_df[full_pos_test_df['Algorithm']=='KNeighborsClassifier()']\n",
    "pos_svc_df = full_pos_test_df[full_pos_test_df['Algorithm']=='LinearSVC()']\n",
    "pos_sgd_df = full_pos_test_df[full_pos_test_df['Algorithm']=='SGDClassifier()']\n",
    "pos_dt_df = full_pos_test_df[full_pos_test_df['Algorithm']=='DecisionTreeClassifier()']\n",
    "pos_gbt_df = full_pos_test_df[full_pos_test_df['Algorithm']=='GradientBoostingClassifier()']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb3414b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "skip_block = 0\n",
    "col_num = 1\n",
    "my_x_updates = list(range(19))[skip_block:]\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.plot(my_x_updates, pos_lr_df.iloc[skip_block:, col_num], label='LogReg')\n",
    "plt.plot(my_x_updates, pos_knn_df.iloc[skip_block:, col_num], label='KNN')\n",
    "plt.plot(my_x_updates, pos_svc_df.iloc[skip_block:, col_num], label='SVC')\n",
    "plt.plot(my_x_updates, pos_sgd_df.iloc[skip_block:, col_num], label='SGD')\n",
    "plt.plot(my_x_updates, pos_dt_df.iloc[skip_block:, col_num], label='DTree')\n",
    "plt.plot(my_x_updates, pos_gbt_df.iloc[skip_block:, col_num], label='GBC')\n",
    "plt.xticks(np.arange(0, 19, 1.0))\n",
    "plt.yticks(np.arange(0, 120, 20.0))\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Update Number')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.title('POSITIVE INIT: Model Accuracy as a function of Decoder Update Number')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69121c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_lr_df = full_neg_test_df[full_neg_test_df['Algorithm']=='LogisticRegression()']\n",
    "neg_knn_df = full_neg_test_df[full_neg_test_df['Algorithm']=='KNeighborsClassifier()']\n",
    "neg_svc_df = full_neg_test_df[full_neg_test_df['Algorithm']=='LinearSVC()']\n",
    "neg_sgd_df = full_neg_test_df[full_neg_test_df['Algorithm']=='SGDClassifier()']\n",
    "neg_dt_df = full_neg_test_df[full_neg_test_df['Algorithm']=='DecisionTreeClassifier()']\n",
    "neg_gbt_df = full_neg_test_df[full_neg_test_df['Algorithm']=='GradientBoostingClassifier()']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb0ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_gbt_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4757a45c",
   "metadata": {},
   "source": [
    "Now plot for negative init case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fa299d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "skip_block = 0\n",
    "col_num = 1\n",
    "my_x_updates = list(range(19))[skip_block:]\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.plot(my_x_updates, neg_lr_df.iloc[skip_block:, col_num], label='LogReg')\n",
    "plt.plot(my_x_updates, neg_knn_df.iloc[skip_block:, col_num], label='KNN')\n",
    "plt.plot(my_x_updates, neg_svc_df.iloc[skip_block:, col_num], label='SVC')\n",
    "plt.plot(my_x_updates, neg_sgd_df.iloc[skip_block:, col_num], label='SGD')\n",
    "plt.plot(my_x_updates, neg_dt_df.iloc[skip_block:, col_num], label='DTree')\n",
    "plt.plot(my_x_updates, neg_gbt_df.iloc[skip_block:, col_num], label='GBC')\n",
    "plt.xticks(np.arange(0, 19, 1.0))\n",
    "plt.yticks(np.arange(0, 120, 20.0))\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Update Number')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.title('NEGATIVE INIT: Model Accuracy as a function of Decoder Update Number')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe9836a",
   "metadata": {},
   "source": [
    "Accuracies get considerably worse.  From the original (NB 104), we had the following:\n",
    "- SVC: 80\n",
    "- LR: 70\n",
    "- KNN: 57\n",
    "- GBC: 53\n",
    "- DTree: 38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95e7f7b",
   "metadata": {},
   "source": [
    "However, this is of course a caveat here: when we split the data into the pos and neg condition dfs, we therefore trained the models with half as much data as they otherwise wouldv'e had (as compared to NB 104 for instance which had the entire dataset to train on).  So let's rerun the NB 104 code using just a random 50% of the full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be97d36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Shuffle the DF\n",
    "full_dec_df = pd.concat((neg_dec_expanded_df, neg_dec_expanded_df))\n",
    "shuffled_dec_df = full_dec_df.sample(frac=1)\n",
    "print(shuffled_dec_df.shape)\n",
    "shuffled_dec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb286f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "half_df = shuffled_dec_df.iloc[shuffled_dec_df.shape[0]//2:, :]\n",
    "print(half_df.shape)\n",
    "half_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495effbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "half_df, half_test_df = nth_decoder_model(half_df, 18, my_models, test=True)\n",
    "half_test_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eeb1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "half_test_df.iloc[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f99c1f",
   "metadata": {},
   "source": [
    "When comparing to the test accuracies all the graphs and testing dataframes, notice that this final performance is actually still better for all models, which was unexpected (especially for KNN!).  E.g. we observe that splitting into positive and negative conditions (initializations) does NOT actually improve the capabilities of an adverary, as the adversary's ML model performs better when just a random sample of all data is taken.\n",
    "> A smaller caveat here is that we only tested one random sample of the data, so perhaps this was just a \"good\" initialization of random training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db351e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd1ed76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09c1667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76722b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, X_val, y_val = train_test_val_split(dec_flattened, flat_dec_labels)\n",
    "y_train = np.ravel(y_train)\n",
    "\n",
    "print(f\"Original dataset shape: {dec_flattened.shape}\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "X_train.head()\n",
    "\n",
    "X_train2 = pd.DataFrame()\n",
    "X_test2 = pd.DataFrame()\n",
    "\n",
    "# Break up list so that every element is its own cell\n",
    "for my_row in range(X_train.shape[0]):\n",
    "    test=pd.DataFrame(X_train.iloc[my_row,2]).T\n",
    "    X_train2 = pd.concat((X_train2, test))\n",
    "    \n",
    "for my_row in range(X_test.shape[0]):\n",
    "    test=pd.DataFrame(X_test.iloc[my_row,2]).T\n",
    "    X_test2 = pd.concat((X_test2, test))\n",
    "    \n",
    "# Convert from strings to floats... not sure if this matters\n",
    "X_train = X_train2.apply(pd.to_numeric)\n",
    "X_test = X_test2.apply(pd.to_numeric)\n",
    "    \n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da8eece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9cb230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce7e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1 Scipy Step\n",
    "\n",
    "user_c0_1ScipyStep = [Client(i, D_0_7, 'EtaScipyMinStep', cond0_training_and_labels_lst[i], 'streaming', delay_scaling=0, verbose=True) for i in range(14)]\n",
    "global_model_1scipystep = Server(1, D_0_7, 'FedAvg', user_c0_1ScipyStep)\n",
    "\n",
    "big_loop_iters = 1000\n",
    "for i in range(big_loop_iters):\n",
    "    global_model_1scipystep.execute_FL_loop()\n",
    "    \n",
    "print(\"(Current Local Round, Current Local Update)\")\n",
    "for my_client in global_model_1scipystep.all_clients:\n",
    "    print((my_client.current_round, my_client.current_update))\n",
    "    \n",
    "condensed_external_plotting(user_c0_1ScipyStep, 'local', custom_title='1 SciPy Step: Global and Local Costs Per Iteration')\n",
    "condensed_external_plotting(global_model_1scipystep, 'global', show_update_change=False, custom_title='1 SciPy Step: Global and Local Costs Per Iteration')\n",
    "condensed_external_plotting(user_c0_1ScipyStep, 'local', dim_reduc_factor=1, plot_gradient=True, local_error=False, global_error=False, custom_title='DRF=1[Off]: GRADIENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9177b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
