{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebafe6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "from kcs_ml_infr import *\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, tree, preprocessing, metrics, linear_model\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Make annoying KNN warning go away since I'm not going to edit scikit learn's code lol\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "random.seed(a=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49d61e0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\kdmen\\\\Desktop\\\\Research\\\\Data\\\\continuous_full_data_block1.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mkdmen\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mResearch\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#with open(path + r'\\cphs_data_block1.pickle', 'rb') as handle:\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mcontinuous_full_data_block1.pickle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m#refs_block1, poss_block1, dec_vels_block1, int_vel_block1, emgs_block1, Ws_block1, Hs_block1, alphas_block1, pDs_block1, times_block1, conditions_block1 = pickle.load(handle)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     _, _, _, _, _, Ws_block1, _, _, _, _, _ \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(handle)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#with open(path + r'\\cphs_data_block2.pickle', 'rb') as handle:\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\fl_torch\\lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\kdmen\\\\Desktop\\\\Research\\\\Data\\\\continuous_full_data_block1.pickle'"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\kdmen\\Desktop\\Research\\Data'\n",
    "\n",
    "#with open(path + r'\\cphs_data_block1.pickle', 'rb') as handle:\n",
    "with open(path + r'\\continuous_full_data_block1.pickle', 'rb') as handle:\n",
    "    #refs_block1, poss_block1, dec_vels_block1, int_vel_block1, emgs_block1, Ws_block1, Hs_block1, alphas_block1, pDs_block1, times_block1, conditions_block1 = pickle.load(handle)\n",
    "    _, _, _, _, _, Ws_block1, _, _, _, _, _ = pickle.load(handle)\n",
    "\n",
    "#with open(path + r'\\cphs_data_block2.pickle', 'rb') as handle:\n",
    "with open(path + r'\\continuous_full_data_block2.pickle', 'rb') as handle:\n",
    "    #refs_block2, poss_block2, dec_vels_block2, int_vel_block2, emgs_block2, Ws_block2, Hs_block2, alphas_block2, pDs_block2, times_block2, conditions_block2 = pickle.load(handle)\n",
    "    _, _, _, _, _, Ws_block2, _, _, _, _, _ = pickle.load(handle)\n",
    "    \n",
    "update_ix = np.load(path+r\"\\update_ix.npy\")\n",
    "print(update_ix.shape)\n",
    "print(update_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2bf5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_num = dict()\n",
    "num_to_key = dict()\n",
    "for idx, key in enumerate(keys):\n",
    "    key_to_num[key] = idx\n",
    "    num_to_key[idx] = key\n",
    "    \n",
    "cv = 5\n",
    "my_metrics_cols = ['Algorithm', 'One Off Acc', 'CV Acc', 'K Folds']\n",
    "my_models = [LogisticRegression(), KNeighborsClassifier(), LinearSVC(), DecisionTreeClassifier(), GradientBoostingClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da905ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = keys[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c5498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_conds = 8\n",
    "dec_flattened_df1 = pd.DataFrame(columns=[\"Subject\", \"Condition\", \"Update Number\", \"Flattened Decoder\"])\n",
    "dec_flattened_df2 = pd.DataFrame(columns=[\"Subject\", \"Condition\", \"Update Number\", \"Flattened Decoder\"])\n",
    "\n",
    "for key in keys:\n",
    "    participant_dec1 = Ws_block1[key]\n",
    "    participant_dec2 = Ws_block2[key]\n",
    "    \n",
    "    for my_cond in range(num_conds):\n",
    "        for update_number, update_idx in enumerate(update_ix):\n",
    "            dec_flattened_df1.loc[len(dec_flattened_df1)] = [key, my_cond, update_number, np.ravel(participant_dec1[my_cond, update_idx, :, :])]\n",
    "            dec_flattened_df2.loc[len(dec_flattened_df2)] = [key, my_cond, update_number, np.ravel(participant_dec2[my_cond, update_idx, :, :])]\n",
    "        \n",
    "dec_flattened_df = pd.concat((dec_flattened_df1, dec_flattened_df2))\n",
    "\n",
    "print(dec_flattened_df.shape)\n",
    "dec_flattened_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e96309",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dec_expanded_df = pd.DataFrame()\n",
    "for my_row in range(dec_flattened_df.shape[0]):\n",
    "    test=pd.DataFrame(dec_flattened_df.iloc[my_row,3]).T\n",
    "    flat_dec_expanded_df = pd.concat((flat_dec_expanded_df, test))\n",
    "\n",
    "flat_dec_expanded_df.reset_index(inplace=True, drop=True)\n",
    "flat_dec_expanded_df.insert(loc=0, column='Update Number', value=list(dec_flattened_df['Update Number']))\n",
    "flat_dec_expanded_df.insert(loc=0, column='Condition', value=list(dec_flattened_df['Condition']))\n",
    "flat_dec_expanded_df.insert(loc=0, column='Subject', value=list(dec_flattened_df['Subject']))\n",
    "\n",
    "print(flat_dec_expanded_df.shape)\n",
    "flat_dec_expanded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626d7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dec_expanded_df.columns = flat_dec_expanded_df.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b200e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_df, zero_test_df = nth_decoder_model(flat_dec_expanded_df, 0, my_models, test=True)\n",
    "zero_test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d761f18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_metrics_cols=['Algorithm', 'One Off Acc', 'CV Acc', 'K Folds']\n",
    "key_to_num_dict=key_to_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ae266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "nth_update_idxs = flat_dec_expanded_df[~(flat_dec_expanded_df['Update Number'] == n)].index\n",
    "dec0_df = flat_dec_expanded_df.drop(nth_update_idxs)\n",
    "dec0_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1\n",
    "nth_update_idxs = flat_dec_expanded_df[~(flat_dec_expanded_df['Update Number'] == n)].index\n",
    "dec1_df = flat_dec_expanded_df.drop(nth_update_idxs)\n",
    "dec1_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa009a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=2\n",
    "nth_update_idxs = flat_dec_expanded_df[~(flat_dec_expanded_df['Update Number'] == n)].index\n",
    "dec2_df = flat_dec_expanded_df.drop(nth_update_idxs)\n",
    "dec2_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c317e63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_df, zero_test_df = nth_decoder_model(flat_dec_expanded_df, 0, my_models, test=True)\n",
    "zero_test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ca6984",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)\n",
    "one_df, one_test_df = nth_decoder_model(flat_dec_expanded_df, 1, my_models, test=True)\n",
    "two_df, two_test_df = nth_decoder_model(flat_dec_expanded_df, 2, my_models, test=True)\n",
    "three_df, three_test_df = nth_decoder_model(flat_dec_expanded_df, 3, my_models, test=True)\n",
    "four_df, four_test_df = nth_decoder_model(flat_dec_expanded_df, 4, my_models, test=True)\n",
    "five_df, five_test_df = nth_decoder_model(flat_dec_expanded_df, 5, my_models, test=True)\n",
    "six_df, six_test_df = nth_decoder_model(flat_dec_expanded_df, 6, my_models, test=True)\n",
    "print(7)\n",
    "seven_df, seven_test_df = nth_decoder_model(flat_dec_expanded_df, 7, my_models, test=True)\n",
    "eight_df, eight_test_df = nth_decoder_model(flat_dec_expanded_df, 8, my_models, test=True)\n",
    "nine_df, nine_test_df = nth_decoder_model(flat_dec_expanded_df, 9, my_models, test=True)\n",
    "ten_df, ten_test_df = nth_decoder_model(flat_dec_expanded_df, 10, my_models, test=True)\n",
    "ele_df, ele_test_df = nth_decoder_model(flat_dec_expanded_df, 11, my_models, test=True)\n",
    "print(12)\n",
    "twe_df, twe_test_df = nth_decoder_model(flat_dec_expanded_df, 12, my_models, test=True)\n",
    "thirt_df, thirt_test_df = nth_decoder_model(flat_dec_expanded_df, 13, my_models, test=True)\n",
    "frtn_df, frtn_test_df = nth_decoder_model(flat_dec_expanded_df, 14, my_models, test=True)\n",
    "fftn_df, fftn_test_df = nth_decoder_model(flat_dec_expanded_df, 15, my_models, test=True)\n",
    "sixtn_df, sixtn_test_df = nth_decoder_model(flat_dec_expanded_df, 16, my_models, test=True)\n",
    "svntn_df, svntn_test_df = nth_decoder_model(flat_dec_expanded_df, 17, my_models, test=True)\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d366494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eightn_df, eightn_test_df = nth_decoder_model(flat_dec_expanded_df, 18, my_models, test=True)\n",
    "eightn_test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4183fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_df = pd.concat((zero_test_df, one_test_df, two_test_df, three_test_df, four_test_df, \n",
    "           five_test_df, six_test_df, seven_test_df, eight_test_df, nine_test_df, \n",
    "           ten_test_df, ele_test_df, twe_test_df, thirt_test_df, frtn_test_df, \n",
    "           fftn_test_df, sixtn_test_df, svntn_test_df, eightn_test_df))\n",
    "\n",
    "full_test_df.drop('K Folds', axis=1, inplace=True)\n",
    "print(full_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05405f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_df = full_test_df[full_test_df['Algorithm']=='LogisticRegression()']\n",
    "knn_df = full_test_df[full_test_df['Algorithm']=='KNeighborsClassifier()']\n",
    "svc_df = full_test_df[full_test_df['Algorithm']=='LinearSVC()']\n",
    "dt_df = full_test_df[full_test_df['Algorithm']=='DecisionTreeClassifier()']\n",
    "gbt_df = full_test_df[full_test_df['Algorithm']=='GradientBoostingClassifier()']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1a54d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,7))\n",
    "plt.plot(list(range(19)), lr_df.iloc[:, 2], label='LogReg')\n",
    "plt.plot(list(range(19)), knn_df.iloc[:, 2], label='KNN')\n",
    "plt.plot(list(range(19)), svc_df.iloc[:, 2], label='SVC')\n",
    "plt.plot(list(range(19)), dt_df.iloc[:, 2], label='DTree')\n",
    "plt.plot(list(range(19)), gbt_df.iloc[:, 2], label='GBC')\n",
    "plt.xticks(np.arange(0, 19, 1.0))\n",
    "plt.yticks(np.arange(0, 120, 20.0))\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Update Number')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.title('Model Accuracy as a function of Decoder Update Number')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ffc4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_x_updates = list(range(19))[2:]\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.plot(my_x_updates, lr_df.iloc[2:, 2], label='LogReg')\n",
    "plt.plot(my_x_updates, knn_df.iloc[2:, 2], label='KNN')\n",
    "plt.plot(my_x_updates, svc_df.iloc[2:, 2], label='SVC')\n",
    "plt.plot(my_x_updates, dt_df.iloc[2:, 2], label='DTree')\n",
    "plt.plot(my_x_updates, gbt_df.iloc[2:, 2], label='GBC')\n",
    "plt.xticks(np.arange(2, 19, 1.0))\n",
    "plt.yticks(np.arange(0, 120, 20.0))\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Update Number')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.title('Model Accuracy as a function of Decoder Update Number')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc56b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(1==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a730d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model dfs so I don't have to rerun all this code\n",
    "lr_df.to_pickle(r\"Saved_Metrics\\104P_full_lr_df.pkl\")\n",
    "knn_df.to_pickle(r\"Saved_Metrics\\104P_full_knn_df.pkl\")\n",
    "svc_df.to_pickle(r\"Saved_Metrics\\104P_full_svc_df.pkl\")\n",
    "dt_df.to_pickle(r\"Saved_Metrics\\104P_full_dt_df.pkl\")\n",
    "gbt_df.to_pickle(r\"Saved_Metrics\\104P_full_gbt_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542cab61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
