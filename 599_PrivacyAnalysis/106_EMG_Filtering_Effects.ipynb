{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d17f193d",
   "metadata": {},
   "source": [
    "> __Purpose:__ Implement an initial privacy attack to quantify how much re-identiifcation and linkability risk exists from  filtered EMG data (should be highly unique). Thus, implement a basic ML model to link the EMG data back to the corresponding subject.  \n",
    "\n",
    "-- 7 Subjects, therefore pure guessing would be 14.28% correct on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a61b3128",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#import seaborn as sns\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpresentation_sns_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkcs_ml_infr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\599_PrivacyAnalysis\\presentation_sns_config.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#_new_black = '#373737'\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from presentation_sns_config import *\n",
    "import pandas as pd\n",
    "from kcs_ml_infr import *\n",
    "from experiment_params import *\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Make annoying KNN warning go away since I'm not going to edit scikit learn's code lol\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813563cf",
   "metadata": {},
   "source": [
    "# Filtered EMG Data Privacy Evaluation\n",
    ">Linking EMG Data to Participants\n",
    "1. Does the channel matter / improve performance? Within the same block (assuming different blocks have the strap re-put on) then presumably the same muscles should act in similar ways.  __Just do PCA on it and don't worry about it__\n",
    "2. Does the condition matter? Presumably, but the question is how much.  __Only look at condition for conditions that changed performance (eg learning rate speed)__\n",
    "3. Ways to compress the input data: PCA/LDA/nonlinearversion, or norms of the vectors... is it even necessary / beneficial to performance.  __Focus on just PCA for now__\n",
    "4. __No standard scaler since negative filtered EMG data has no meaning__\n",
    "1. Actually, do NMF instead of PCA since PCA can result in negative values which don't have any meaning for EMG data\n",
    "\n",
    "## 1) Create Envelope of Filtered EMG Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6331b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dont rerun this code since it's already been done and also takes forever\n",
    "if 0:\n",
    "    t0 = time.time()\n",
    "\n",
    "    emg_data_df1 = pd.read_csv(\"Data\\emg_full_data1.csv\")\n",
    "    emg_labels_df1 = pd.read_csv(\"Data\\emg_full_labels1.csv\")\n",
    "    emg_data_df2 = pd.read_csv(\"Data\\emg_full_data2.csv\")\n",
    "    emg_labels_df2 = pd.read_csv(\"Data\\emg_full_labels2.csv\")\n",
    "\n",
    "    t1 = time.time()\n",
    "    total = t1-t0  \n",
    "    print(total)\n",
    "\n",
    "    emg_data_df = pd.concat((emg_data_df1, emg_data_df2))\n",
    "    emg_labels_df = pd.concat((emg_labels_df1, emg_labels_df2))\n",
    "    emg_data_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    emg_labels_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    labels_df = pd.DataFrame(emg_labels_df['Subject'].map(key_to_num))\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    plt.plot(emg_data_df.iloc[0, :])\n",
    "    plt.show()\n",
    "\n",
    "    t1 = time.time()\n",
    "    total = t1-t0  \n",
    "    print(total)\n",
    "\n",
    "    # Do a crude moving average with no overlap\n",
    "    envelope_df50 = emg_data_df.groupby(np.arange(len(emg_data_df.columns))//50, axis=1).mean()\n",
    "    envelope_df100 = emg_data_df.groupby(np.arange(len(emg_data_df.columns))//100, axis=1).mean()\n",
    "    envelope_df150 = emg_data_df.groupby(np.arange(len(emg_data_df.columns))//150, axis=1).mean()\n",
    "    envelope_df200 = emg_data_df.groupby(np.arange(len(emg_data_df.columns))//200, axis=1).mean()\n",
    "    envelope_df250 = emg_data_df.groupby(np.arange(len(emg_data_df.columns))//250, axis=1).mean()\n",
    "    envelope_df300 = emg_data_df.groupby(np.arange(len(emg_data_df.columns))//250, axis=1).mean()\n",
    "\n",
    "    envelope_df50.to_csv(\"Data\\envelope_df50.csv\")\n",
    "    envelope_df100.to_csv(\"Data\\envelope_df100.csv\")\n",
    "    envelope_df150.to_csv(\"Data\\envelope_df150.csv\")\n",
    "    envelope_df200.to_csv(\"Data\\envelope_df200.csv\")\n",
    "    envelope_df250.to_csv(\"Data\\envelope_df250.csv\")\n",
    "    envelope_df300.to_csv(\"Data\\envelope_df300.csv\")\n",
    "\n",
    "    # This is substantially different than the original lol\n",
    "    plt.plot(envelope_df100.iloc[0, :])\n",
    "    plt.xlabel(\"Downsampled Time\")\n",
    "    plt.ylabel(\"EMG Reading\")\n",
    "    plt.title(\"Smoothed EMG Data (100 ms windows)\")\n",
    "    plt.show()\n",
    "\n",
    "    ex = emg_data_df.iloc[0, :].rolling(window=100).mean().dropna().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a850bb15",
   "metadata": {},
   "source": [
    "# Load In Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a97330",
   "metadata": {},
   "source": [
    "Load in the other data\n",
    "> This cell takes ~2 minutes to run as a heads up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b50886",
   "metadata": {},
   "outputs": [],
   "source": [
    "emg_labels_df1 = pd.read_csv(\"Data\\emg_full_labels1.csv\")\n",
    "emg_labels_df2 = pd.read_csv(\"Data\\emg_full_labels2.csv\")\n",
    "emg_labels_df = pd.concat((emg_labels_df1, emg_labels_df2))\n",
    "\n",
    "try:\n",
    "    emg_labels_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "except:\n",
    "    # Masterful code here\n",
    "    print(\"NO UNNAMED COLUMN DETECTED!\")\n",
    "\n",
    "print(emg_labels_df.shape)\n",
    "emg_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204c1691",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.DataFrame(emg_labels_df['Subject'].map(key_to_num))\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979df175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below needs to be run on raw EMG data not the filtered data.  Don't waste time running it again\n",
    "assert(1==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb204dc",
   "metadata": {},
   "source": [
    "# Filtered EMG Data Privacy Evaluation\n",
    ">Linking EMG Data to Participants\n",
    "1. Does the channel matter / improve performance? Within the same block (assuming different blocks have the strap re-put on) then presumably the same muscles should act in similar ways.  __Just do PCA on it and don't worry about it__\n",
    "2. Does the condition matter? Presumably, but the question is how much.  __Only look at condition for conditions that changed performance (eg learning rate speed)__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6433b2",
   "metadata": {},
   "source": [
    "## Load the Envelopes of Filtered EMG Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be26eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "envelope_df50 = pd.read_csv(\"C:\\\\Users\\\\kdmen\\\\Desktop\\\\Research\\\\Data\\\\envelope_df50.csv\")\n",
    "envelope_df100 = pd.read_csv(\"C:\\\\Users\\\\kdmen\\\\Desktop\\\\Research\\\\Data\\\\envelope_df100.csv\")\n",
    "envelope_df150 = pd.read_csv(\"C:\\\\Users\\\\kdmen\\\\Desktop\\\\Research\\\\Data\\\\envelope_df150.csv\")\n",
    "envelope_df200 = pd.read_csv(\"C:\\\\Users\\\\kdmen\\\\Desktop\\\\Research\\\\Data\\\\envelope_df200.csv\")\n",
    "envelope_df250 = pd.read_csv(\"C:\\\\Users\\\\kdmen\\\\Desktop\\\\Research\\\\Data\\\\envelope_df250.csv\")\n",
    "envelope_df300 = pd.read_csv(\"C:\\\\Users\\\\kdmen\\\\Desktop\\\\Research\\\\Data\\\\envelope_df300.csv\")\n",
    "\n",
    "raw_envs = [envelope_df50, envelope_df100, envelope_df150, envelope_df200, envelope_df250, envelope_df300]\n",
    "all_envs = [env.drop('Unnamed: 0', axis=1) for env in raw_envs]\n",
    "\n",
    "print(\"100\")\n",
    "print(all_envs[1].shape)\n",
    "all_envs[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c7f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(envelope_df100.iloc[0, :])\n",
    "plt.xlabel(\"Downsampled Time\")\n",
    "plt.ylabel(\"EMG Reading\")\n",
    "plt.title(\"Smoothed EMG Data (100 ms windows)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1388f6",
   "metadata": {},
   "source": [
    "# Make ML Model Attack\n",
    "> Trying without doing any sample reduction just to see if the run times are bearable... if so, then maybe don't need to do any PCA and can save myself the trouble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1243befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, tree, preprocessing, metrics, linear_model\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b319090",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_models = [LogisticRegression(), KNeighborsClassifier(), LinearSVC(), SGDClassifier(), DecisionTreeClassifier(), GradientBoostingClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e10d6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_envs_res_df = pd.DataFrame()\n",
    "\n",
    "for idx, my_env_df in enumerate(all_envs):\n",
    "    print(f\"Envelope: {idx+1} of {len(all_envs)}\")\n",
    "    X_train, y_train, X_test, y_test, X_val, y_val = train_test_val_split(my_env_df, labels_df, stratification=False)\n",
    "    y_train = np.ravel(y_train)\n",
    "\n",
    "    print(\"X_train\")\n",
    "    print(X_train.shape)\n",
    "    #display(X_train.head())\n",
    "    \n",
    "    for model_num, model in enumerate(my_models):\n",
    "        print(f\"Model: {model_num+1} of {len(my_models)}\")\n",
    "        all_envs_res_df = train_model(model, X_train, y_train, cv, all_envs_res_df)\n",
    "\n",
    "all_envs_res_df.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476f9526",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_envs_res_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9d4b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(columns=['Algorithm', 'CV Acc', 'Test Acc', 'K Folds'])\n",
    "\n",
    "# THIS DOES NOT ITER THROUGH ALL ENVELOPES RIGHT NOW\n",
    "for model_num, model in enumerate(my_models):\n",
    "    test_df = test_model(model, X_train, y_train, X_test, y_test, test_df, cv)\n",
    "    \n",
    "test_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e98c0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_envs_res_df.reset_index(inplace=True)\n",
    "all_envs_res_df.drop('index', axis=1, inplace=True)\n",
    "all_envs_res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edad12c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not plotting all 7 model right now\n",
    "lr_df = all_envs_res_df[all_envs_res_df['Algorithm']=='LogisticRegression()']\n",
    "knn_df = all_envs_res_df[all_envs_res_df['Algorithm']=='KNeighborsClassifier()']\n",
    "svc_df = all_envs_res_df[all_envs_res_df['Algorithm']=='LinearSVC()']\n",
    "dt_df = all_envs_res_df[all_envs_res_df['Algorithm']=='DecisionTreeClassifier()']\n",
    "gbt_df = all_envs_res_df[all_envs_res_df['Algorithm']=='GradientBoostingClassifier()']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e67b975",
   "metadata": {},
   "outputs": [],
   "source": [
    "envir_list = [50, 100, 150, 200, 250, 300]\n",
    "my_x_updates = envir_list\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.plot(my_x_updates, lr_df.iloc[:, 2], label='LogReg')\n",
    "plt.plot(my_x_updates, knn_df.iloc[:, 2], label='KNN')\n",
    "plt.plot(my_x_updates, svc_df.iloc[:, 2], label='SVC')\n",
    "plt.plot(my_x_updates, dt_df.iloc[:, 2], label='DTree')\n",
    "plt.plot(my_x_updates, gbt_df.iloc[:, 2], label='GBC')\n",
    "\n",
    "plt.scatter(my_x_updates, lr_df.iloc[:, 2])#, label='LogReg')\n",
    "plt.scatter(my_x_updates, knn_df.iloc[:, 2])#, label='KNN')\n",
    "plt.scatter(my_x_updates, svc_df.iloc[:, 2])#, label='SVC')\n",
    "plt.scatter(my_x_updates, dt_df.iloc[:, 2])#, label='DTree')\n",
    "plt.scatter(my_x_updates, gbt_df.iloc[:, 2])#, label='GBC')\n",
    "plt.yticks(np.arange(0, 120, 20.0))\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Filtering Window Size (ms)')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.title('Adversary Linkage Capability as a function of Filtering Window Size')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a5399",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "envir_list = [50, 100, 150, 200, 250, 300]\n",
    "my_x_updates = envir_list\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.plot(my_x_updates, lr_df.iloc[:, 2], label='LogReg')\n",
    "plt.plot(my_x_updates, knn_df.iloc[:, 2], label='KNN')\n",
    "plt.plot(my_x_updates, svc_df.iloc[:, 2], label='SVC')\n",
    "plt.plot(my_x_updates, dt_df.iloc[:, 2], label='DTree')\n",
    "plt.plot(my_x_updates, gbt_df.iloc[:, 2], label='GBC')\n",
    "\n",
    "plt.scatter(my_x_updates, lr_df.iloc[:, 2])#, label='LogReg')\n",
    "plt.scatter(my_x_updates, knn_df.iloc[:, 2])#, label='KNN')\n",
    "plt.scatter(my_x_updates, svc_df.iloc[:, 2])#, label='SVC')\n",
    "plt.scatter(my_x_updates, dt_df.iloc[:, 2])#, label='DTree')\n",
    "plt.scatter(my_x_updates, gbt_df.iloc[:, 2])#, label='GBC')\n",
    "plt.yticks(np.arange(40, 120, 20.0))\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Filtering Window Size (ms)')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.title('Adversary Linkage Capability as a function of Filtering Window Size')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d668a6",
   "metadata": {},
   "source": [
    "This is about what we would expect, although there is significant variation between models.  Generally, a smaller filtering window acts as less dimensionality reduction, and therefore the most information is preserved.  High filtering windows get rid of the most information and thus should have the lowest accuracies.  Perhaps we ought to test the decoder accuracy with differing window sizes, but I think that would be difficult to verify given the co-adaptive nature of the signal collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(1==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7db8f0",
   "metadata": {},
   "source": [
    "## Investigate How Performance Changes Per Update\n",
    "> E.g. as we use later intervals (note, not more intervals, just the later ones), does the EMG performance linking improve? Intuitively it should not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc209b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(update_ix)\n",
    "print()\n",
    "\n",
    "# Scale update_ix to be for the new envelope_df, as it is currently meant for the original dataset\n",
    "env_update_ix = np.array(np.ceil(update_ix/20770*envelope_df.shape[1]), dtype='int')\n",
    "print(env_update_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554fc945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nth_emg_model(nth_emg_df, emg_label_df, n, my_models, my_metrics_cols=['Algorithm', 'One Off Acc', 'CV Acc', 'K Folds', 'N'], cv=5, test=True):\n",
    "    ''''''\n",
    "\n",
    "    X_train, y_train, X_test, y_test, X_val, y_val = train_test_val_split(nth_emg_df, emg_label_df)\n",
    "    y_train = np.ravel(y_train)\n",
    "\n",
    "    dec_res_df = pd.DataFrame(columns=my_metrics_cols)\n",
    "    #print(\"TRAINING\")\n",
    "    for model_num, model in enumerate(my_models):\n",
    "        #print(f\"{model_num} of {len(my_models)}\")\n",
    "        dec_res_df = train_model(model, X_train, y_train, cv, dec_res_df, dec_num=n)\n",
    "        \n",
    "    test_df = pd.DataFrame(columns=['Algorithm', 'CV Acc', 'Test Acc', 'K Folds'])\n",
    "    if test:\n",
    "        #print(\"TESTING\")\n",
    "        for model in my_models:\n",
    "            #print(f\"{model_num} of {len(my_models)}\")\n",
    "            test_df = test_model(model, X_train, y_train, X_test, y_test, test_df, cv, dec_num=n)\n",
    "            \n",
    "    return dec_res_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24806a1",
   "metadata": {},
   "source": [
    "This cell also takes forever to run too lol\n",
    "> ONLY 18 updates because here we have to take full intervals as opposed to just grabbing the value at the update time (19 update indices and thus 18 intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05123a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(columns=['Algorithm', 'One Off Acc', 'CV Acc', 'K Folds', 'N'])\n",
    "test_df.head()\n",
    "\n",
    "for i in range(19):\n",
    "    print(f\"{i} of 18\")\n",
    "    if i==18:\n",
    "        pass\n",
    "    else:\n",
    "        current_emg_df = envelope_df.iloc[:, env_update_ix[i]:env_update_ix[i+1]]\n",
    "        current_dec_res_df, current_test_df = nth_emg_model(current_emg_df, labels_df, i, my_models, test=True)\n",
    "        test_df = pd.concat((test_df, current_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea8d055",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ce747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_df = test_df[test_df['Algorithm']=='LogisticRegression()']\n",
    "knn_df = test_df[test_df['Algorithm']=='KNeighborsClassifier()']\n",
    "svc_df = test_df[test_df['Algorithm']=='LinearSVC()']\n",
    "dt_df = test_df[test_df['Algorithm']=='DecisionTreeClassifier()']\n",
    "gbt_df = test_df[test_df['Algorithm']=='GradientBoostingClassifier()']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daceb3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,7))\n",
    "plt.plot(list(range(18)), lr_df.iloc[:, 5], label='LogReg')\n",
    "plt.plot(list(range(18)), knn_df.iloc[:, 5], label='KNN')\n",
    "plt.plot(list(range(18)), svc_df.iloc[:, 5], label='SVC')\n",
    "plt.plot(list(range(18)), dt_df.iloc[:, 5], label='DTree')\n",
    "plt.plot(list(range(18)), gbt_df.iloc[:, 5], label='GBC')\n",
    "plt.xticks(np.arange(0, 19, 1.0))\n",
    "plt.yticks(np.arange(0, 120, 20.0))\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Update Number')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.title('Model Accuracy as a function of EMG Update Interval')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeebb7e",
   "metadata": {},
   "source": [
    "Note the massive drop at the last update is because the last update is not the same size as the rest of the updates, it is much smaller and thus the drop in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977b6cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
