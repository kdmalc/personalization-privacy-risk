{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d39628",
   "metadata": {},
   "source": [
    "__Purpose:__ Introduce Personalized Federated Learning, specifically by implementing APFL on our dataset and then trying other methods.\n",
    "<br>\n",
    "1. We are still assuming we can test on the second half (updates 10-19ish) since (human/co-adaptive) learning should be complete by then!  For reasons shown in earlier NBs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f00b7cb",
   "metadata": {},
   "source": [
    "Adapting their code to actually be able to be run in something other than top-down server-only approach\n",
    "> Their Github: https://github.com/MLOPTPSU/FedTorch <br>\n",
    "> APFL link: https://github.com/MLOPTPSU/FedTorch/blob/ab8068dbc96804a5c1a8b898fd115175cfebfe75/fedtorch/comms/trainings/federated/apfl.py#L33\n",
    "\n",
    "loss.backward() computes dloss/dx for every parameter x which has requires_grad=True. These are accumulated into x.grad for every parameter x. Loss.backward() does not update the weights, only computes the gradients.  The graph is used by loss.backward() to compute gradients.  In pseudo-code: x.grad += dloss/dx\n",
    "\n",
    "optimizer.step updates the value of x using the gradient x.grad. For example, the SGD optimizer performs:\n",
    "\n",
    "x += -lr * x.grad\n",
    "optimizer.zero_grad() clears x.grad for every parameter x in the optimizer. It’s important to call this before loss.backward(), otherwise you’ll accumulate the gradients from multiple passes.\n",
    "\n",
    "optimizer.zero_grad() and optimizer.step() do not affect the graph of autograd objects. They only touch the model’s parameters and the parameter’s grad attributes.\n",
    "\n",
    "If you have multiple losses (loss1, loss2) you can sum them and then call backwards once:\n",
    "\n",
    "loss3 = loss1 + loss2\n",
    "loss3.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2f09a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "import copy\n",
    "\n",
    "from experiment_params import *\n",
    "from cost_funcs import *\n",
    "from fl_sim_classes import *\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9450bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\kdmen\\Desktop\\Research\\personalization-privacy-risk\\Data'\n",
    "cond0_filename = r'\\cond0_dict_list.p'\n",
    "all_decs_init_filename = r'\\all_decs_init.p'\n",
    "nofl_decs_filename = r'\\nofl_decs.p'\n",
    "id2color = {0:'lightcoral', 1:'maroon', 2:'chocolate', 3:'darkorange', 4:'gold', 5:'olive', 6:'olivedrab', \n",
    "            7:'lawngreen', 8:'aquamarine', 9:'deepskyblue', 10:'steelblue', 11:'violet', 12:'darkorchid', 13:'deeppink'}\n",
    "implemented_client_training_methods = ['EtaGradStep', 'EtaScipyMinStep', 'FullScipyMinStep']\n",
    "implement_these_methods_next = ['APFL', 'AFL', 'PersA_FL_MAML', 'PersA_FL_ME', 'PFA']\n",
    "num_participants = 14\n",
    "\n",
    "# For exclusion when plotting later on\n",
    "bad_nodes = [1,3,13]\n",
    "\n",
    "with open(path+cond0_filename, 'rb') as fp:\n",
    "    cond0_training_and_labels_lst = pickle.load(fp)\n",
    "\n",
    "D_0_7 = np.random.rand(2,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eefe71",
   "metadata": {},
   "source": [
    "# Testing APFL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed36785",
   "metadata": {},
   "source": [
    "Testing the APFL Implementation\n",
    "> Why does the client and global server need num_steps... is it not just set by the server?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f75f84",
   "metadata": {},
   "source": [
    "Dynamic learning rate, adaptive off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aefb6278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0 of 250\n",
      "Round 10 of 250\n",
      "Round 20 of 250\n",
      "Round 30 of 250\n",
      "Round 40 of 250\n",
      "Round 50 of 250\n",
      "Round 60 of 250\n",
      "Round 70 of 250\n",
      "Round 80 of 250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22372\\2364629787.py\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Round {i} of {big_loop_iters}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mglobal_model_APFL_realhess_noeta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_FL_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\fl_sim_classes.py\u001b[0m in \u001b[0;36mexecute_FL_loop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[1;31m# AKA 50 t's to select new clients.  I'll write it like they did ig...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_client_and_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclient_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchosen_clients_lst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mmy_client\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavailable_clients_lst\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m^\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchosen_clients_lst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                     \u001b[1;31m# Otherwise indices will break when calculating finalized running terms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\fl_sim_classes.py\u001b[0m in \u001b[0;36mtrain_client_and_log\u001b[1;34m(self, client_set)\u001b[0m\n\u001b[0;32m    214\u001b[0m                 \u001b[0mmy_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                 \u001b[0mmy_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_training_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m                 current_local_lst.append((my_client.ID, self.current_round, \n\u001b[0;32m    218\u001b[0m                                           my_client.eval_model(which='local')))\n",
      "\u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\fl_sim_classes.py\u001b[0m in \u001b[0;36mexecute_training_loop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexecute_training_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulate_data_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[1;31m# LOG EVERYTHING\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\fl_sim_classes.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    670\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_real_hess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m                     \u001b[0meigvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhessian_cost_l2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malphaD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprev_eigvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meigvals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatest_global_round\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_transition_log\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36meig\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36meig\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m   1302\u001b[0m         _raise_linalgerror_eigenvalues_nonconvergence)\n\u001b[0;32m   1303\u001b[0m     \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D->DD'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'd->DD'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m     \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimag\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "user_c0_APFL_realhess_noeta = [Client(i, np.random.rand(2,7), 'NAN', cond0_training_and_labels_lst[i], \n",
    "                       'streaming', adaptive=False, \n",
    "                       num_steps=10, global_method='APFL') for i in range(14)]\n",
    "global_model_APFL_realhess_noeta = Server(1, np.random.rand(2,7), 'APFL', user_c0_APFL_realhess_noeta)\n",
    "\n",
    "big_loop_iters = 250\n",
    "for i in range(big_loop_iters):\n",
    "    if i%10==0:\n",
    "        print(f\"Round {i} of {big_loop_iters}\")\n",
    "    global_model_APFL_realhess_noeta.execute_FL_loop()\n",
    "    \n",
    "print()\n",
    "print(\"(Current Local Round, Current Local Update)\")\n",
    "for my_client in global_model_APFL_realhess_noeta.all_clients:\n",
    "    print((my_client.current_round, my_client.current_update))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbddaf27",
   "metadata": {},
   "source": [
    "Note that graphs don't start at zero because we do dim reduc which essentially shaves (averages) points off the start and end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0623f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_realhess_noeta, 'local', global_error=False, dim_reduc_factor=10, show_update_change=False, custom_title='Cost Func')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7a0b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_realhess_noeta, 'local', plot_gradient=True, local_error=False, \n",
    "                            global_error=False, show_update_change=False, custom_title='Local Gradient When Using Real Hessian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2550cf09",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_realhess_noeta, 'local', plot_global_gradient=True, local_error=False, \n",
    "                            global_error=False, show_update_change=False, custom_title='Global Gradient When Using Real Hessian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0b4f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_realhess_noeta, 'local', plot_pers_gradient=True, local_error=False, \n",
    "                            global_error=False, show_update_change=False, custom_title='Personalized Gradient When Using Real Hessian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd53a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "u0 = user_c0_APFL_realhess_noeta[0]\n",
    "print(\"Local vs Personalized Gradient\")\n",
    "print(np.array(u0.gradient_log) - np.array(u0.pers_gradient_log))\n",
    "print(\"\\nLocal vs Global Gradient\")\n",
    "print(np.array(u0.gradient_log) - np.array(u0.global_gradient_log))\n",
    "print(\"\\nPers vs Global Gradient\")\n",
    "print(np.array(u0.pers_gradient_log) - np.array(u0.global_gradient_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe83744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(u0.mu_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d8ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(u0.L_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f5437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(u0.eta_t_log, label='Dynamic LR')\n",
    "plt.plot(1/(2*np.array(u0.L_log)), label='Upper bound')\n",
    "plt.title(\"Used learning rate vs safe theoretical max\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b20942",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(user_c0_APFL_realhess_noeta)):\n",
    "    u0 = user_c0_APFL_realhess_noeta[i]\n",
    "    plt.plot(u0.eta_t_log, color='blue', label='Dynamic LR')\n",
    "    plt.plot(1/(2*np.array(u0.L_log)), color='red', label='Upper bound')\n",
    "plt.title(\"Used learning rate vs safe theoretical max\")\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32e6d74",
   "metadata": {},
   "source": [
    "Clearly, we are well within the safe learning rate limit. Let's try setting the adaptive mixing parameter and see if that helps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68607d7c",
   "metadata": {},
   "source": [
    "Dynamic learning rate, adaptive ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dee599",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "user_c0_APFL_realhess_adapt = [Client(i, np.random.rand(2,7), 'NAN', cond0_training_and_labels_lst[i], \n",
    "                       'streaming', adaptive=True, \n",
    "                       num_steps=10, global_method='APFL') for i in range(14)]\n",
    "global_model_APFL_realhess_adapt = Server(1, np.random.rand(2,7), 'APFL', user_c0_APFL_realhess_adapt)\n",
    "\n",
    "big_loop_iters = 250\n",
    "for i in range(big_loop_iters):\n",
    "    if i%10==0:\n",
    "        print(f\"Round {i} of {big_loop_iters}\")\n",
    "    global_model_APFL_realhess_adapt.execute_FL_loop()\n",
    "    \n",
    "print()\n",
    "print(\"(Current Local Round, Current Local Update)\")\n",
    "for my_client in global_model_APFL_realhess_adapt.all_clients:\n",
    "    print((my_client.current_round, my_client.current_update))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c816da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_realhess_adapt, 'local', global_error=False, dim_reduc_factor=10, show_update_change=False, custom_title='(Adaptive) Cost Func')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6866b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_realhess_adapt, 'local', plot_gradient=True, local_error=False, \n",
    "                            global_error=False, show_update_change=False, custom_title='(Adaptive) Gradient When Using Real Hessian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32275329",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(user_c0_APFL_realhess_adapt)):\n",
    "    u0 = user_c0_APFL_realhess_adapt[i]\n",
    "    plt.plot(u0.eta_t_log, color='blue', label='Dynamic LR')\n",
    "    plt.plot(1/(2*np.array(u0.L_log)), color='red', label='Upper bound')\n",
    "plt.title(\"Used learning rate vs safe theoretical max\")\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de183da1",
   "metadata": {},
   "source": [
    "LR (eta) = 0.001, adaptive off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfa0819",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_c0_APFL_eta_001 = [Client(i, D_0_7, 'NAN', cond0_training_and_labels_lst[i], \n",
    "                       'streaming', eta=0.001, input_eta=True, gradient_clipping=True, adaptive=False, \n",
    "                       num_steps=10, global_method='APFL') for i in range(14)]\n",
    "global_model_APFL_eta_001 = Server(1, D_0_7, 'APFL', user_c0_APFL_eta_001)\n",
    "\n",
    "big_loop_iters = 250\n",
    "for i in range(big_loop_iters):\n",
    "    if i%10==0:\n",
    "        print(f\"Round {i} of {big_loop_iters}\")\n",
    "    global_model_APFL_eta_001.execute_FL_loop()\n",
    "    \n",
    "print(\"(Current Local Round, Current Local Update)\")\n",
    "for my_client in global_model_APFL_eta_001.all_clients:\n",
    "    print((my_client.current_round, my_client.current_update))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a62e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_eta_001, 'local', global_error=False, dim_reduc_factor=10, show_update_change=False, custom_title='Cost Func')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1ecb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_eta_001, 'local', plot_gradient=True, local_error=False, \n",
    "                            global_error=False, show_update_change=False, custom_title='Local Gradient, Eta=0.001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8755983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_eta_001, 'local', plot_global_gradient=True, local_error=False, \n",
    "                            global_error=False, show_update_change=False, custom_title='Global Gradient, Eta=0.001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b1b1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_eta_001, 'local', plot_pers_gradient=True, local_error=False, \n",
    "                            global_error=False, show_update_change=False, custom_title='Personalized Gradient, Eta=0.001')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d978c78",
   "metadata": {},
   "source": [
    "LR (eta) = 1e-7, adaptive off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249c235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_c0_APFL_eta_em7 = [Client(i, D_0_7, 'NAN', cond0_training_and_labels_lst[i], \n",
    "                       'streaming', eta=1e-7, input_eta=True, gradient_clipping=True, adaptive=False, \n",
    "                       num_steps=10, global_method='APFL') for i in range(14)]\n",
    "global_model_APFL_eta_em7 = Server(1, D_0_7, 'APFL', user_c0_APFL_eta_em7)\n",
    "\n",
    "big_loop_iters = 250\n",
    "for i in range(big_loop_iters):\n",
    "    if i%10==0:\n",
    "        print(f\"Round {i} of {big_loop_iters}\")\n",
    "    global_model_APFL_eta_em7.execute_FL_loop()\n",
    "    \n",
    "print(\"(Current Local Round, Current Local Update)\")\n",
    "for my_client in global_model_APFL_eta_em7.all_clients:\n",
    "    print((my_client.current_round, my_client.current_update))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee089d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_eta_em7, 'local', global_error=False, dim_reduc_factor=10, show_update_change=False, custom_title='Cost Func')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc049269",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_eta_em7, 'local', plot_gradient=True, local_error=False, \n",
    "                            global_error=False, show_update_change=False, custom_title='Local Gradient, Eta=1e-7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf683eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_eta_em7, 'local', plot_global_gradient=True, local_error=False, \n",
    "                            global_error=False, show_update_change=False, custom_title='Global Gradient, Eta=1e-7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995a5c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_eta_em7, 'local', plot_pers_gradient=True, local_error=False, \n",
    "                            global_error=False, show_update_change=False, custom_title='Personalized Gradient, Eta=1e-7')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b196cbe",
   "metadata": {},
   "source": [
    "LR (eta) = 1e-10, adaptive off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde69a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_c0_APFL_eta_em10 = [Client(i, D_0_7, 'NAN', cond0_training_and_labels_lst[i], \n",
    "                       'streaming', eta=1e-10, input_eta=True, gradient_clipping=True, adaptive=False, \n",
    "                       num_steps=10, global_method='APFL') for i in range(14)]\n",
    "global_model_APFL_eta_em10 = Server(1, D_0_7, 'APFL', user_c0_APFL_eta_em10, num_steps=10)\n",
    "\n",
    "big_loop_iters = 250\n",
    "for i in range(big_loop_iters):\n",
    "    if i%10==0:\n",
    "        print(f\"Round {i} of {big_loop_iters}\")\n",
    "    global_model_APFL_eta_em10.execute_FL_loop()\n",
    "    \n",
    "print(\"(Current Local Round, Current Local Update)\")\n",
    "for my_client in global_model_APFL_eta_em10.all_clients:\n",
    "    print((my_client.current_round, my_client.current_update))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d330f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_eta_em10, 'local', global_error=False, dim_reduc_factor=10, show_update_change=False, custom_title='Cost Func')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_eta_em10, 'local', plot_gradient=True, local_error=False, \n",
    "                            global_error=False, show_update_change=False, custom_title='Local Gradient, Eta=1e-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdf215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_eta_em10, 'local', plot_global_gradient=True, local_error=False, \n",
    "                            global_error=False, show_update_change=False, custom_title='Global Gradient, Eta=1e-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a97ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_external_plotting(user_c0_APFL_eta_em10, 'local', plot_pers_gradient=True, local_error=False, \n",
    "                            global_error=False, show_update_change=False, custom_title='Personalized Gradient, Eta=1e-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16784d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5827e3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827dd502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9520eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fcbf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "central_tendency_plotting(all_user_input, highlight_default=False, default_local=False, default_global=False, default_pers=False, plot_mean=True, plot_gradient=False, global_error=False, local_error=False, pers_error=True, custom_title=\"\", input_linewidth=1, my_legend_loc='best', iterable_labels=[], iterable_colors=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc695fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "central_tendency_plotting(all_user_input, highlight_default=False, default_local=False, default_global=False, default_pers=False, plot_mean=True, plot_gradient=False, global_error=False, local_error=False, pers_error=True, custom_title=\"\", input_linewidth=1, my_legend_loc='best', iterable_labels=[], iterable_colors=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d696e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
