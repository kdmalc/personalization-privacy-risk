{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5add6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from flcore.pflniid_utils.data_utils import read_client_data\n",
    "from flcore.clients.clientavg import clientAVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1413334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import logging\n",
    "from flcore.servers.serveravg import FedAvg\n",
    "from flcore.servers.serverlocal import Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55f6ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.custom_loss_class import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "528b9fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\kdmen\\Desktop\\Research\\personalization-privacy-risk\\Data'\n",
    "cond0_filename = r'\\cond0_dict_list.p'\n",
    "with open(path+cond0_filename, 'rb') as fp:\n",
    "    cond0_training_and_labels_lst = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea3a4ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_ix = np.load(r\"..\\Data\\update_ix.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c3884e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cond0_training_and_labels_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40e3e29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20770, 64)\n",
      "(20770, 2)\n"
     ]
    }
   ],
   "source": [
    "print(cond0_training_and_labels_lst[0]['training'].shape)\n",
    "print(cond0_training_and_labels_lst[0]['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1da64c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_emg=False\n",
    "pca_channels=64\n",
    "device_channels=64\n",
    "dt=1/60\n",
    "normalize_V=False\n",
    "\n",
    "my_model = torch.nn.Linear(64, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd553bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_temp = torch.tensor(cond0_training_and_labels_lst[0]['training'][:update_ix[1], :], dtype=torch.float32)\n",
    "p_reference = torch.transpose(torch.tensor(cond0_training_and_labels_lst[0]['labels'][:update_ix[1], :]), 0, 1)\n",
    "\n",
    "# First, normalize the entire s matrix\n",
    "if normalize_emg:\n",
    "    s_normed = s_temp / torch.linalg.norm(s_temp, ord='fro')\n",
    "    assert (torch.linalg.norm(s_normed, ord='fro')<1.2) and (torch.linalg.norm(s_normed, ord='fro')>0.8)\n",
    "else:\n",
    "    s_normed = s_temp\n",
    "# Apply PCA if applicable\n",
    "if pca_channels!=device_channels:  # 64 is the number of channels present on the recording armband\n",
    "    pca = PCA(n_components=pca_channels)\n",
    "    s = torch.transpose(torch.tensor(pca.fit_transform(s_normed), dtype=torch.float32), 0, 1)\n",
    "else:\n",
    "    s = torch.transpose(s_normed, 0, 1)\n",
    "\n",
    "F = s[:,:-1]\n",
    "v_actual =  torch.matmul(my_model.weight, s)\n",
    "p_actual = torch.cumsum(v_actual, dim=1)*dt  # Numerical integration of v_actual to get p_actual\n",
    "V = (p_reference - p_actual)*dt\n",
    "if normalize_V:\n",
    "    V = V/torch.linalg.norm(V, ord='fro')\n",
    "    assert (torch.linalg.norm(V, ord='fro')<1.2) and (torch.linalg.norm(V, ord='fro')>0.8)\n",
    "Y = p_reference[:, :-1]  # To match the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06320bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1199])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6db291db",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = CPHSLoss(F, my_model.weight, V, F.size()[1], \n",
    "                     lambdaF=0, lambdaD=1e-3, lambdaE=1e-4, \n",
    "                     Nd=2, Ne=64, return_cost_func_comps=True)\n",
    "loss_log = []\n",
    "running_epoch_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bae47cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: LambdaE*Error_Norm^2: 178.27844634683584\n",
      "D: LambdaD*Decoder_Norm^2: 0.0006647210102528334\n",
      "F: LambdaF*EMG_Norm^2: 0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#print(f\"clientAVG ----> Training LOSS {i}\")  # What is this even tellimg me lol\u001b[39;00m\n\u001b[0;32m     11\u001b[0m my_loss \u001b[38;5;241m=\u001b[39m loss(output, y, my_model)\n\u001b[1;32m---> 12\u001b[0m loss_log\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmy_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m())\n\u001b[0;32m     13\u001b[0m running_num_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "running_num_samples = 0\n",
    "x = torch.transpose(F,0,1)\n",
    "y = torch.transpose(Y,0,1)\n",
    "#if type(x) == type([]):\n",
    "#    x[0] = x[0].to(self.device)\n",
    "#else:\n",
    "#    x = x.to(self.device)\n",
    "#y = y.to(self.device)\n",
    "output = my_model(x)\n",
    "#print(f\"clientAVG ----> Training LOSS {i}\")  # What is this even tellimg me lol\n",
    "my_loss = loss(output, y, my_model)\n",
    "loss_log.append(my_loss.item())\n",
    "running_num_samples += x.size(0)\n",
    "#optimizer.zero_grad()\n",
    "#loss.backward()\n",
    "#optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e99cf00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(178.2791, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(178.2784, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(0.0007, grad_fn=<MulBackward0>),\n",
       " 0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b51db9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
