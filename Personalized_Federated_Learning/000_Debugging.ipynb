{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5add6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from flcore.pflniid_utils.data_utils import read_client_data\n",
    "from flcore.clients.clientavg import clientAVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1413334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import logging\n",
    "from flcore.servers.serveravg import FedAvg\n",
    "from flcore.servers.serverlocal import Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fccfa2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6403217f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-nnc', '--num_new_clients'], dest='num_new_clients', nargs=None, const=None, default=0, type=<class 'int'>, choices=None, required=False, help=None, metavar=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general\n",
    "parser.add_argument('-go', \"--goal\", type=str, default=\"test\", \n",
    "                    help=\"The goal for this experiment\")\n",
    "parser.add_argument('-dev', \"--device\", type=str, default=\"cpu\",  # KAI: Changed the default to cpu\n",
    "                    choices=[\"cpu\", \"cuda\"])\n",
    "parser.add_argument('-did', \"--device_id\", type=str, default=\"0\")\n",
    "parser.add_argument('-data', \"--dataset\", type=str, default=\"cphs\")  # KAI: Changed the default to cphs (from mnist)\n",
    "#parser.add_argument('-nb', \"--num_classes\", type=int, default=10)  # Not doing classification...\n",
    "parser.add_argument('-m', \"--model\", type=str, default=\"LinearRegression\")  # KAI: Changed the default to Linear Regression\n",
    "parser.add_argument('-lbs', \"--batch_size\", type=int, default=1200)  # Setting it to a full update would be 1300ish... how many batches does it run? In one epoch? Not even sure where that is set\n",
    "# The 1300 and the batch size are 2 separate things...\n",
    "# I want to restrict the given dataset to just the 1300, but then iterate in batches... or do I since we don't have that much data and can probably just use all the data at once? Make batch size match the update size? ...\n",
    "parser.add_argument('-lr', \"--local_learning_rate\", type=float, default=0.005,\n",
    "                    help=\"Local learning rate\")\n",
    "parser.add_argument('-ld', \"--learning_rate_decay\", type=bool, default=False)\n",
    "parser.add_argument('-ldg', \"--learning_rate_decay_gamma\", type=float, default=0.99)\n",
    "parser.add_argument('-gr', \"--global_rounds\", type=int, default=250)  # KAI: Switched to 250 down from 2000\n",
    "parser.add_argument('-ls', \"--local_epochs\", type=int, default=1, \n",
    "                    help=\"Multiple update steps in one local epoch.\")  # KAI: I think it was 1 originally.  I'm gonna keep it there.  Does this mean I can set batchsize to 1300 and cook?Is my setup capable or running multiple epochs? Implicitly I was doing 1 epoch before, using the full update data I believe...\n",
    "parser.add_argument('-algo', \"--algorithm\", type=str, default=\"FedAvg\")\n",
    "parser.add_argument('-jr', \"--join_ratio\", type=float, default=0.2,\n",
    "                    help=\"Ratio of clients per round\")\n",
    "parser.add_argument('-rjr', \"--random_join_ratio\", type=bool, default=False,\n",
    "                    help=\"Random ratio of clients per round\")\n",
    "parser.add_argument('-nc', \"--num_clients\", type=int, default=14,\n",
    "                    help=\"Total number of clients\")\n",
    "parser.add_argument('-dp', \"--privacy\", type=bool, default=False,\n",
    "                    help=\"differential privacy\")\n",
    "parser.add_argument('-dps', \"--dp_sigma\", type=float, default=0.0)\n",
    "parser.add_argument('-sfn', \"--save_folder_name\", type=str, default='items')\n",
    "\n",
    "# SECTION: practical\n",
    "parser.add_argument('-cdr', \"--client_drop_rate\", type=float, default=0.0,\n",
    "                    help=\"Rate for clients that train but drop out\")\n",
    "parser.add_argument('-tsr', \"--train_slow_rate\", type=float, default=0.0,\n",
    "                    help=\"The rate for slow clients when training locally\")\n",
    "parser.add_argument('-ssr', \"--send_slow_rate\", type=float, default=0.0,\n",
    "                    help=\"The rate for slow clients when sending global model\")\n",
    "parser.add_argument('-ts', \"--time_select\", type=bool, default=False,\n",
    "                    help=\"Whether to group and select clients at each round according to time cost\")\n",
    "parser.add_argument('-tth', \"--time_threthold\", type=float, default=10000,\n",
    "                    help=\"The threthold for droping slow clients\")\n",
    "\n",
    "# SECTION: Kai's additional args\n",
    "parser.add_argument('-pca_channels', \"--pca_channels\", type=int, default=64,\n",
    "                    help=\"Number of principal components. 64 means do not use any PCA\")\n",
    "parser.add_argument('-lambdas', \"--lambdas\", type=list, default=[0, 1e-3, 1e-4],\n",
    "                    help=\"Lamda F, D, E penalty terms \")\n",
    "parser.add_argument('-starting_update', \"--starting_update\", type=int, default=0,\n",
    "                    help=\"Which update to start on (for CPHS Simulation). Use 0 or 10.\")\n",
    "parser.add_argument('-test_split', \"--test_split\", type=float, default=0.2,\n",
    "                    help=\"Percent of data to use for testing\")\n",
    "parser.add_argument('-device_channels', \"--device_channels\", type=int, default=64,\n",
    "                    help=\"Number of recording channels with the used EMG device\")\n",
    "parser.add_argument('-dt', \"--dt\", type=float, default=1/60,\n",
    "                    help=\"Delta time, amount of time (sec?) between measurements\")\n",
    "parser.add_argument('-normalize_emg', \"--normalize_emg\", type=bool, default=False,\n",
    "                    help=\"Normalize the input EMG signals\")\n",
    "parser.add_argument('-normalize_V', \"--normalize_V\", type=bool, default=False,\n",
    "                    help=\"Normalize the V term in the cost function\")\n",
    "parser.add_argument('-local_round_threshold', \"--local_round_threshold\", type=int, default=50,\n",
    "                    help=\"Number of communication rounds per client until a client will advance to the next batch of streamed data\")\n",
    "parser.add_argument('-debug_mode', \"--debug_mode\", type=bool, default=False,\n",
    "                    help=\"In debug mode, the code is run to minimize overhead time in order to debug as fast as possible.  Namely, the data is held at the server to decrease init time, and communication delays are ignored.\")\n",
    "parser.add_argument('-condition_number', \"--condition_number\", type=int, default=1,\n",
    "                    help=\"Which condition number (trial) to train on\")\n",
    "\n",
    "\n",
    "\n",
    "parser.add_argument('-t', \"--times\", type=int, default=1,\n",
    "                    help=\"Running times\")\n",
    "parser.add_argument('-ab', \"--auto_break\", type=bool, default=False)\n",
    "parser.add_argument('-dlg', \"--dlg_eval\", type=bool, default=False)\n",
    "parser.add_argument('-dlgg', \"--dlg_gap\", type=int, default=100)\n",
    "parser.add_argument('-bnpc', \"--batch_num_per_client\", type=int, default=2)  # Only used with DLG\n",
    "parser.add_argument('-eg', \"--eval_gap\", type=int, default=1,\n",
    "                    help=\"Rounds gap for evaluation\")\n",
    "parser.add_argument('-nnc', \"--num_new_clients\", type=int, default=0)\n",
    "\n",
    "\n",
    "# This one for sure breaks it\n",
    "#parser.add_argument('-fte', \"--fine_tuning_epoch\", type=int, default=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c8d6f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#args = parser.parse_args()\n",
    "args = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a187189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Namespace(goal='test', device='cpu', device_id='0', dataset='cphs', model='LinearRegression', batch_size=1200, local_learning_rate=0.005, learning_rate_decay=False, learning_rate_decay_gamma=0.99, global_rounds=250, local_epochs=1, algorithm='FedAvg', join_ratio=0.2, random_join_ratio=False, num_clients=14, privacy=False, dp_sigma=0.0, save_folder_name='items', client_drop_rate=0.0, train_slow_rate=0.0, send_slow_rate=0.0, time_select=False, time_threthold=10000, pca_channels=64, lambdas=[0, 0.001, 0.0001], starting_update=0, test_split=0.2, device_channels=64, dt=0.016666666666666666, normalize_emg=False, normalize_V=False, local_round_threshold=50, debug_mode=False, condition_number=1, times=1, auto_break=False, dlg_eval=False, dlg_gap=100, batch_num_per_client=2, eval_gap=1, num_new_clients=0),\n",
       " ['-f',\n",
       "  'C:\\\\Users\\\\kdmen\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-6a80223e-7337-46ed-87f0-c7998d9d9b4c.json'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6139a2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(goal='test', device='cpu', device_id='0', dataset='cphs', model='LinearRegression', batch_size=1200, local_learning_rate=0.005, learning_rate_decay=False, learning_rate_decay_gamma=0.99, global_rounds=250, local_epochs=1, algorithm='FedAvg', join_ratio=0.2, random_join_ratio=False, num_clients=14, privacy=False, dp_sigma=0.0, save_folder_name='items', client_drop_rate=0.0, train_slow_rate=0.0, send_slow_rate=0.0, time_select=False, time_threthold=10000, pca_channels=64, lambdas=[0, 0.001, 0.0001], starting_update=0, test_split=0.2, device_channels=64, dt=0.016666666666666666, normalize_emg=False, normalize_V=False, local_round_threshold=50, debug_mode=False, condition_number=1, times=1, auto_break=False, dlg_eval=False, dlg_gap=100, batch_num_per_client=2, eval_gap=1, num_new_clients=0, fine_tuning_epoch=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = args[0]\n",
    "args.fine_tuning_epoch=0\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc8ac4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cphs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df473841",
   "metadata": {},
   "source": [
    "Runs and crashes in the same way that the command line version does! Yay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8accba7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============= Running time: 0th =============\n",
      "Creating server and clients ...\n",
      "Linear(in_features=64, out_features=2, bias=True)\n",
      "Serveravg init(): set_slow_clients()\n",
      "Serveravg init(): set_clients()\n",
      "Serverbase set_clients\n",
      "SBSC: iter 0\n",
      "Setting train_data\n",
      "Client0, train=True: read_CLIENT_data() called!\n",
      "Client0, train=True: read_data() called!\n",
      "Setting test_data\n",
      "Client0, train=False: read_CLIENT_data() called!\n",
      "Client0, train=False: read_data() called!\n",
      "clientbase load_train_data(): Client0: Setting Training DataLoader\n",
      "read_client_data()\n",
      "Client0, train=True: read_CLIENT_data() called!\n",
      "Client0, train=True: read_data() called!\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# select algorithm\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFedAvg\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 21\u001b[0m     server \u001b[38;5;241m=\u001b[39m \u001b[43mFedAvg\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     23\u001b[0m     server \u001b[38;5;241m=\u001b[39m Local(args, i)\n",
      "File \u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\Personalized_Federated_Learning\\flcore\\servers\\serveravg.py:17\u001b[0m, in \u001b[0;36mFedAvg.__init__\u001b[1;34m(self, args, times)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_slow_clients()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mServeravg init(): set_clients()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_clients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclientAVG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mJoin ratio / total clients: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_ratio\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_clients\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished creating server and clients.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\Personalized_Federated_Learning\\flcore\\servers\\serverbase.py:104\u001b[0m, in \u001b[0;36mServer.set_clients\u001b[1;34m(self, clientObj)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting test_data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    103\u001b[0m     test_data \u001b[38;5;241m=\u001b[39m read_client_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_update, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 104\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mclientObj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m                \u001b[49m\u001b[43mID\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtrain_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtest_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtrain_slow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_slow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m                \u001b[49m\u001b[43msend_slow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msend_slow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclients\u001b[38;5;241m.\u001b[39mappend(client)\n",
      "File \u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\Personalized_Federated_Learning\\flcore\\clients\\clientavg.py:13\u001b[0m, in \u001b[0;36mclientAVG.__init__\u001b[1;34m(self, args, ID, train_samples, test_samples, **kwargs)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, args, ID, train_samples, test_samples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(args, ID, train_samples, test_samples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\Personalized_Federated_Learning\\flcore\\clients\\clientbase.py:75\u001b[0m, in \u001b[0;36mClient.__init__\u001b[1;34m(self, args, ID, train_samples, test_samples, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Before this I need to run the INIT update segmentation code...\u001b[39;00m\n\u001b[0;32m     74\u001b[0m init_dl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_train_data()\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate_data_streaming\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_dl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# ^ This func sets F, V, etc\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInit loss setup (no calc?)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\Research\\personalization-privacy-risk\\Personalized_Federated_Learning\\flcore\\clients\\clientbase.py:91\u001b[0m, in \u001b[0;36mClient.simulate_data_streaming\u001b[1;34m(self, dl)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimulate_data_streaming\u001b[39m(\u001b[38;5;28mself\u001b[39m, dl):\n\u001b[0;32m     90\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(dl)\n\u001b[1;32m---> 91\u001b[0m     s0 \u001b[38;5;241m=\u001b[39m \u001b[43mit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m     s_temp \u001b[38;5;241m=\u001b[39m s0[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_ix[\u001b[38;5;241m1\u001b[39m],:]\n\u001b[0;32m     93\u001b[0m     p_reference \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(s0[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_ix[\u001b[38;5;241m1\u001b[39m],:], \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\fl_torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\fl_torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\fl_torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:624\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_index\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampler_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "time_list = []\n",
    "#reporter = MemReporter()\n",
    "model_str = args.model\n",
    "\n",
    "# Switched args.prev to 0 since it wasn't working\n",
    "for i in range(0, args.times):\n",
    "    print(f\"\\n============= Running time: {i}th =============\")\n",
    "    print(\"Creating server and clients ...\")\n",
    "    start = time.time()\n",
    "\n",
    "    # Generate args.model\n",
    "    if model_str == \"LinearRegression\":\n",
    "        args.model = torch.nn.Linear(args.pca_channels, 2)  #input_size, output_size\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    print(args.model)\n",
    "\n",
    "    # select algorithm\n",
    "    if args.algorithm == \"FedAvg\":\n",
    "        server = FedAvg(args, i)\n",
    "    elif args.algorithm == \"Local\":\n",
    "        server = Local(args, i)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    server.train()\n",
    "\n",
    "    time_list.append(time.time()-start)\n",
    "\n",
    "print(f\"\\nAverage time cost: {round(np.average(time_list), 2)}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f6ec80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
