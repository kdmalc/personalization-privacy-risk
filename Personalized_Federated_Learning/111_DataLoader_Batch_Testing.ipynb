{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d646d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import metrics\n",
    "\n",
    "from flcore.pflniid_utils.data_utils import read_client_data\n",
    "from utils.custom_loss_class import CPHSLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c9db32",
   "metadata": {},
   "source": [
    "# Toy Example of DataLoader\n",
    "- https://www.youtube.com/watch?v=3GVUzwXXihs\n",
    "- https://pytorch.org/docs/stable/_modules/torch/utils/data/sampler.html#BatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0c54eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [5., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [7., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [8., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [9., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = torch.zeros((10,11))\n",
    "tp[:,0] = torch.arange(10)\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c9c29c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(\n",
    "    dataset=tp,\n",
    "    batch_size=10, \n",
    "    drop_last=False) \n",
    "\n",
    "it = iter(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e107c1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [5., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [7., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [8., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [9., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it.__next__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e827f8fe",
   "metadata": {},
   "source": [
    "# Validating read_client_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d9a3ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_client_data('cphs', 0, is_train=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d5ebba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl1 = DataLoader(\n",
    "                dataset=train_data,\n",
    "                batch_sampler=torch.utils.data.BatchSampler(\n",
    "                    torch.utils.data.SequentialSampler(train_data), \n",
    "                    batch_size=1200, \n",
    "                    drop_last=False) \n",
    "        )\n",
    "it1 = iter(dl1)\n",
    "\n",
    "dl2 = DataLoader(\n",
    "                dataset=train_data,\n",
    "                batch_size=1200,\n",
    "                drop_last=False) \n",
    "it2 = iter(dl2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1144e5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1200, 64])\n",
      "tensor([[  0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        ...,\n",
      "        [128.8972,  71.8650,  34.2512,  10.2227],\n",
      "        [135.5390,  80.6596,  33.9306,  10.2820],\n",
      "        [135.5390,  80.6596,  33.9306,  10.2820]])\n"
     ]
    }
   ],
   "source": [
    "s1 = it1.__next__()\n",
    "print(s1[0].size())\n",
    "print(s1[0][:, :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38b3831f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1200, 64])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [16.4556, 18.0038,  2.8854,  5.8259]])\n"
     ]
    }
   ],
   "source": [
    "s2 = it2.__next__()\n",
    "print(s2[0].size())\n",
    "print(s2[0][:4, :4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f251ee8",
   "metadata": {},
   "source": [
    "# Deconstructed load_train_data() From Clientbase.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df583a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#self.model = copy.deepcopy(args.model)\n",
    "algorithm = 'FedAvg'\n",
    "dataset = 'cphs'\n",
    "device = 'cpu'\n",
    "ID = 0  # integer\n",
    "#self.save_folder_name = args.save_folder_name\n",
    "\n",
    "#self.num_classes = args.num_classes\n",
    "#train_samples = train_samples\n",
    "#test_samples = test_samples\n",
    "batch_size = 1200\n",
    "learning_rate = 0.005\n",
    "local_epochs = 1\n",
    "\n",
    "# My additional parameters\n",
    "pca_channels = 64\n",
    "lambdas = [0, 1e-3, 1e-4]\n",
    "lambdaF = lambdas[0]\n",
    "lambdaD = lambdas[1]\n",
    "lambdaE = lambdas[2]\n",
    "current_update = 0\n",
    "local_round = 0\n",
    "last_global_round = 0\n",
    "local_round_threshold = 50\n",
    "update_ix=[0,  1200,  2402,  3604,  4806,  6008,  7210,  8412,  9614, 10816, 12018, 13220, 14422, 15624, 16826, 18028, 19230, 20432, 20769]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6eb85959",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_round += 1\n",
    "if local_round%local_round_threshold==0:\n",
    "    current_update += 1\n",
    "\n",
    "if batch_size == None:\n",
    "    batch_size = batch_size\n",
    "train_data = read_client_data(dataset, ID, is_train=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c952324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 64])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [16.4556, 18.0038,  2.8854,  5.8259,  8.1008,  2.2209,  9.7316, 19.7165,\n",
      "         11.9520,  0.5433]])\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_sampler=torch.utils.data.BatchSampler(\n",
    "            torch.utils.data.SequentialSampler(dataset), \n",
    "            batch_size=batch_size, \n",
    "            drop_last=False) \n",
    ")\n",
    "sit1 = iter(loader)\n",
    "s1 = sit1.__next__()\n",
    "print(s1[0].size())\n",
    "print(s1[0][:, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25f62753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1200, 64])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [16.4556, 18.0038,  2.8854,  5.8259,  8.1008,  2.2209,  9.7316, 19.7165,\n",
      "         11.9520,  0.5433]])\n"
     ]
    }
   ],
   "source": [
    "# I think it is doing Sequential Sampler by default, if shuffle is False (which is true by default)\n",
    "\n",
    "loader2 = DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=batch_size, \n",
    "        drop_last=False) \n",
    "sit2 = iter(loader2)\n",
    "s2 = sit2.__next__()\n",
    "print(s2[0].size())\n",
    "print(s2[0][:4, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3c59c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [16.4556, 18.0038,  2.8854,  5.8259,  8.1008],\n",
      "        [16.4556, 18.0038,  2.8854,  5.8259,  8.1008],\n",
      "        [16.4556, 18.0038,  2.8854,  5.8259,  8.1008],\n",
      "        [40.5837, 41.7818, 13.8757, 12.2603, 15.2425],\n",
      "        [58.4589, 56.5549, 24.6047, 24.2789, 20.7511],\n",
      "        [58.4589, 56.5549, 24.6047, 24.2789, 20.7511],\n",
      "        [45.4502, 43.0116, 24.5893, 24.8776, 16.5744]])\n"
     ]
    }
   ],
   "source": [
    "print(s2[0][:10, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80270d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s2 type: <class 'list'>\n",
      "s2 len: 2\n",
      "s2[0] (training data) size: torch.Size([1200, 64])\n",
      "s2[1] (training data) size: torch.Size([1200, 2])\n"
     ]
    }
   ],
   "source": [
    "print(f\"s2 type: {type(s2)}\")\n",
    "print(f\"s2 len: {len(s2)}\")\n",
    "print(f\"s2[0] (training data) size: {s2[0].size()}\")\n",
    "print(f\"s2[1] (training data) size: {s2[1].size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0286ba40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "        ...,\n",
       "        [128.8972,  71.8650,  34.2512,  ...,   8.3115,  10.0432,   9.2224],\n",
       "        [135.5390,  80.6596,  33.9306,  ...,  10.5396,  11.5099,   9.2469],\n",
       "        [135.5390,  80.6596,  33.9306,  ...,  10.5396,  11.5099,   9.2469]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab5a226",
   "metadata": {},
   "source": [
    "## Integrating With CPHS Processing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf7f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_temp = s2[0][0:update_ix[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1e49d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_EMG = False\n",
    "PCA_comps = 64\n",
    "\n",
    "# First, normalize the entire s matrix\n",
    "if normalize_EMG:\n",
    "    s_normed = s_temp/torch.max(s_temp)\n",
    "else:\n",
    "    s_normed = s_temp\n",
    "# Now do PCA unless it is set to 64 (AKA the default num channels i.e. no reduction)\n",
    "# Also probably ought to find a global transform if possible so I don't recompute it every time...\n",
    "if PCA_comps!=64:  \n",
    "    pca = PCA(n_components=PCA_comps)\n",
    "    s_normed = pca.fit_transform(s_normed)\n",
    "#s = np.transpose(s_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4df0b33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1200, 64])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_normed.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2139bafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1200])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.transpose(s_normed, 0, 1)\n",
    "s.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6260f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't run this since I don't have the model weights\n",
    "\n",
    "#F = s[:,:-1] # note: truncate F for estimate_decoder\n",
    "#v_actual = self.w@s\n",
    "#p_actual = np.cumsum(v_actual, axis=1)*self.dt  # Numerical integration of v_actual to get p_actual\n",
    "#p_reference = np.transpose(self.labels[lower_bound:upper_bound,:])\n",
    "#self.V = (p_reference - p_actual)*self.dt\n",
    "#\n",
    "#self.loss = CPHSLoss(self.F, self.model.weight, self.V, torch.view(self.F)[0], lambdaF=self.lambdaF, lambdaD=self.lambdaD, lambdaE=self.lambdaE, Nd=2, Ne=self.pca_channels, return_cost_func_comps=False)\n",
    "#\n",
    "#self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.learning_rate)\n",
    "#self.learning_rate_scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "#    optimizer=self.optimizer, \n",
    "#    gamma=args.learning_rate_decay_gamma\n",
    "#)\n",
    "#self.learning_rate_decay = args.learning_rate_decay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5245d58c",
   "metadata": {},
   "source": [
    "## Checking How Many Iterations The Iter Object Has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f100bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    s2 = sit2.__next__()\n",
    "    print(\"We can run multiple times!\")\n",
    "except StopIteration:\n",
    "    print(\"StopIteration Error: Can only call next once!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8592324",
   "metadata": {},
   "source": [
    "Why can we run multiple times... can we run 18 or 19 total times (once for each update?)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb44d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(19):\n",
    "    print(i+2)  # +2 since we have already called __next__() twice in the code above\n",
    "    \n",
    "    try:\n",
    "        s2 = sit2.__next__()\n",
    "    except StopIteration:\n",
    "        print(\"StopIteration Error: Can only call next once!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a808cd89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
