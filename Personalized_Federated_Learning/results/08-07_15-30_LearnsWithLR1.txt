-------------Round number: 99-------------

Evaluate personalized models
Averaged Test Loss: 94.4746
Serverbase train_metrics(): GLOBAL ROUND: 99
Averaged Train Loss: 23.3429

Client0 advances to update 12 on local round 100
Client0 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00047
SL: Client0 round 99 loss: 0.00047
Client1 advances to update 12 on local round 100
Client1 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00047
SL: Client1 round 99 loss: 0.00047
Client2 advances to update 12 on local round 100
Client2 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00047
SL: Client2 round 99 loss: 0.00047
Client3 advances to update 12 on local round 100
Client3 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00046
SL: Client3 round 99 loss: 0.00046
Client4 advances to update 12 on local round 100
Client4 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00048
SL: Client4 round 99 loss: 0.00048
Client5 advances to update 12 on local round 100
Client5 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00045
SL: Client5 round 99 loss: 0.00045
Client6 advances to update 12 on local round 100
Client6 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00045
SL: Client6 round 99 loss: 0.00045
Client7 advances to update 12 on local round 100
Client7 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00059
SL: Client7 round 99 loss: 0.00059
Client8 advances to update 12 on local round 100
Client8 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00046
SL: Client8 round 99 loss: 0.00046
Client9 advances to update 12 on local round 100
Client9 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00054
SL: Client9 round 99 loss: 0.00054
Client10 advances to update 12 on local round 100
Client10 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00046
SL: Client10 round 99 loss: 0.00046
Client11 advances to update 12 on local round 100
Client11 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00045
SL: Client11 round 99 loss: 0.00045
Client12 advances to update 12 on local round 100
Client12 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00046
SL: Client12 round 99 loss: 0.00046
Client13 advances to update 12 on local round 100
Client13 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00046
SL: Client13 round 99 loss: 0.00046


-------------Round number: 100-------------

Evaluate personalized models
Averaged Test Loss: 93.2496
Serverbase train_metrics(): GLOBAL ROUND: 100
Averaged Train Loss: 17.9816

Client0 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00047
SL: Client0 round 100 loss: 0.00047
Client1 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00046
SL: Client1 round 100 loss: 0.00046
Client2 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00047
SL: Client2 round 100 loss: 0.00047
Client3 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00045
SL: Client3 round 100 loss: 0.00045
Client4 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00047
SL: Client4 round 100 loss: 0.00047
Client5 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00045
SL: Client5 round 100 loss: 0.00045
Client6 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00045
SL: Client6 round 100 loss: 0.00045
Client7 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00057
SL: Client7 round 100 loss: 0.00057
Client8 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00046
SL: Client8 round 100 loss: 0.00046
Client9 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00052
SL: Client9 round 100 loss: 0.00052
Client10 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00046
SL: Client10 round 100 loss: 0.00046
Client11 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00045
SL: Client11 round 100 loss: 0.00045
Client12 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00045
SL: Client12 round 100 loss: 0.00045
Client13 Training
Step 0, pair 0 in traindl; update 12; x.size(): torch.Size([1202, 64]); loss: 0.00046
SL: Client13 round 100 loss: 0.00046

Averaged Test Loss: 92.3660

Best Loss.
92.36603718996048
File path: ../results/mdHM_08-07_15-36_cphs_Local_test_0.h5

Average time cost: 138.02s.
Server's round, rs_train_loss, rs_test_loss (averaged over clients):
Round 0, Train Loss: 33.78, Test Loss: 220.10
Round 1, Train Loss: 31.80, Test Loss: 214.61
Round 2, Train Loss: 30.26, Test Loss: 210.91
Round 3, Train Loss: 29.03, Test Loss: 208.34
Round 4, Train Loss: 28.01, Test Loss: 206.53
Round 5, Train Loss: 27.16, Test Loss: 205.24
Round 6, Train Loss: 26.44, Test Loss: 204.31
Round 7, Train Loss: 25.82, Test Loss: 203.64
Round 8, Train Loss: 25.29, Test Loss: 203.14
Round 9, Train Loss: 24.82, Test Loss: 202.76
Round 10, Train Loss: 24.41, Test Loss: 202.46
Round 11, Train Loss: 24.04, Test Loss: 202.21
Round 12, Train Loss: 23.70, Test Loss: 201.99
Round 13, Train Loss: 23.40, Test Loss: 201.78
Round 14, Train Loss: 23.12, Test Loss: 201.56
Round 15, Train Loss: 22.86, Test Loss: 201.34
Round 16, Train Loss: 22.62, Test Loss: 201.11
Round 17, Train Loss: 22.39, Test Loss: 200.86
Round 18, Train Loss: 22.18, Test Loss: 200.59
Round 19, Train Loss: 21.98, Test Loss: 200.30
Round 20, Train Loss: 21.79, Test Loss: 199.99
Round 21, Train Loss: 21.61, Test Loss: 199.66
Round 22, Train Loss: 21.44, Test Loss: 199.31
Round 23, Train Loss: 21.27, Test Loss: 198.93
Round 24, Train Loss: 21.11, Test Loss: 198.54
Round 25, Train Loss: 20.96, Test Loss: 198.13
Round 26, Train Loss: 20.81, Test Loss: 197.70
Round 27, Train Loss: 20.66, Test Loss: 197.25
Round 28, Train Loss: 20.52, Test Loss: 196.79
Round 29, Train Loss: 20.38, Test Loss: 196.32
Round 30, Train Loss: 20.25, Test Loss: 195.83
Round 31, Train Loss: 20.12, Test Loss: 195.33
Round 32, Train Loss: 19.99, Test Loss: 194.82
Round 33, Train Loss: 19.86, Test Loss: 194.30
Round 34, Train Loss: 19.74, Test Loss: 193.77
Round 35, Train Loss: 19.62, Test Loss: 193.23
Round 36, Train Loss: 19.50, Test Loss: 192.69
Round 37, Train Loss: 19.39, Test Loss: 192.13
Round 38, Train Loss: 19.27, Test Loss: 191.57
Round 39, Train Loss: 19.16, Test Loss: 191.01
Round 40, Train Loss: 19.05, Test Loss: 190.44
Round 41, Train Loss: 18.94, Test Loss: 189.86
Round 42, Train Loss: 18.83, Test Loss: 189.28
Round 43, Train Loss: 18.73, Test Loss: 188.70
Round 44, Train Loss: 18.62, Test Loss: 188.12
Round 45, Train Loss: 18.52, Test Loss: 187.53
Round 46, Train Loss: 18.42, Test Loss: 186.94
Round 47, Train Loss: 18.32, Test Loss: 186.35
Round 48, Train Loss: 18.22, Test Loss: 185.75
Round 49, Train Loss: 35.77, Test Loss: 179.35
Round 50, Train Loss: 34.97, Test Loss: 173.61
Round 51, Train Loss: 34.27, Test Loss: 168.39
Round 52, Train Loss: 33.64, Test Loss: 163.61
Round 53, Train Loss: 33.06, Test Loss: 159.21
Round 54, Train Loss: 32.53, Test Loss: 155.15
Round 55, Train Loss: 32.04, Test Loss: 151.39
Round 56, Train Loss: 31.59, Test Loss: 147.90
Round 57, Train Loss: 31.16, Test Loss: 144.65
Round 58, Train Loss: 30.76, Test Loss: 141.62
Round 59, Train Loss: 30.39, Test Loss: 138.80
Round 60, Train Loss: 30.04, Test Loss: 136.17
Round 61, Train Loss: 29.71, Test Loss: 133.71
Round 62, Train Loss: 29.39, Test Loss: 131.41
Round 63, Train Loss: 29.10, Test Loss: 129.25
Round 64, Train Loss: 28.82, Test Loss: 127.22
Round 65, Train Loss: 28.55, Test Loss: 125.32
Round 66, Train Loss: 28.29, Test Loss: 123.53
Round 67, Train Loss: 28.05, Test Loss: 121.84
Round 68, Train Loss: 27.82, Test Loss: 120.24
Round 69, Train Loss: 27.60, Test Loss: 118.74
Round 70, Train Loss: 27.39, Test Loss: 117.31
Round 71, Train Loss: 27.18, Test Loss: 115.96
Round 72, Train Loss: 26.98, Test Loss: 114.68
Round 73, Train Loss: 26.79, Test Loss: 113.46
Round 74, Train Loss: 26.61, Test Loss: 112.30
Round 75, Train Loss: 26.43, Test Loss: 111.19
Round 76, Train Loss: 26.26, Test Loss: 110.14
Round 77, Train Loss: 26.10, Test Loss: 109.13
Round 78, Train Loss: 25.94, Test Loss: 108.16
Round 79, Train Loss: 25.78, Test Loss: 107.24
Round 80, Train Loss: 25.63, Test Loss: 106.35
Round 81, Train Loss: 25.48, Test Loss: 105.49
Round 82, Train Loss: 25.33, Test Loss: 104.67
Round 83, Train Loss: 25.19, Test Loss: 103.88
Round 84, Train Loss: 25.05, Test Loss: 103.11
Round 85, Train Loss: 24.91, Test Loss: 102.37
Round 86, Train Loss: 24.78, Test Loss: 101.66
Round 87, Train Loss: 24.65, Test Loss: 100.96
Round 88, Train Loss: 24.52, Test Loss: 100.29
Round 89, Train Loss: 24.39, Test Loss: 99.64
Round 90, Train Loss: 24.27, Test Loss: 99.00
Round 91, Train Loss: 24.15, Test Loss: 98.39
Round 92, Train Loss: 24.03, Test Loss: 97.79
Round 93, Train Loss: 23.91, Test Loss: 97.20
Round 94, Train Loss: 23.79, Test Loss: 96.63
Round 95, Train Loss: 23.68, Test Loss: 96.07
Round 96, Train Loss: 23.57, Test Loss: 95.53
Round 97, Train Loss: 23.45, Test Loss: 95.00
Round 98, Train Loss: 23.34, Test Loss: 94.47
Round 99, Train Loss: 17.98, Test Loss: 93.25
Final eval (100), Test Loss: 92.37
All done!

Storage on cpu
-------------------------------------------------------------------------------
Total Tensors: 3346116  Used Memory: 4.42M
-------------------------------------------------------------------------------