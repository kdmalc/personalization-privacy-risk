BASE
algorithm = Centralized
model = LSTMModel(
  (lstm): LSTM(64, 32, batch_first=True)
  (fc): Linear(in_features=32, out_features=2, bias=True)
)
train_subj_IDs = ['METACPHS_S106', 'METACPHS_S107', 'METACPHS_S108', 'METACPHS_S109', 'METACPHS_S110', 'METACPHS_S111', 'METACPHS_S112', 'METACPHS_S113', 'METACPHS_S114', 'METACPHS_S115', 'METACPHS_S116', 'METACPHS_S117', 'METACPHS_S118', 'METACPHS_S119']
condition_number_lst = [3]
total effective clients = train_subj_IDs*condition_number_lst = 14
device_channels = 64


MODEL HYPERPARAMETERS
lambdaF = 0.0
lambdaD = 0.001
lambdaE = 0.0001
global_rounds = 5
local_epochs = 1
batch_size = 32
local_learning_rate = 0.1
learning_rate_decay = False
learning_rate_decay_gamma = 0.99
pca_channels = 64
normalize_data = True


FEDERATED LEARNING PARAMS
starting_update = 10
local_round_threshold = 25


TESTING
test_split_fraction = 0.2
test_split_each_update = False
test_split_users = True
run_train_metrics = True


SEQUENTIAL
sequential = False
live_client_IDs_queue = []
static_client_IDs = []
num_liveseq_rounds_per_seqclient = 25
prev_model_directory = C:\Users\kdmen\Desktop\Research\personalization-privacy-risk\Personalized_Federated_Learning\models\cphs\FedAvg\11-10_16-14\FedAvg_server_global.pt