BASE
algorithm = Centralized
model = RNNModel(
  (rnn): RNN(64, 10, batch_first=True)
  (fc): Linear(in_features=10, out_features=2, bias=True)
)
device_channels = 64


MODEL HYPERPARAMETERS
lambdaF = 0.0
lambdaD = 0.001
lambdaE = 0.0001
global_rounds = 100
local_epochs = 1
batch_size = 32
local_learning_rate = 0.1
learning_rate_decay = False
learning_rate_decay_gamma = 0.99
optimizer = SGD
pca_channels = 64
normalize_data = True
(model) input_size = 64
(model) output_size = 2


TESTING
test_split_fraction = 0.2
test_split_each_update = False
test_split_users = True


SEQUENTIAL
sequential = False


CONTINUAL LEARNING PARAMS
ewc_bool = True
fisher_multiplier = 1000.0


DEEP NETWORK HYPERPARAMETERS
hidden_size = 10
sequence_length = 10


FEDERATED LEARNING PARAMS
local_round_threshold = 25


SIMULATION PARAMS
starting_update = 10
train_subj_IDs = ['METACPHS_S106', 'METACPHS_S107', 'METACPHS_S108', 'METACPHS_S109', 'METACPHS_S110', 'METACPHS_S111', 'METACPHS_S112', 'METACPHS_S113', 'METACPHS_S114', 'METACPHS_S115', 'METACPHS_S116', 'METACPHS_S117', 'METACPHS_S118', 'METACPHS_S119']
condition_number_lst = [3]
total effective clients = train_subj_IDs*condition_number_lst = 14
