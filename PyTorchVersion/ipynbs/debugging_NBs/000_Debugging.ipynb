{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757c20a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0755713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "A\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n"
     ]
    }
   ],
   "source": [
    "product_list = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "limit = 8\n",
    "name_list = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "for idx, val in enumerate(product_list):\n",
    "    if idx < limit:\n",
    "        name_str = name_list[0]\n",
    "    elif (limit <= idx) and idx < 2*limit:\n",
    "        name_str = name_list[1]\n",
    "    elif (2*limit <= idx) and idx < 3*limit:\n",
    "        name_str = name_list[2]\n",
    "    else:\n",
    "        print(\"DONE\")\n",
    "    print(name_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46bcc7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B']\n"
     ]
    }
   ],
   "source": [
    "def assign_names_to_intervals(my_list, name_list, limit):\n",
    "    interval_size = limit #len(my_list) // limit\n",
    "    assigned_names = []\n",
    "\n",
    "    for idx, val in enumerate(my_list):\n",
    "        name_index = idx // interval_size\n",
    "        if name_index >= len(name_list):\n",
    "            name_index = len(name_list) - 1  # Ensure it doesn't exceed the last index\n",
    "        assigned_names.append(name_list[name_index])\n",
    "\n",
    "    return assigned_names\n",
    "\n",
    "result = assign_names_to_intervals(product_list, name_list, limit)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0591597",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf47034c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char: [\n",
      "current_string: \n",
      "string_list: []\n",
      "\n",
      "MATCH\n",
      "char: '\n",
      "current_string: \n",
      "string_list: []\n",
      "\n",
      "QUOTATION\n",
      "char: M\n",
      "current_string: \n",
      "string_list: []\n",
      "\n",
      "ELSE\n",
      "char: E\n",
      "current_string: M\n",
      "string_list: []\n",
      "\n",
      "ELSE\n",
      "char: T\n",
      "current_string: ME\n",
      "string_list: []\n",
      "\n",
      "ELSE\n",
      "char: A\n",
      "current_string: MET\n",
      "string_list: []\n",
      "\n",
      "ELSE\n",
      "char: C\n",
      "current_string: META\n",
      "string_list: []\n",
      "\n",
      "ELSE\n",
      "char: P\n",
      "current_string: METAC\n",
      "string_list: []\n",
      "\n",
      "ELSE\n",
      "char: H\n",
      "current_string: METACP\n",
      "string_list: []\n",
      "\n",
      "ELSE\n",
      "char: S\n",
      "current_string: METACPH\n",
      "string_list: []\n",
      "\n",
      "ELSE\n",
      "char: _\n",
      "current_string: METACPHS\n",
      "string_list: []\n",
      "\n",
      "ELSE\n",
      "char: S\n",
      "current_string: METACPHS_\n",
      "string_list: []\n",
      "\n",
      "ELSE\n",
      "char: 1\n",
      "current_string: METACPHS_S\n",
      "string_list: []\n",
      "\n",
      "ELSE\n",
      "char: 0\n",
      "current_string: METACPHS_S1\n",
      "string_list: []\n",
      "\n",
      "ELSE\n",
      "char: 6\n",
      "current_string: METACPHS_S10\n",
      "string_list: []\n",
      "\n",
      "ELSE\n",
      "char: '\n",
      "current_string: METACPHS_S106\n",
      "string_list: []\n",
      "\n",
      "QUOTATION\n",
      "char: ,\n",
      "current_string: \n",
      "string_list: ['METACPHS_S106']\n",
      "\n",
      "MATCH\n",
      "char: '\n",
      "current_string: \n",
      "string_list: ['METACPHS_S106']\n",
      "\n",
      "QUOTATION\n",
      "char: M\n",
      "current_string: \n",
      "string_list: ['METACPHS_S106']\n",
      "\n",
      "ELSE\n",
      "char: E\n",
      "current_string: M\n",
      "string_list: ['METACPHS_S106']\n",
      "\n",
      "ELSE\n",
      "char: T\n",
      "current_string: ME\n",
      "string_list: ['METACPHS_S106']\n",
      "\n",
      "ELSE\n",
      "char: A\n",
      "current_string: MET\n",
      "string_list: ['METACPHS_S106']\n",
      "\n",
      "ELSE\n",
      "char: C\n",
      "current_string: META\n",
      "string_list: ['METACPHS_S106']\n",
      "\n",
      "ELSE\n",
      "char: P\n",
      "current_string: METAC\n",
      "string_list: ['METACPHS_S106']\n",
      "\n",
      "ELSE\n",
      "char: H\n",
      "current_string: METACP\n",
      "string_list: ['METACPHS_S106']\n",
      "\n",
      "ELSE\n",
      "char: S\n",
      "current_string: METACPH\n",
      "string_list: ['METACPHS_S106']\n",
      "\n",
      "ELSE\n",
      "char: _\n",
      "current_string: METACPHS\n",
      "string_list: ['METACPHS_S106']\n",
      "\n",
      "ELSE\n",
      "char: S\n",
      "current_string: METACPHS_\n",
      "string_list: ['METACPHS_S106']\n",
      "\n",
      "ELSE\n",
      "char: 1\n",
      "current_string: METACPHS_S\n",
      "string_list: ['METACPHS_S106']\n",
      "\n",
      "ELSE\n",
      "char: 0\n",
      "current_string: METACPHS_S1\n",
      "string_list: ['METACPHS_S106']\n",
      "\n",
      "ELSE\n",
      "char: 7\n",
      "current_string: METACPHS_S10\n",
      "string_list: ['METACPHS_S106']\n",
      "\n",
      "ELSE\n",
      "char: '\n",
      "current_string: METACPHS_S107\n",
      "string_list: ['METACPHS_S106']\n",
      "\n",
      "QUOTATION\n",
      "char: ]\n",
      "current_string: \n",
      "string_list: ['METACPHS_S106', 'METACPHS_S107']\n",
      "\n",
      "MATCH\n"
     ]
    }
   ],
   "source": [
    "temp_lst = ['[', \"'\", 'M', 'E', 'T', 'A', 'C', 'P', 'H', 'S', '_', 'S', '1', '0', '6', \"'\", ']']\n",
    "temp_lst = ['[', \"'\", 'M', 'E', 'T', 'A', 'C', 'P', 'H', 'S', '_', 'S', '1', '0', '6', \"'\", \",\", \"'\", 'M', 'E', 'T', 'A', 'C', 'P', 'H', 'S', '_', 'S', '1', '0', '7', \"'\", ']']\n",
    "\n",
    "# Initialize an empty list to store the string elements\n",
    "string_list = []\n",
    "\n",
    "# Iterate through the characters and add them to the result list as strings\n",
    "current_string = \"\"\n",
    "for char in temp_lst:\n",
    "    print(f\"char: {char}\")\n",
    "    print(f\"current_string: {current_string}\")\n",
    "    print(f\"string_list: {string_list}\")\n",
    "    print()\n",
    "    \n",
    "    if char=='[' or char==']' or char==',' or char==' ':\n",
    "        print(\"MATCH\")\n",
    "        pass\n",
    "    elif char == \"'\":\n",
    "        print(\"QUOTATION\")\n",
    "        # When encountering a single quote, it indicates the start or end of a string\n",
    "        if current_string:\n",
    "            string_list.append(current_string)\n",
    "            current_string = \"\"\n",
    "    else:\n",
    "        print(\"ELSE\")\n",
    "        current_string += char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6334990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List: [1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Retrieve the list as a string from command line arguments\n",
    "list_as_string = '[1, 2, 3, 4]'\n",
    "\n",
    "# Convert the string representation of the list to a list using ast.literal_eval\n",
    "try:\n",
    "    my_list = ast.literal_eval(list_as_string)\n",
    "    if not isinstance(my_list, list):\n",
    "        raise ValueError(\"Invalid input. Must be a list.\")\n",
    "except (ValueError, SyntaxError):\n",
    "    print(\"Invalid input. Please provide a valid list.\")\n",
    "\n",
    "# Now, you have 'my_list' as a Python list that you can use in your program.\n",
    "print(\"List:\", my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd29d923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid input. Please provide a valid list.\n",
      "List: [1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the list as a string from command line arguments\n",
    "list_as_string = ['[', \"'\", 'M', 'E', 'T', 'A', 'C', 'P', 'H', 'S', '_', 'S', '1', '0', '6', \"'\", \",\", \"'\", 'M', 'E', 'T', 'A', 'C', 'P', 'H', 'S', '_', 'S', '1', '0', '7', \"'\", ']']\n",
    "\n",
    "# Convert the string representation of the list to a list using ast.literal_eval\n",
    "try:\n",
    "    my_list = ast.literal_eval(list_as_string)\n",
    "    if not isinstance(my_list, list):\n",
    "        raise ValueError(\"Invalid input. Must be a list.\")\n",
    "except (ValueError, SyntaxError):\n",
    "    print(\"Invalid input. Please provide a valid list.\")\n",
    "\n",
    "# Now, you have 'my_list' as a Python list that you can use in your program.\n",
    "print(\"List:\", my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13196e77",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5add6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from flcore.pflniid_utils.data_utils import read_client_data\n",
    "from flcore.clients.clientavg import clientAVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1413334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import logging\n",
    "from flcore.servers.serveravg import FedAvg\n",
    "from flcore.servers.serverlocal import Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f6ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.custom_loss_class import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf0c97a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072579af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From clientbase.py\n",
    "def load_test_data(self, batch_size=None): \n",
    "        # Make sure this runs AFTER load_train_data so the data is already loaded in\n",
    "        print(f\"Client{self.ID}: Setting Test DataLoader\")\n",
    "        if batch_size == None:\n",
    "            batch_size = self.batch_size\n",
    "\n",
    "        #test_data = read_client_data(self.dataset, self.ID, self.current_update, is_train=False)\n",
    "        testing_dataset_obj = CustomEMGDataset(self.cond_samples_npy[self.update_upper_bound:,:], self.cond_labels_npy[self.update_upper_bound:,:])\n",
    "        X_data = torch.Tensor(testing_dataset_obj['x']).type(torch.float32)\n",
    "        y_data = torch.Tensor(testing_dataset_obj['y']).type(torch.float32)\n",
    "        testing_data_for_dataloader = [(x, y) for x, y in zip(X_data, y_data)]\n",
    "\n",
    "        dl = DataLoader(\n",
    "            dataset=testing_data_for_dataloader,\n",
    "            batch_size=batch_size, \n",
    "            drop_last=False,  # Yah idk if this should be true or false or if it matters...\n",
    "            shuffle=False) \n",
    "        return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d39965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4df1004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87d3592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb83a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf47e60b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df95d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc477e12",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ffddd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight: Parameter containing:\n",
      "tensor([[ 0.0752, -0.1182, -0.1825, -0.1810, -0.0480,  0.0073, -0.2458, -0.1464,\n",
      "          0.0931, -0.0762]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Sequential(torch.nn.Linear(10, 1, bias=False))\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e26a3735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight: Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    #model[0].weight = torch.nn.Parameter(torch.ones_like(model[0].weight))\n",
    "    #model[0].weight[0, 0] = 2.\n",
    "    model[0].weight.fill_(0)\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name}: {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70b800b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4acb3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: Parameter containing:\n",
      "tensor([[ 0.2077, -0.2590,  0.1117,  0.0130, -0.3067, -0.1483, -0.0893,  0.2726,\n",
      "          0.1238,  0.1271]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Linear(10, 1, bias=False)\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3092412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    #model[0].weight = torch.nn.Parameter(torch.ones_like(model[0].weight))\n",
    "    #model[0].weight[0, 0] = 2.\n",
    "    model.weight.fill_(0)\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name}: {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e193d7c3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "528b9fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\kdmen\\Desktop\\Research\\personalization-privacy-risk\\Data'\n",
    "cond0_filename = r'\\cond0_dict_list.p'\n",
    "with open(path+cond0_filename, 'rb') as fp:\n",
    "    cond0_training_and_labels_lst = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea3a4ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_ix = np.load(r\"..\\Data\\update_ix.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c3884e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cond0_training_and_labels_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40e3e29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20770, 64)\n",
      "(20770, 2)\n"
     ]
    }
   ],
   "source": [
    "print(cond0_training_and_labels_lst[0]['training'].shape)\n",
    "print(cond0_training_and_labels_lst[0]['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1da64c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_emg=False\n",
    "pca_channels=64\n",
    "device_channels=64\n",
    "dt=1/60\n",
    "normalize_V=False\n",
    "\n",
    "my_model = torch.nn.Linear(64, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd553bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_temp = torch.tensor(cond0_training_and_labels_lst[0]['training'][:update_ix[1], :], dtype=torch.float32)\n",
    "p_reference = torch.transpose(torch.tensor(cond0_training_and_labels_lst[0]['labels'][:update_ix[1], :]), 0, 1)\n",
    "\n",
    "# First, normalize the entire s matrix\n",
    "if normalize_emg:\n",
    "    s_normed = s_temp / torch.linalg.norm(s_temp, ord='fro')\n",
    "    assert (torch.linalg.norm(s_normed, ord='fro')<1.2) and (torch.linalg.norm(s_normed, ord='fro')>0.8)\n",
    "else:\n",
    "    s_normed = s_temp\n",
    "# Apply PCA if applicable\n",
    "if pca_channels!=device_channels:  # 64 is the number of channels present on the recording armband\n",
    "    pca = PCA(n_components=pca_channels)\n",
    "    s = torch.transpose(torch.tensor(pca.fit_transform(s_normed), dtype=torch.float32), 0, 1)\n",
    "else:\n",
    "    s = torch.transpose(s_normed, 0, 1)\n",
    "\n",
    "F = s[:,:-1]\n",
    "v_actual =  torch.matmul(my_model.weight, s)\n",
    "p_actual = torch.cumsum(v_actual, dim=1)*dt  # Numerical integration of v_actual to get p_actual\n",
    "V = (p_reference - p_actual)*dt\n",
    "if normalize_V:\n",
    "    V = V/torch.linalg.norm(V, ord='fro')\n",
    "    assert (torch.linalg.norm(V, ord='fro')<1.2) and (torch.linalg.norm(V, ord='fro')>0.8)\n",
    "Y = p_reference[:, :-1]  # To match the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06320bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1199])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6db291db",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = CPHSLoss(F, my_model.weight, V, F.size()[1], \n",
    "                     lambdaF=0, lambdaD=1e-3, lambdaE=1e-4, \n",
    "                     Nd=2, Ne=64, return_cost_func_comps=True)\n",
    "loss_log = []\n",
    "running_epoch_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bae47cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: LambdaE*Error_Norm^2: 178.27844634683584\n",
      "D: LambdaD*Decoder_Norm^2: 0.0006647210102528334\n",
      "F: LambdaF*EMG_Norm^2: 0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#print(f\"clientAVG ----> Training LOSS {i}\")  # What is this even tellimg me lol\u001b[39;00m\n\u001b[0;32m     11\u001b[0m my_loss \u001b[38;5;241m=\u001b[39m loss(output, y, my_model)\n\u001b[1;32m---> 12\u001b[0m loss_log\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmy_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m())\n\u001b[0;32m     13\u001b[0m running_num_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "running_num_samples = 0\n",
    "x = torch.transpose(F,0,1)\n",
    "y = torch.transpose(Y,0,1)\n",
    "#if type(x) == type([]):\n",
    "#    x[0] = x[0].to(self.device)\n",
    "#else:\n",
    "#    x = x.to(self.device)\n",
    "#y = y.to(self.device)\n",
    "output = my_model(x)\n",
    "#print(f\"clientAVG ----> Training LOSS {i}\")  # What is this even tellimg me lol\n",
    "my_loss = loss(output, y, my_model)\n",
    "loss_log.append(my_loss.item())\n",
    "running_num_samples += x.size(0)\n",
    "#optimizer.zero_grad()\n",
    "#loss.backward()\n",
    "#optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e99cf00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(178.2791, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(178.2784, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(0.0007, grad_fn=<MulBackward0>),\n",
       " 0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b51db9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
