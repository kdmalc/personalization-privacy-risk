{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d17f193d",
   "metadata": {},
   "source": [
    "> __Purpose:__ \n",
    "\n",
    "- The x axis is really starting from update 10 (or 9?) in the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a61b3128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import h5py\n",
    "import copy\n",
    "import statistics\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "#from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import re\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from utils import *\n",
    "\n",
    "random.seed(a=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f2109c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_update = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb379c33-eece-4803-9e5d-c674321223e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVING = True\n",
    "\n",
    "#raise ValueError(\"MAKE SURE SAVING IS WHAT YOU WANT IT TO BE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2b58b",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59f33a4f-ccfb-42df-a59f-8dbd6b20cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PLOTTED_CONDITIONS = 6\n",
    "NUM_PLOTTED_CONDITIONS_WITH_GLOBAL = 10\n",
    "NUM_CLIENTS = 14\n",
    "NUM_FOLDS = 5\n",
    "\n",
    "results_path = r'C:\\Users\\kdmen\\Desktop\\Research\\personalization-privacy-risk\\PythonVersion\\PythonSimsRevamp\\results'\n",
    "current_directory = r'\\FinalSimRes'\n",
    "base_path = results_path + current_directory\n",
    "\n",
    "'''\n",
    "# CROSS\n",
    "10-05_14-23_NOFL_Cross\n",
    "10-05_14-32_PFAFO_Cross5\n",
    "10-05_14-48_FEDAVG_Cross5\n",
    "10-05_15-08_FEDAVG_Cross1\n",
    "10-05_15-14_PFAFO_Cross1\n",
    "\n",
    "# INTRA\n",
    "10-05_13-44_NOFL_Intra\n",
    "10-05_13-46_FEDAVG_Intra5\n",
    "10-05_13-55_FEDAVG_Intra1\n",
    "10-05_14-10_PFAFO_Intra1\n",
    "10-05_14-13_PFAFO_Intra5\n",
    "'''\n",
    "\n",
    "# CROSS\n",
    "cpfa_model_dict = load_model_logs(base_path+r'\\10-05_14-32_PFAFO_Cross5', 'GDLS_PFAFO_KFold')\n",
    "cfa_model_dict = load_model_logs(base_path+r'\\10-05_14-48_FEDAVG_Cross5', 'GDLS_FEDAVG_KFold')\n",
    "cnofl_model_dict = load_model_logs(base_path+r'\\10-05_14-23_NOFL_Cross', 'FULLSCIPYMIN_NOFL_KFold')\n",
    "# INTRA\n",
    "ipfa_model_dict = load_model_logs(base_path+r'\\10-05_14-13_PFAFO_Intra5', 'GDLS_PFAFO_KFold')\n",
    "ifa_model_dict = load_model_logs(base_path+r'\\10-05_13-46_FEDAVG_Intra5', 'GDLS_FEDAVG_KFold')\n",
    "inofl_model_dict = load_model_logs(base_path+r'\\10-05_13-44_NOFL_Intra', 'FULLSCIPYMIN_NOFL_KFold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35e0a736-d013-4980-ac79-4272d5d50e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMS_SAVING = False\n",
    "if SIMS_SAVING:\n",
    "    cpfa_global_sims_model = cpfa_model_dict['global_dec_log_fold6'][-2]\n",
    "    cfa_global_sims_model = cfa_model_dict['global_dec_log_fold6'][-2]\n",
    "    ipfa_global_sims_model = ipfa_model_dict['global_dec_log_fold6'][-2]\n",
    "    ifa_global_sims_model = ifa_model_dict['global_dec_log_fold6'][-2]\n",
    "    \n",
    "    sims_model_save_path = r'C:\\Users\\kdmen\\Desktop\\Research\\personalization-privacy-risk\\PythonVersion\\PythonSimsRevamp\\models\\FinalSimsModelForUserStudies'\n",
    "    np.save(f'{sims_model_save_path}\\\\cpfa_sims_init.npy', cpfa_global_sims_model)\n",
    "    np.save(f'{sims_model_save_path}\\\\cfa_sims_init.npy', cfa_global_sims_model)\n",
    "    np.save(f'{sims_model_save_path}\\\\ipfa_sims_init.npy', ipfa_global_sims_model)\n",
    "    np.save(f'{sims_model_save_path}\\\\ifa_sims_init.npy', ifa_global_sims_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a850bb15",
   "metadata": {},
   "source": [
    "# Adversarial Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d9d6712-6436-4246-a1d7-1cb744d22c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearSVC() --> Was failling to converge..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5955b098-cba4-4cdd-9b5a-7914b20890b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_linkage_attack(extractration_dict, num_kfolds=0, i_modulus=3, i_lt_or_eq='lt', \n",
    "                           my_models_list=[KNeighborsClassifier(), DecisionTreeClassifier(), GradientBoostingClassifier()], \n",
    "                           make_df=True, min_n_samples=10, num_clients=14):\n",
    "\n",
    "    flattened_input_df, num_updates = create_linkage_attack_df(extractration_dict, num_clients=num_clients)\n",
    "\n",
    "    local_res_df = execute_local_linkage_attack(flattened_input_df, num_updates, num_kfolds=num_kfolds, i_modulus=i_modulus, i_lt_or_eq=i_lt_or_eq,\n",
    "                           my_models_list=my_models_list, make_df=make_df, min_n_samples=min_n_samples, num_clients=num_clients)\n",
    "\n",
    "    global_res_df = execute_global_linkage_attack(flattened_input_df, num_updates, i_modulus=i_modulus, i_lt_or_eq=i_lt_or_eq,\n",
    "                           my_models_list=my_models_list, make_df=make_df, min_n_samples=min_n_samples, num_clients=num_clients)\n",
    "\n",
    "    return local_res_df, global_res_df\n",
    "\n",
    "    \n",
    "def create_linkage_attack_df(extractration_dict, num_clients=14):\n",
    "\n",
    "    keys = extractration_dict.keys()\n",
    "    num_updates_lst = []\n",
    "    for key in keys:\n",
    "        if \"global\" in key:\n",
    "            continue\n",
    "        num_updates_lst.append(len(extractration_dict[key]))\n",
    "    mode_update = statistics.mode(num_updates_lst)\n",
    "    max_update = max(num_updates_lst)\n",
    "    # ^ NOW THAT GLOVAL IS INCLUDED, MAX UPDATE IS WAY OFF FOR LOCAL!\n",
    "    ## Could find the 2nd largest value, since all global runs will have the same length...\n",
    "    if max_update == mode_update:  # Eg this is a poor man's proxy for if this is the NOFL case\n",
    "        num_updates = mode_update\n",
    "    else:\n",
    "        num_updates = min(max_update, int(statistics.mean(num_updates_lst) + np.sqrt(statistics.stdev(num_updates_lst))))  # int() rounds down\n",
    "        # np.sqrt(stdev) bc sometimes stdev is massive (like 38), making num_updates just equal to the max...\n",
    "    print(f\"num updates = {num_updates}; max_update {max_update}; avg_num_updates {statistics.mean(num_updates_lst)}\")\n",
    "    \n",
    "    # Initialize a list of empty DataFrames for each user group\n",
    "    dec_flattened_list = [pd.DataFrame(columns=['Subject', 'Fold', 'Update Number', 'Flattened Dec']) for _ in range(num_updates)]\n",
    "    global_dec_flattened_list = [pd.DataFrame(columns=['Subject', 'Fold', 'Update Number', 'Flattened Dec']) for _ in range(max_update)]\n",
    "    \n",
    "    # Regular expression pattern to extract subject and fold\n",
    "    #pattern = r\"S(\\d+)_client_local_model_log_fold(\\d+)\"\n",
    "    #pattern = r\"(S\\d+)_client_local_model_log_fold(\\d+)\"\n",
    "    pattern = r\"((S\\d+)_client_local_model_log_fold(\\d+)|global_dec_log_fold(\\d+))\"\n",
    "    # Loop through keys and updates to populate the DataFrames\n",
    "    for key_idx, key in enumerate(keys):\n",
    "        key_len = len(extractration_dict[key])\n",
    "        match = re.search(pattern, key)  # Extract the subject and fold using regex\n",
    "        # Group0: Entire match (the entire local key? Not sure what happens if global is the match...)\n",
    "        # Group1: Local subject ID (str)\n",
    "        # Group3: Local fold\n",
    "        # Group4: Global fold\n",
    "        if match:\n",
    "            if match.group(2):\n",
    "                #print(f\"Group 1: {match.group(1)}\")\n",
    "                #print(f\"Group 2: {match.group(2)}\")\n",
    "                #print(f\"Group 3: {match.group(3)}\")\n",
    "                subject = match.group(1)  # e.g., 'S0', 'S1', 'S10'\n",
    "                fold = int(match.group(3))  # e.g., '0', '1', '2'\n",
    "                for update_number in range(num_updates): \n",
    "                    if update_number >= key_len:\n",
    "                        continue\n",
    "                    else:\n",
    "                        user_data = np.ravel(extractration_dict[key][update_number])\n",
    "                        dec_flattened_list[update_number].loc[len(dec_flattened_list[update_number])] = [subject, fold, update_number, user_data]\n",
    "            elif match.group(4):  # This means it's a 'global_dec_log_fold(\\d+)' key\n",
    "                #print(f\"Group 4: {match.group(4)}\")\n",
    "                fold = int(match.group(4))\n",
    "                for update_number in range(max_update): # Max_update will be the number of global rounds\n",
    "                    global_data = np.ravel(extractration_dict[key][update_number])\n",
    "                    for subj_ID_num in range(num_clients):\n",
    "                        global_dec_flattened_list[update_number].loc[len(global_dec_flattened_list[update_number])] = [\"S\"+str(subj_ID_num), fold, update_number, global_data]\n",
    "    \n",
    "    # Concat all the dfs into a single training input dataframe\n",
    "    dec_flattened = pd.concat(dec_flattened_list, ignore_index=True, axis=0)\n",
    "    flattened_input_df = dec_flattened.join(dec_flattened['Flattened Dec'].apply(pd.Series)).drop('Flattened Dec', axis=1)\n",
    "    return flattened_input_df, num_updates\n",
    "\n",
    "\n",
    "def execute_local_linkage_attack(flattened_input_df, num_updates, num_kfolds=0, i_modulus=3, i_lt_or_eq='eq', \n",
    "                           my_models_list=[KNeighborsClassifier(), DecisionTreeClassifier(), GradientBoostingClassifier()], \n",
    "                           make_df=True, min_n_samples=10, num_clients=14):\n",
    "    my_metrics_columns=['Adversarial Model', 'Update Number', 'CV Acc', 'Test Acc']\n",
    "    full_test_res_df = pd.DataFrame(columns=my_metrics_columns)\n",
    "    \n",
    "    # Adjust stop index to prevent overflow\n",
    "    n_start_stop=(0, num_updates)\n",
    "    n_stop = n_start_stop[1] - 1\n",
    "    print(f\"num_updates {num_updates}; n_start_stop {n_start_stop}; new n_stop {n_stop}\")\n",
    "    \n",
    "    for i in range(n_start_stop[0], n_stop + 1):\n",
    "        #print(f\"Round i={i} of stop={n_start_stop[1]}\")\n",
    "    \n",
    "        if make_df:\n",
    "            #print(\"Making custom test set, NOT USING PASSED IN full_test_df\")\n",
    "    \n",
    "            if ((i_modulus==-1) and ((i==2) or (i==n_stop-1))) or ((i_modulus==-1) and (i%i_modulus==0)):\n",
    "                # Filter the dataframe to use data from updates </= = i\n",
    "                if i_lt_or_eq == 'lt':\n",
    "                    train_df = flattened_input_df[flattened_input_df['Update Number'] <= i]\n",
    "                elif i_lt_or_eq == 'eq':\n",
    "                    train_df = flattened_input_df[flattened_input_df['Update Number'] == i]  \n",
    "                # Hold out the last update for testing\n",
    "                ## Actually, I changed it to use ALL updates greater than the final train update (which is close to the mean...)\n",
    "                test_df = flattened_input_df[flattened_input_df['Update Number'] >= n_stop]\n",
    "            else:\n",
    "                # SKIP THE ENTIRE LOOP\n",
    "                #print(f\"{i} skipped for speed!\")\n",
    "                continue\n",
    "        else:\n",
    "            raise ValueError('Need to set train_df somehow...: for now, only use make_df=True')\n",
    "        \n",
    "        X_test = test_df.drop(columns=['Subject', 'Fold', 'Update Number'])\n",
    "        y_test = test_df['Subject']\n",
    "    \n",
    "        # Explicitly use the 'Fold' column for cross-validation\n",
    "        for model in my_models_list:\n",
    "            if num_kfolds == 0:\n",
    "                #print(f\"Fold {fold_num}\")\n",
    "                train_fold = train_df#[train_df['Fold'] != fold_num]\n",
    "                #val_fold = train_df[train_df['Fold'] == fold_num]\n",
    "    \n",
    "                if train_fold.shape[0] < min_n_samples: \n",
    "                    print(f\"Not enough samples! Skipping this round\")\n",
    "                    continue\n",
    "                #elif val_fold.shape[0]==0:\n",
    "                #    # Clients are trained a different number of rounds, so the max may be much higher than the average\n",
    "                #    # Thus resulting in upper rounds not containing any instances of a specific fold (eg can't train the model the way it is expected here)\n",
    "                #    continue\n",
    "\n",
    "                X_train_fold = train_fold.drop(columns=['Subject', 'Fold', 'Update Number']).reset_index(drop=True)\n",
    "                y_train_fold = train_fold['Subject'].reset_index(drop=True)\n",
    "                #X_val_fold = val_fold.drop(columns=['Subject', 'Fold', 'Update Number'])\n",
    "                #y_val_fold = val_fold['Subject']\n",
    "    \n",
    "                # Fit model on the current training fold\n",
    "                model.fit(X_train_fold, y_train_fold)\n",
    "                # Evaluate on the validation fold\n",
    "                #score = model.score(X_val_fold, y_val_fold)\n",
    "                cv_avg_score = None\n",
    "            else:\n",
    "                cv_scores = []\n",
    "                for fold_num in range(num_kfolds):\n",
    "                    #print(f\"Fold {fold_num}\")\n",
    "                    train_fold = train_df[train_df['Fold'] != fold_num]\n",
    "                    val_fold = train_df[train_df['Fold'] == fold_num]\n",
    "        \n",
    "                    if train_fold.shape[0] < min_n_samples:\n",
    "                        # if model is KNN and num_train_samples < model.n_neighbors\n",
    "                        # Adjust n_neighbors if necessary\n",
    "                        #print(f\"Adjusting n_neighbors to {num_train_samples} since it's smaller than n_neighbors.\")\n",
    "                        #model.set_params(n_neighbors=num_train_samples) \n",
    "                        \n",
    "                        print(f\"Not enough samples! Skipping this round\")\n",
    "                        continue\n",
    "                    elif val_fold.shape[0]==0:\n",
    "                        # Clients are trained a different number of rounds, so the max may be much higher than the average\n",
    "                        # Thus resulting in upper rounds not containing any instances of a specific fold (eg can't train the model the way it is expected here)\n",
    "                        continue\n",
    "    \n",
    "                    X_train_fold = train_fold.drop(columns=['Subject', 'Fold', 'Update Number']).reset_index(drop=True)\n",
    "                    y_train_fold = train_fold['Subject'].reset_index(drop=True)\n",
    "        \n",
    "                    X_val_fold = val_fold.drop(columns=['Subject', 'Fold', 'Update Number'])\n",
    "                    y_val_fold = val_fold['Subject']\n",
    "        \n",
    "                    # Fit model on the current training fold\n",
    "                    model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "                    # Evaluate on the validation fold\n",
    "                    score = model.score(X_val_fold, y_val_fold)\n",
    "                    cv_scores.append(score)\n",
    "        \n",
    "                # After evaluating all folds, calculate the average cross-validation score\n",
    "                cv_avg_score = sum(cv_scores) / len(cv_scores)\n",
    "    \n",
    "            # Calculate the test accuracy on the hold-out test set\n",
    "            test_acc = model.score(X_test, y_test)\n",
    "    \n",
    "            # Save the results to the full_test_res_df DataFrame\n",
    "            new_row = pd.DataFrame({\n",
    "                'Adversarial Model': [type(model).__name__],\n",
    "                'Update Number': [i],\n",
    "                'CV Acc': [cv_avg_score],\n",
    "                'Test Acc': [test_acc]\n",
    "            })\n",
    "            full_test_res_df = pd.concat([full_test_res_df, new_row], ignore_index=True)\n",
    "    \n",
    "    return full_test_res_df\n",
    "\n",
    "def execute_global_linkage_attack(flattened_input_df, num_updates, i_modulus=3, i_lt_or_eq='eq',\n",
    "                           my_models_list=[KNeighborsClassifier(), DecisionTreeClassifier(), GradientBoostingClassifier()], \n",
    "                           make_df=True, min_n_samples=5, num_clients=14):\n",
    "    my_metrics_columns=['Adversarial Model', 'Update Number', 'Test Acc']\n",
    "    full_test_res_df = pd.DataFrame(columns=my_metrics_columns)\n",
    "    \n",
    "    # Adjust stop index to prevent overflow\n",
    "    n_start_stop=(0, num_updates)\n",
    "    n_stop = n_start_stop[1] - 1\n",
    "    print(f\"num_updates {num_updates}; n_start_stop {n_start_stop}; new n_stop {n_stop}\")\n",
    "    \n",
    "    for i in range(n_start_stop[0], n_stop + 1):\n",
    "        #print(f\"Round i={i} of stop={n_start_stop[1]}\")\n",
    "    \n",
    "        if make_df:\n",
    "            #print(\"Making custom test set, NOT USING PASSED IN full_test_df\")\n",
    "    \n",
    "            if ((i_modulus==-1) and ((i==2) or (i==n_stop-1))) or ((i_modulus==-1) and (i%i_modulus==0)):\n",
    "                # Filter the dataframe to use data from updates </= = i\n",
    "                if i_lt_or_eq == 'lt':\n",
    "                    train_df = flattened_input_df[flattened_input_df['Update Number'] <= i]\n",
    "                elif i_lt_or_eq == 'eq':\n",
    "                    train_df = flattened_input_df[flattened_input_df['Update Number'] == i]  \n",
    "                # Hold out the last update for testing\n",
    "                ## Actually, I changed it to use ALL updates greater than the final train update (which is close to the mean...)\n",
    "                test_df = flattened_input_df[flattened_input_df['Update Number'] >= n_stop]\n",
    "            else:\n",
    "                # SKIP THE ENTIRE LOOP\n",
    "                #print(f\"{i} skipped for speed!\")\n",
    "                continue\n",
    "        else:\n",
    "            raise ValueError('Need to set train_df somehow...: for now, only use make_df=True')\n",
    "        \n",
    "        X_test = test_df.drop(columns=['Subject', 'Fold', 'Update Number'])\n",
    "        y_test = test_df['Subject']\n",
    "\n",
    "        # Explicitly use the 'Fold' column for cross-validation\n",
    "        for model in my_models_list:\n",
    "            if train_df.shape[0] < min_n_samples:\n",
    "                print(f\"Not enough samples! Skipping this round\")\n",
    "                continue\n",
    "\n",
    "            X_train = train_df.drop(columns=['Subject', 'Fold', 'Update Number']).reset_index(drop=True)\n",
    "            y_train = train_df['Subject'].reset_index(drop=True)\n",
    "\n",
    "            # Fit model on the current training fold\n",
    "            model.fit(X_train, y_train)\n",
    "            # Calculate the test accuracy on the hold-out test set\n",
    "            test_acc = model.score(X_test, y_test)\n",
    "    \n",
    "            # Save the results to the full_test_res_df DataFrame\n",
    "            new_row = pd.DataFrame({\n",
    "                'Adversarial Model': [type(model).__name__],\n",
    "                'Update Number': [i],\n",
    "                'Test Acc': [test_acc]\n",
    "            })\n",
    "            full_test_res_df = pd.concat([full_test_res_df, new_row], ignore_index=True)\n",
    "    \n",
    "    return full_test_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43255b2a-ea29-43ca-a8be-14b03af13227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1 does 2, a final and initial. 2 and 10 take way too long to run... kept getting frozen as well\n",
    "i_nofl = -1 #2\n",
    "i_fl = -1 #10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242a020a-7c19-47c6-825b-88ac9dd49fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num updates = 96; max_update 127; avg_num_updates 90.28571428571429\n",
      "num_updates 96; n_start_stop (0, 96); new n_stop 95\n"
     ]
    }
   ],
   "source": [
    "if SAVING:\n",
    "    cpfa_local_res_df, cpfa_global_res_df = execute_linkage_attack(cpfa_model_dict, i_modulus=i_fl)\n",
    "    cfa_local_res_df, cfa_global_res_df = execute_linkage_attack(cfa_model_dict, i_modulus=i_fl)\n",
    "    cnofl_local_res_df, cnofl_global_res_df = execute_linkage_attack(cnofl_model_dict, i_modulus=i_nofl)\n",
    "\n",
    "    cpfa_local_res_df.to_pickle(\"cpfa_local_res_df.pkl\")\n",
    "    cpfa_global_res_df.to_pickle(\"cpfa_global_res_df.pkl\")\n",
    "    cfa_local_res_df.to_pickle(\"cfa_local_res_df.pkl\")\n",
    "    cfa_global_res_df.to_pickle(\"cfa_global_res_df.pkl\")\n",
    "    cnofl_local_res_df.to_pickle(\"cnofl_local_res_df.pkl\")\n",
    "    cnofl_global_res_df.to_pickle(\"cnofl_global_res_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4a71a5-ee02-41f2-821b-f18cceb6c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVING:\n",
    "    ipfa_local_res_df, ipfa_global_res_df = execute_linkage_attack(ipfa_model_dict, i_modulus=i_fl)\n",
    "    ifa_local_res_df, ifa_global_res_df = execute_linkage_attack(ifa_model_dict, i_modulus=i_fl)\n",
    "    inofl_local_res_df, inofl_global_res_df = execute_linkage_attack(inofl_model_dict, i_modulus=i_nofl)\n",
    "    \n",
    "    ipfa_local_res_df.to_pickle(\"ipfa_local_res_df.pkl\")\n",
    "    ipfa_global_res_df.to_pickle(\"ipfa_global_res_df.pkl\")\n",
    "    ifa_local_res_df.to_pickle(\"ifa_local_res_df.pkl\")\n",
    "    ifa_global_res_df.to_pickle(\"ifa_global_res_df.pkl\")\n",
    "    inofl_local_res_df.to_pickle(\"inofl_local_res_df.pkl\")\n",
    "    inofl_global_res_df.to_pickle(\"inofl_global_res_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69649574-8c4d-40e5-b99f-47a306fa5dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# List of local and global dataframes\n",
    "local_dfs = [ipfa_local_res_df, ifa_local_res_df, inofl_local_res_df, cpfa_local_res_df, cfa_local_res_df, cnofl_local_res_df]\n",
    "global_dfs = [ipfa_global_res_df, ifa_global_res_df, inofl_global_res_df, cpfa_global_res_df, cfa_global_res_df, cnofl_global_res_df]\n",
    "\n",
    "# Combine all dataframes and filter by 'KNeighborsClassifier'\n",
    "filtered_dfs = []\n",
    "for local_df, global_df in zip(local_dfs, global_dfs):\n",
    "    # Filter for KNeighborsClassifier in each dataframe\n",
    "    local_filtered = local_df[local_df['Adversarial Model'] == 'KNeighborsClassifier']\n",
    "    global_filtered = global_df[global_df['Adversarial Model'] == 'KNeighborsClassifier']\n",
    "    \n",
    "    # Append both filtered dataframes to a combined list\n",
    "    filtered_dfs.append(local_filtered)\n",
    "    filtered_dfs.append(global_filtered)\n",
    "\n",
    "# Concatenate all filtered dataframes\n",
    "combined_df = pd.concat(filtered_dfs)\n",
    "\n",
    "### 1. LINE PLOT\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Define unique colors for trials (6 trials, local and global)\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y']\n",
    "line_styles = ['-', '--']  # Solid for local, dashed for global\n",
    "\n",
    "# Plot the local and global models with different line styles\n",
    "for idx, df in enumerate(local_dfs):\n",
    "    local_filtered = df[df['Adversarial Model'] == 'KNeighborsClassifier']\n",
    "    global_filtered = global_dfs[idx][global_dfs[idx]['Adversarial Model'] == 'KNeighborsClassifier']\n",
    "    \n",
    "    plt.plot(local_filtered['Update Number'], local_filtered['Test Acc'], color=colors[idx], linestyle=line_styles[0], label=f'Trial {idx+1} Local')\n",
    "    plt.plot(global_filtered['Update Number'], global_filtered['Test Acc'], color=colors[idx], linestyle=line_styles[1], label=f'Trial {idx+1} Global')\n",
    "\n",
    "plt.xlabel('Update Number')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.title('KNN Adversarial Model Accuracy Progression')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "### 2. HEATMAP\n",
    "\n",
    "# To create a heatmap, we need a pivoted dataframe where rows represent trials (local and global) and columns are Update Number\n",
    "\n",
    "# Add a column to represent the trial name\n",
    "for idx, (local_df, global_df) in enumerate(zip(local_dfs, global_dfs)):\n",
    "    local_dfs[idx]['Trial'] = f'Trial {idx+1} Local'\n",
    "    global_dfs[idx]['Trial'] = f'Trial {idx+1} Global'\n",
    "\n",
    "# Combine all dataframes again with the new 'Trial' column\n",
    "heatmap_df = pd.concat(local_dfs + global_dfs)\n",
    "\n",
    "# Filter for KNeighborsClassifier and pivot the dataframe\n",
    "heatmap_df = heatmap_df[heatmap_df['Adversarial Model'] == 'KNeighborsClassifier']\n",
    "heatmap_pivot = heatmap_df.pivot(index='Trial', columns='Update Number', values='Test Acc')\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(heatmap_pivot, annot=True, cmap='coolwarm', cbar_kws={'label': 'Test Accuracy (%)'})\n",
    "plt.title('KNN Adversarial Model Accuracy Heatmap')\n",
    "plt.xlabel('Update Number')\n",
    "plt.ylabel('Trial')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37af10b-9e54-446a-a5ed-6993f2ba68e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a9012b-8973-418c-94eb-ed07edf22c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
