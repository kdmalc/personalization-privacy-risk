5/15/23
1. Refer to issues in Github, mainly
2. Cross-validation in sklearn for adding stdev to plots: https://scikit-learn.org/stable/modules/cross_validation.html, https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score
3. "A collection of important tasks in PyTorch from a vision researcher": https://spandan-madan.github.io/A-Collection-of-important-tasks-in-pytorch/

CONSIDERATIONS
1. ADVERSARIAL ROBUSTNESS
 - Seems like we ought to add a way to track how much each client has been contributing, to see if one client is just spamming data, drastically moving the global model
 - Generally, can an adversary contribute and hurt the performance on everyone else (intuitively yes), but do we have a way to track this? Amount of change from current model?  Statistical variance? Make separate globel models for different clusters?
 - Likewise probably need to do something about eavesdropping --> eg HE/SMC/encryption